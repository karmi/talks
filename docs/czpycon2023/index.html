<!DOCTYPE html>
<html lang="en"><head>
<script src="library-and-maze-czpycon2023_files/libs/clipboard/clipboard.min.js"></script>
<script src="library-and-maze-czpycon2023_files/libs/quarto-html/tabby.min.js"></script>
<script src="library-and-maze-czpycon2023_files/libs/quarto-html/popper.min.js"></script>
<script src="library-and-maze-czpycon2023_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="library-and-maze-czpycon2023_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="library-and-maze-czpycon2023_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="library-and-maze-czpycon2023_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="library-and-maze-czpycon2023_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.450">

  <meta name="author" content="Karel Minařík">
  <title>The Library  and  the&nbsp;Maze</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="library-and-maze-czpycon2023_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="library-and-maze-czpycon2023_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="library-and-maze-czpycon2023_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="style.css">
  <link href="library-and-maze-czpycon2023_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="library-and-maze-czpycon2023_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="library-and-maze-czpycon2023_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="library-and-maze-czpycon2023_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section data-background-color="#000" data-background-image="assets/the-library-of-babel.png" data-background-opacity="0.5" class="quarto-title-block center">
  <h1 class="title">The Library <br>and <br>the&nbsp;Maze</h1>
  <p class="subtitle">CZ PyCon 2023</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Karel Minařík 
</div>
</div>
</div>

</section>
<section class="slide level2">
<h2>This Talk is a Jupyter Notebook</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="assets/screenshot-notebook.png" class="border"></p>
<p><a href="https://github.com/karmi/talks/blob/main/czpycon2023/library-and-maze-czpycon2023.ipynb" style="font-size: 80%;">github.com/karmi/talks</a></p>
</div><div class="column" style="width:50%;">
<p>Software Developer</p>
<p><small>ex-</small>Elastic.co</p>
<p><small>ex-</small>Česko.Digital</p>
<p>Philosophy major</p>
<p><a href="https://karmi.cz" class="underline">https://karmi.cz</a></p>
<p style="margin-top: 40px; margin-bottom:0; line-height: 1;">
<img src="assets/icons/github-square.svg" width="25" class="icon small" style="opacity: 0.3; top: 4px;"><small><code><a href="https://github.com/karmi"><span class="citation" data-cites="karmi">@karmi</span></a></code></small>
</p>
<p style="margin-top:0; line-height: 1;">
<img src="assets/icons/twitter-square.svg" width="25" class="icon small" style="opacity: 0.3;top: 4px;"><small><code><a href="https://twitter.com/karmiq"><span class="citation" data-cites="karmiq">@karmiq</span></a></code></small>
</p>
</div>
</div>
</section>
<section class="slide level2 quotes-grid">
<h2></h2>
<div class="quotes">
<blockquote>
<p>“The self-attention mechanism uses multiple heads to capture different aspects of the sequence. Each head uses scaled dot-product attention to weight the importance of various parts of the input sequence when producing each element of the output sequence.”</p>
</blockquote>
<blockquote>
<p>“The vanishing gradient problem in RNNs is often mitigated by adopting architectures like LSTM (Long Short-Term Memory) or GRU (Gated Recurrent Units), which introduce gating mechanisms to control the flow of information.”</p>
</blockquote>
<blockquote>
<p>“The masked language model (MLM) pre-training objective allows BERT to learn bidirectional representations by randomly masking tokens and predicting them based on their context, using the Transformer’s encoder architecture. Fine-tuning is then performed using a task-specific head layer over the pre-trained embeddings.”</p>
</blockquote>
<blockquote>
<p>“The model is trained using stochastic gradient descent (SGD) with a learning rate decay, optimized on the cross-entropy loss. The final output layer uses a softmax activation function to produce class probabilities, which are converted to logits for evaluation.”</p>
</blockquote>
<blockquote>
<p>“LoRA augments pre-trained Transformer models by adding learnable, layer-wise recurrent mechanisms. This enables the model to adapt to new tasks without requiring extensive fine-tuning and mitigates the catastrophic forgetting problem.”</p>
</blockquote>
<blockquote>
<p>“The embeddings are initialized randomly and updated via backpropagation. These high-dimensional vectors capture syntactic and semantic information and are fed into a stack of convolutional and fully connected layers for downstream tasks.”</p>
</blockquote>
<div class="quotes-description">
(Content generated by AI)
</div>
</div>
</section>
<section class="slide level2" data-background="black" data-background-image="assets/meme-math-lady.jpg" data-background-transition="fade" data-transition="fade" data-transition-speed="slow">
<h2></h2>
<p><br><br><br><br></p>
<p><span class="math display">\[
\theta_{j} := \theta_{j} - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_{\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)}
\]</span></p>
<aside class="notes">
<p>It’s perfectly understandable to be completely confused by this.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>ChatGPT by OpenAI</h2>
<div class="columns">
<div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://openai.com/blog/chatgpt"><img data-src="assets/screenshot-chatgpt-announcement.png"></a></p>
</figure>
</div>
</div><div class="column" style="width:70%;">
<p>Announced in&nbsp;November&nbsp;2022</p>
<p>A&nbsp;“cambrian explosion” of interest in&nbsp;artificial intelligence</p>
<p>Many problems in IT will be<br> reframed as AI problems</p>
<p><small> Trivial example: extracting data from text </small></p>
</div>
</div>
<aside class="notes">
<p>Example, extracting data from text: regex pattern or few-shot learning?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section class="slide level2 text-white" data-background="black" data-background-image="assets/big-maze.png" data-background-opacity="0.6" data-background-transition="fade">
<h2>Our Itinerary</h2>
<ul>
<li>What are text embeddings?</li>
<li>Use case: <em>Semantic Search</em></li>
<li>Embeddings for other media</li>
</ul>
<aside class="notes">
<p><code>5 min</code></p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2 center" data-background="#dc143c">
<h2>➊ What Are Text Embeddings?</h2>
</section>
<section class="slide level2">
<h2>What Are Text Embeddings?</h2>
<p><br></p>
<ul>
<li><p>Basic mechanism for natural language processing<br> <small>(LLMs, machine translation, sentiment analysis, …)</small></p></li>
<li><p>Numerical representations of text<br> <small>(Words, phrases, sentences …)</small></p></li>
<li><p>“Long lists of numbers”</p></li>
<li><p>“GPS coordinates” for meaning</p></li>
</ul>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
</section>
<section class="slide level2 slide-code">
<h2>Let’s initialize a small model.</h2>
<p><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"><img data-src="assets/logo-huggingface.svg" class="icon" width="40" height="40"> <code>sentence-transformers/all-MiniLM-L6-v2</code></a></p>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<aside class="notes">
<p>Training data is more than 1 billion sentences (scientific papers, Reddit, StackExchange, MS Marco, Yahoo, …)</p>
<p>The model card at Hugging Face has all the details.</p>
<p>(“Self-supervised contrastive learning objective” – given a sentence from pair, predict the best pairing.)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">-</span>q sentence<span class="op">-</span>transformers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> SentenceTransformer(<span class="st">"all-MiniLM-L6-v2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<aside><div>
<p><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" class="uri">https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2</a></p>
</div></aside></section>
<section class="slide level2 slide-code smaller">
<h2>Let’s create embeddings for two words.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>embeddings_for_cat <span class="op">=</span> model1.encode(<span class="st">"cat"</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(embeddings_for_cat)[:<span class="dv">5</span>] <span class="op">+</span> [<span class="st">"..."</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.03733039, 0.0511619, -0.00030606816, 0.060209926, -0.11749442, '...']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>embeddings_for_dog <span class="op">=</span> model1.encode(<span class="st">"dog"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(embeddings_for_dog)[:<span class="dv">5</span>] <span class="op">+</span> [<span class="st">"..."</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[-0.05314704, 0.014194381, 0.0071458234, 0.06860866, -0.07848035, '...']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(embeddings_for_dog))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>384</code></pre>
</div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model1.get_sentence_embedding_dimension())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>384</code></pre>
</div>
</div>
</section>
<section class="slide level2 text-white" data-background="#718096">
<h2>What Are the “Dimensions”?</h2>
<pre><code>print(len(embeddings_for_dog))
# =&gt; 384
print(model1.get_sentence_embedding_dimension())
# =&gt; 384</code></pre>
<p><br></p>
<p>The model captures 384 different aspects of the word’s meaning, usage, or context.</p>
<p>For example:</p>
<ul>
<li>the <strong>emotional tone</strong> (positive, negative, neutral?)</li>
<li>the <strong>usage patterns</strong> (common or rare? in which genre?)</li>
<li>the <strong>social setting</strong> (formal or informal?)</li>
</ul>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
</section>
<section class="slide level2 slide-code">
<h2>Let’s put the embeddings into a <em>pandas</em> dataframe,<br> so we can make transformations and manipulations.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.DataFrame(</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>      [embeddings_for_cat],</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>      [embeddings_for_dog],</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>[<span class="st">"cat"</span>, <span class="st">"dog"</span>], columns<span class="op">=</span>[<span class="st">"embeddings"</span>])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>df1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">embeddings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">cat</td>
<td>[0.03733039, 0.0511619, -0.00030606816, 0.0602...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">dog</td>
<td>[-0.05314704, 0.014194381, 0.0071458234, 0.068...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Let’s transform the data for a visualization.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell columns column-output-location" data-execution_count="8">
<div class="column">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> df_for_heatmap(df):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    df.copy(deep<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Store the embeddings index as `position`</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    .assign(</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>      position<span class="op">=</span>[</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(x))) <span class="cf">for</span> x <span class="kw">in</span> df.embeddings</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>      ])</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the index into a regular column</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    .reset_index()</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert from "wide" to "long" format</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    .explode([<span class="st">"embeddings"</span>, <span class="st">"position"</span>])</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Rename columns for more clarity</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    .rename(</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>      columns<span class="op">=</span>{<span class="st">"index"</span>: <span class="st">"animal"</span>,  </span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>               <span class="st">"embeddings"</span>: <span class="st">"embedding"</span>})</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>source <span class="op">=</span> df_for_heatmap(df1)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>source</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output cell-output-display" data-execution_count="8">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">animal</th>
<th data-quarto-table-cell-role="th">embedding</th>
<th data-quarto-table-cell-role="th">position</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>cat</td>
<td>0.03733</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">0</td>
<td>cat</td>
<td>0.051162</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>cat</td>
<td>-0.000306</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">0</td>
<td>cat</td>
<td>0.06021</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>cat</td>
<td>-0.117494</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>dog</td>
<td>0.03667</td>
<td>379</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>dog</td>
<td>0.111445</td>
<td>380</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>dog</td>
<td>0.029857</td>
<td>381</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>dog</td>
<td>0.023905</td>
<td>382</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>dog</td>
<td>0.110093</td>
<td>383</td>
</tr>
</tbody>
</table>

<p>768 rows × 3 columns</p>
</div>
</div>
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Let’s make a simple <em>heatmap</em> visualization.</h2>

<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> altair <span class="im">as</span> alt</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> heatmap(df):</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> alt.Chart(</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        df</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    ).encode(</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        alt.X(<span class="st">"position:N"</span>, title<span class="op">=</span><span class="st">""</span>).axis(labels<span class="op">=</span><span class="va">False</span>, ticks<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        alt.Y(<span class="st">"animal:N"</span>, title<span class="op">=</span><span class="st">""</span>, sort<span class="op">=</span>df[<span class="st">"animal"</span>].unique()).axis(labelLimit<span class="op">=</span><span class="dv">300</span>, tickWidth<span class="op">=</span><span class="dv">0</span>, labelFontWeight<span class="op">=</span><span class="st">"bold"</span>),</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        alt.Color(<span class="st">"embedding:Q"</span>).scale(scheme<span class="op">=</span><span class="st">"goldred"</span>).legend(<span class="va">None</span>),</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    ).mark_rect(</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        width<span class="op">=</span><span class="dv">3</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    ).properties(</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        width<span class="op">=</span>alt.Step(<span class="dv">3</span>), height<span class="op">=</span>alt.Step(<span class="dv">50</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    ).configure_axis(</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        grid<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        domain<span class="op">=</span><span class="va">False</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>heatmap(source)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">

<style>
  #altair-viz-5278ba93b017469b9a08f308108517c5.vega-embed {
    width: 100%;
    display: flex;
  }

  #altair-viz-5278ba93b017469b9a08f308108517c5.vega-embed details,
  #altair-viz-5278ba93b017469b9a08f308108517c5.vega-embed details summary {
    position: relative;
  }
</style>
<div id="altair-viz-5278ba93b017469b9a08f308108517c5"></div>
<script type="text/javascript">
  var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-5278ba93b017469b9a08f308108517c5") {
      outputDiv = document.getElementById("altair-viz-5278ba93b017469b9a08f308108517c5");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm/vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm/vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm/vega-embed@6?noext",
    };

    function maybeLoadScript(lib, version) {
      var key = `${lib.replace("-", "")}_version`;
      return (VEGA_DEBUG[key] == version) ?
        Promise.resolve(paths[lib]) :
        new Promise(function(resolve, reject) {
          var s = document.createElement('script');
          document.getElementsByTagName("head")[0].appendChild(s);
          s.async = true;
          s.onload = () => {
            VEGA_DEBUG[key] = version;
            return resolve(paths[lib]);
          };
          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
          s.src = paths[lib];
        });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else {
      maybeLoadScript("vega", "5")
        .then(() => maybeLoadScript("vega-lite", "5.8.0"))
        .then(() => maybeLoadScript("vega-embed", "6"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 300, "continuousHeight": 300}, "axis": {"domain": false, "grid": false}}, "data": {"name": "data-8efba1ba53a4bb618665f8f43a86d300"}, "mark": {"type": "rect", "width": 3}, "encoding": {"color": {"field": "embedding", "legend": null, "scale": {"scheme": "goldred"}, "type": "quantitative"}, "x": {"axis": {"labels": false, "ticks": false}, "field": "position", "title": "", "type": "nominal"}, "y": {"axis": {"labelLimit": 300, "tickWidth": 0, "labelFontWeight": "bold"}, "field": "animal", "sort": ["cat", "dog"], "title": "", "type": "nominal"}}, "height": {"step": 50}, "width": {"step": 3}, "$schema": "https://vega.github.io/schema/vega-lite/v5.8.0.json", "datasets": {"data-8efba1ba53a4bb618665f8f43a86d300": [{"animal": "cat", "embedding": 0.03733038902282715, "position": 0}, {"animal": "cat", "embedding": 0.05116190016269684, "position": 1}, {"animal": "cat", "embedding": -0.00030606816289946437, "position": 2}, {"animal": "cat", "embedding": 0.06020992621779442, "position": 3}, {"animal": "cat", "embedding": -0.11749441921710968, "position": 4}, {"animal": "cat", "embedding": -0.014230103231966496, "position": 5}, {"animal": "cat", "embedding": 0.10577624291181564, "position": 6}, {"animal": "cat", "embedding": 0.02678622677922249, "position": 7}, {"animal": "cat", "embedding": 0.02633771300315857, "position": 8}, {"animal": "cat", "embedding": -0.025700822472572327, "position": 9}, {"animal": "cat", "embedding": -0.023490382358431816, "position": 10}, {"animal": "cat", "embedding": -0.059555213898420334, "position": 11}, {"animal": "cat", "embedding": -0.030213920399546623, "position": 12}, {"animal": "cat", "embedding": 0.01632016710937023, "position": 13}, {"animal": "cat", "embedding": -0.029070131480693817, "position": 14}, {"animal": "cat", "embedding": -0.021689726039767265, "position": 15}, {"animal": "cat", "embedding": -0.06624991446733475, "position": 16}, {"animal": "cat", "embedding": 0.0018566468497738242, "position": 17}, {"animal": "cat", "embedding": -0.02400624379515648, "position": 18}, {"animal": "cat", "embedding": -0.028462519869208336, "position": 19}, {"animal": "cat", "embedding": -0.04663162678480148, "position": 20}, {"animal": "cat", "embedding": 0.04970483109354973, "position": 21}, {"animal": "cat", "embedding": 0.0030829671304672956, "position": 22}, {"animal": "cat", "embedding": 0.0017627303022891283, "position": 23}, {"animal": "cat", "embedding": -0.0677575021982193, "position": 24}, {"animal": "cat", "embedding": 0.07610169798135757, "position": 25}, {"animal": "cat", "embedding": -0.04533000662922859, "position": 26}, {"animal": "cat", "embedding": -0.03643454983830452, "position": 27}, {"animal": "cat", "embedding": -0.01879478245973587, "position": 28}, {"animal": "cat", "embedding": -0.059158362448215485, "position": 29}, {"animal": "cat", "embedding": -0.06607434153556824, "position": 30}, {"animal": "cat", "embedding": -0.00032660627039149404, "position": 31}, {"animal": "cat", "embedding": -0.00892042275518179, "position": 32}, {"animal": "cat", "embedding": 0.0534161739051342, "position": 33}, {"animal": "cat", "embedding": -0.05470164492726326, "position": 34}, {"animal": "cat", "embedding": -0.05120444297790527, "position": 35}, {"animal": "cat", "embedding": -0.009808437898755074, "position": 36}, {"animal": "cat", "embedding": 0.001138185034506023, "position": 37}, {"animal": "cat", "embedding": 0.05640072748064995, "position": 38}, {"animal": "cat", "embedding": 0.06178216636180878, "position": 39}, {"animal": "cat", "embedding": -0.03502189368009567, "position": 40}, {"animal": "cat", "embedding": -0.08470239490270615, "position": 41}, {"animal": "cat", "embedding": -0.027238626033067703, "position": 42}, {"animal": "cat", "embedding": -0.01921604946255684, "position": 43}, {"animal": "cat", "embedding": -0.0301410760730505, "position": 44}, {"animal": "cat", "embedding": 0.004264598712325096, "position": 45}, {"animal": "cat", "embedding": 0.029739808291196823, "position": 46}, {"animal": "cat", "embedding": -0.061798322945833206, "position": 47}, {"animal": "cat", "embedding": 0.04495337978005409, "position": 48}, {"animal": "cat", "embedding": -0.003923146519809961, "position": 49}, {"animal": "cat", "embedding": -0.06464503705501556, "position": 50}, {"animal": "cat", "embedding": 0.02069356106221676, "position": 51}, {"animal": "cat", "embedding": -0.0368909053504467, "position": 52}, {"animal": "cat", "embedding": -0.005059054587036371, "position": 53}, {"animal": "cat", "embedding": -0.01631752960383892, "position": 54}, {"animal": "cat", "embedding": 0.0001643513242015615, "position": 55}, {"animal": "cat", "embedding": 0.05130369961261749, "position": 56}, {"animal": "cat", "embedding": -0.018979744985699654, "position": 57}, {"animal": "cat", "embedding": -0.025225350633263588, "position": 58}, {"animal": "cat", "embedding": -0.029659781605005264, "position": 59}, {"animal": "cat", "embedding": 0.004612454213202, "position": 60}, {"animal": "cat", "embedding": 0.010547024197876453, "position": 61}, {"animal": "cat", "embedding": -0.00012563458585646003, "position": 62}, {"animal": "cat", "embedding": 0.07811744511127472, "position": 63}, {"animal": "cat", "embedding": 0.025477126240730286, "position": 64}, {"animal": "cat", "embedding": -3.3329724828945473e-06, "position": 65}, {"animal": "cat", "embedding": 0.0002755826571956277, "position": 66}, {"animal": "cat", "embedding": 0.009694824926555157, "position": 67}, {"animal": "cat", "embedding": 0.04977673664689064, "position": 68}, {"animal": "cat", "embedding": -0.011180022731423378, "position": 69}, {"animal": "cat", "embedding": 0.012095801532268524, "position": 70}, {"animal": "cat", "embedding": 0.03868110850453377, "position": 71}, {"animal": "cat", "embedding": -0.029366565868258476, "position": 72}, {"animal": "cat", "embedding": -0.00028453633422032, "position": 73}, {"animal": "cat", "embedding": 0.019265014678239822, "position": 74}, {"animal": "cat", "embedding": -0.0329861044883728, "position": 75}, {"animal": "cat", "embedding": 0.13171620666980743, "position": 76}, {"animal": "cat", "embedding": -0.007330453954637051, "position": 77}, {"animal": "cat", "embedding": 0.10367878526449203, "position": 78}, {"animal": "cat", "embedding": 0.01577475108206272, "position": 79}, {"animal": "cat", "embedding": -0.006975072436034679, "position": 80}, {"animal": "cat", "embedding": 0.028203023597598076, "position": 81}, {"animal": "cat", "embedding": -0.026833834126591682, "position": 82}, {"animal": "cat", "embedding": 0.03720366954803467, "position": 83}, {"animal": "cat", "embedding": 0.04000026360154152, "position": 84}, {"animal": "cat", "embedding": 0.06586140394210815, "position": 85}, {"animal": "cat", "embedding": -0.001760500599630177, "position": 86}, {"animal": "cat", "embedding": 0.016396649181842804, "position": 87}, {"animal": "cat", "embedding": -0.06748654693365097, "position": 88}, {"animal": "cat", "embedding": 0.02065412700176239, "position": 89}, {"animal": "cat", "embedding": 0.0171644426882267, "position": 90}, {"animal": "cat", "embedding": -0.010133227333426476, "position": 91}, {"animal": "cat", "embedding": 0.06467209756374359, "position": 92}, {"animal": "cat", "embedding": 0.014943447895348072, "position": 93}, {"animal": "cat", "embedding": -0.11084962636232376, "position": 94}, {"animal": "cat", "embedding": 0.03118159994482994, "position": 95}, {"animal": "cat", "embedding": -0.0077262986451387405, "position": 96}, {"animal": "cat", "embedding": -0.07746338099241257, "position": 97}, {"animal": "cat", "embedding": -0.04207180067896843, "position": 98}, {"animal": "cat", "embedding": 0.23520731925964355, "position": 99}, {"animal": "cat", "embedding": 0.02549399808049202, "position": 100}, {"animal": "cat", "embedding": 0.02585536614060402, "position": 101}, {"animal": "cat", "embedding": -0.04416589438915253, "position": 102}, {"animal": "cat", "embedding": 0.056878671050071716, "position": 103}, {"animal": "cat", "embedding": 0.00432342616841197, "position": 104}, {"animal": "cat", "embedding": -0.015330181457102299, "position": 105}, {"animal": "cat", "embedding": 0.011216405779123306, "position": 106}, {"animal": "cat", "embedding": 0.0017130991909652948, "position": 107}, {"animal": "cat", "embedding": 0.006893873680382967, "position": 108}, {"animal": "cat", "embedding": 0.014921043068170547, "position": 109}, {"animal": "cat", "embedding": -0.0020004312973469496, "position": 110}, {"animal": "cat", "embedding": -0.04708622768521309, "position": 111}, {"animal": "cat", "embedding": -0.05938082933425903, "position": 112}, {"animal": "cat", "embedding": 0.054582782089710236, "position": 113}, {"animal": "cat", "embedding": 0.0366448275744915, "position": 114}, {"animal": "cat", "embedding": 0.021196236833930016, "position": 115}, {"animal": "cat", "embedding": -0.022666316479444504, "position": 116}, {"animal": "cat", "embedding": -0.033385489135980606, "position": 117}, {"animal": "cat", "embedding": 0.08896197378635406, "position": 118}, {"animal": "cat", "embedding": -0.01806301809847355, "position": 119}, {"animal": "cat", "embedding": 0.03752695024013519, "position": 120}, {"animal": "cat", "embedding": -0.009956763125956059, "position": 121}, {"animal": "cat", "embedding": -0.04760892689228058, "position": 122}, {"animal": "cat", "embedding": -0.011007025837898254, "position": 123}, {"animal": "cat", "embedding": -0.0520976223051548, "position": 124}, {"animal": "cat", "embedding": -0.08540461212396622, "position": 125}, {"animal": "cat", "embedding": -0.04771364480257034, "position": 126}, {"animal": "cat", "embedding": -4.5456480422313094e-33, "position": 127}, {"animal": "cat", "embedding": -0.0048442017287015915, "position": 128}, {"animal": "cat", "embedding": -0.0976090058684349, "position": 129}, {"animal": "cat", "embedding": 0.014730213209986687, "position": 130}, {"animal": "cat", "embedding": -0.02608395740389824, "position": 131}, {"animal": "cat", "embedding": 0.04912848398089409, "position": 132}, {"animal": "cat", "embedding": 0.05850321054458618, "position": 133}, {"animal": "cat", "embedding": 0.0028911400586366653, "position": 134}, {"animal": "cat", "embedding": 0.02906510978937149, "position": 135}, {"animal": "cat", "embedding": -0.08842658996582031, "position": 136}, {"animal": "cat", "embedding": 0.016123125329613686, "position": 137}, {"animal": "cat", "embedding": -0.08860384672880173, "position": 138}, {"animal": "cat", "embedding": 0.012519451789557934, "position": 139}, {"animal": "cat", "embedding": -0.07366228848695755, "position": 140}, {"animal": "cat", "embedding": -0.012363078072667122, "position": 141}, {"animal": "cat", "embedding": 0.03294412046670914, "position": 142}, {"animal": "cat", "embedding": -0.009775564074516296, "position": 143}, {"animal": "cat", "embedding": -0.013371375389397144, "position": 144}, {"animal": "cat", "embedding": 0.022750822827219963, "position": 145}, {"animal": "cat", "embedding": -0.03435720130801201, "position": 146}, {"animal": "cat", "embedding": 0.01697033829987049, "position": 147}, {"animal": "cat", "embedding": -0.01303133275359869, "position": 148}, {"animal": "cat", "embedding": 0.07845914363861084, "position": 149}, {"animal": "cat", "embedding": 0.07198294997215271, "position": 150}, {"animal": "cat", "embedding": 0.07821457833051682, "position": 151}, {"animal": "cat", "embedding": -0.004803099203854799, "position": 152}, {"animal": "cat", "embedding": -0.08423855900764465, "position": 153}, {"animal": "cat", "embedding": -0.03150900825858116, "position": 154}, {"animal": "cat", "embedding": -0.08608413487672806, "position": 155}, {"animal": "cat", "embedding": -0.016402896493673325, "position": 156}, {"animal": "cat", "embedding": 0.010649312287569046, "position": 157}, {"animal": "cat", "embedding": 0.052741192281246185, "position": 158}, {"animal": "cat", "embedding": -0.00983115378767252, "position": 159}, {"animal": "cat", "embedding": 0.0637749433517456, "position": 160}, {"animal": "cat", "embedding": -0.003886570455506444, "position": 161}, {"animal": "cat", "embedding": -0.09037613123655319, "position": 162}, {"animal": "cat", "embedding": -0.12911859154701233, "position": 163}, {"animal": "cat", "embedding": -0.0193893164396286, "position": 164}, {"animal": "cat", "embedding": -0.04714939743280411, "position": 165}, {"animal": "cat", "embedding": 0.017238669097423553, "position": 166}, {"animal": "cat", "embedding": 0.024575872346758842, "position": 167}, {"animal": "cat", "embedding": 0.04931345954537392, "position": 168}, {"animal": "cat", "embedding": 0.015245893970131874, "position": 169}, {"animal": "cat", "embedding": 0.052764177322387695, "position": 170}, {"animal": "cat", "embedding": 0.021206554025411606, "position": 171}, {"animal": "cat", "embedding": 0.007927180267870426, "position": 172}, {"animal": "cat", "embedding": 0.006518141366541386, "position": 173}, {"animal": "cat", "embedding": 0.0398627370595932, "position": 174}, {"animal": "cat", "embedding": 0.084649957716465, "position": 175}, {"animal": "cat", "embedding": -0.06809552758932114, "position": 176}, {"animal": "cat", "embedding": 0.058130018413066864, "position": 177}, {"animal": "cat", "embedding": 0.08200763165950775, "position": 178}, {"animal": "cat", "embedding": -0.02538556605577469, "position": 179}, {"animal": "cat", "embedding": -0.016495410352945328, "position": 180}, {"animal": "cat", "embedding": -0.02540753223001957, "position": 181}, {"animal": "cat", "embedding": -0.02050221525132656, "position": 182}, {"animal": "cat", "embedding": -0.010569297708570957, "position": 183}, {"animal": "cat", "embedding": -0.012290237471461296, "position": 184}, {"animal": "cat", "embedding": -0.06475042551755905, "position": 185}, {"animal": "cat", "embedding": -0.0017496290383860469, "position": 186}, {"animal": "cat", "embedding": 0.10200170427560806, "position": 187}, {"animal": "cat", "embedding": 0.02206496335566044, "position": 188}, {"animal": "cat", "embedding": 0.0765802413225174, "position": 189}, {"animal": "cat", "embedding": 0.09286633133888245, "position": 190}, {"animal": "cat", "embedding": 0.02781105227768421, "position": 191}, {"animal": "cat", "embedding": 0.06639950722455978, "position": 192}, {"animal": "cat", "embedding": -0.09011589735746384, "position": 193}, {"animal": "cat", "embedding": 0.05881255865097046, "position": 194}, {"animal": "cat", "embedding": -0.010556093417108059, "position": 195}, {"animal": "cat", "embedding": 0.10835209488868713, "position": 196}, {"animal": "cat", "embedding": 0.04515175148844719, "position": 197}, {"animal": "cat", "embedding": -0.09467636793851852, "position": 198}, {"animal": "cat", "embedding": -0.003975188825279474, "position": 199}, {"animal": "cat", "embedding": 0.05559930205345154, "position": 200}, {"animal": "cat", "embedding": -0.07512973994016647, "position": 201}, {"animal": "cat", "embedding": 0.0425630621612072, "position": 202}, {"animal": "cat", "embedding": -0.04162270575761795, "position": 203}, {"animal": "cat", "embedding": -0.03164689242839813, "position": 204}, {"animal": "cat", "embedding": 0.022920027375221252, "position": 205}, {"animal": "cat", "embedding": -0.07881384342908859, "position": 206}, {"animal": "cat", "embedding": 0.02434290573000908, "position": 207}, {"animal": "cat", "embedding": -0.0004664689186029136, "position": 208}, {"animal": "cat", "embedding": -0.0020791019778698683, "position": 209}, {"animal": "cat", "embedding": 0.06402021646499634, "position": 210}, {"animal": "cat", "embedding": 0.04672593995928764, "position": 211}, {"animal": "cat", "embedding": -0.05104973912239075, "position": 212}, {"animal": "cat", "embedding": 0.08571244031190872, "position": 213}, {"animal": "cat", "embedding": -0.003941823728382587, "position": 214}, {"animal": "cat", "embedding": -0.08086039870977402, "position": 215}, {"animal": "cat", "embedding": -0.001296516042202711, "position": 216}, {"animal": "cat", "embedding": 0.09354415535926819, "position": 217}, {"animal": "cat", "embedding": -0.08106525242328644, "position": 218}, {"animal": "cat", "embedding": 0.05914008617401123, "position": 219}, {"animal": "cat", "embedding": 0.04921571537852287, "position": 220}, {"animal": "cat", "embedding": -0.07231651991605759, "position": 221}, {"animal": "cat", "embedding": 0.058873023837804794, "position": 222}, {"animal": "cat", "embedding": 3.7824829468729096e-33, "position": 223}, {"animal": "cat", "embedding": 0.012545853853225708, "position": 224}, {"animal": "cat", "embedding": -0.04446148872375488, "position": 225}, {"animal": "cat", "embedding": -0.024489810690283775, "position": 226}, {"animal": "cat", "embedding": 0.04101358354091644, "position": 227}, {"animal": "cat", "embedding": -0.08004330098628998, "position": 228}, {"animal": "cat", "embedding": 0.054829951375722885, "position": 229}, {"animal": "cat", "embedding": 0.03494759649038315, "position": 230}, {"animal": "cat", "embedding": -0.019040284678339958, "position": 231}, {"animal": "cat", "embedding": -0.026668254286050797, "position": 232}, {"animal": "cat", "embedding": 0.090579092502594, "position": 233}, {"animal": "cat", "embedding": -0.040876492857933044, "position": 234}, {"animal": "cat", "embedding": 0.0605093277990818, "position": 235}, {"animal": "cat", "embedding": 0.12900973856449127, "position": 236}, {"animal": "cat", "embedding": 0.012991182506084442, "position": 237}, {"animal": "cat", "embedding": 0.03803068771958351, "position": 238}, {"animal": "cat", "embedding": 0.03300974890589714, "position": 239}, {"animal": "cat", "embedding": -0.014435109682381153, "position": 240}, {"animal": "cat", "embedding": -0.03980138525366783, "position": 241}, {"animal": "cat", "embedding": 0.03257004916667938, "position": 242}, {"animal": "cat", "embedding": 0.011381683871150017, "position": 243}, {"animal": "cat", "embedding": -0.07342980802059174, "position": 244}, {"animal": "cat", "embedding": -0.010433388873934746, "position": 245}, {"animal": "cat", "embedding": -0.07071487605571747, "position": 246}, {"animal": "cat", "embedding": 0.03186000511050224, "position": 247}, {"animal": "cat", "embedding": 0.017511023208498955, "position": 248}, {"animal": "cat", "embedding": -0.006756139453500509, "position": 249}, {"animal": "cat", "embedding": 0.02524220384657383, "position": 250}, {"animal": "cat", "embedding": 0.0011837746715173125, "position": 251}, {"animal": "cat", "embedding": 0.03266751393675804, "position": 252}, {"animal": "cat", "embedding": -0.15093408524990082, "position": 253}, {"animal": "cat", "embedding": 0.031178871169686317, "position": 254}, {"animal": "cat", "embedding": -0.059040218591690063, "position": 255}, {"animal": "cat", "embedding": -0.014013662934303284, "position": 256}, {"animal": "cat", "embedding": -0.033383652567863464, "position": 257}, {"animal": "cat", "embedding": 0.008506729267537594, "position": 258}, {"animal": "cat", "embedding": 0.125481516122818, "position": 259}, {"animal": "cat", "embedding": -0.016623444855213165, "position": 260}, {"animal": "cat", "embedding": -0.02540566585958004, "position": 261}, {"animal": "cat", "embedding": -0.023232221603393555, "position": 262}, {"animal": "cat", "embedding": -0.005709399003535509, "position": 263}, {"animal": "cat", "embedding": 0.02903098426759243, "position": 264}, {"animal": "cat", "embedding": 0.0447402223944664, "position": 265}, {"animal": "cat", "embedding": -0.015073765069246292, "position": 266}, {"animal": "cat", "embedding": 0.0722578912973404, "position": 267}, {"animal": "cat", "embedding": -0.05189726501703262, "position": 268}, {"animal": "cat", "embedding": -0.02070474810898304, "position": 269}, {"animal": "cat", "embedding": -0.03925088420510292, "position": 270}, {"animal": "cat", "embedding": 0.0036010397598147392, "position": 271}, {"animal": "cat", "embedding": 0.040269169956445694, "position": 272}, {"animal": "cat", "embedding": 0.017428286373615265, "position": 273}, {"animal": "cat", "embedding": -0.08170264959335327, "position": 274}, {"animal": "cat", "embedding": -0.06424960494041443, "position": 275}, {"animal": "cat", "embedding": -0.0008617308922111988, "position": 276}, {"animal": "cat", "embedding": -0.03882838785648346, "position": 277}, {"animal": "cat", "embedding": 0.02205195277929306, "position": 278}, {"animal": "cat", "embedding": 0.019644981250166893, "position": 279}, {"animal": "cat", "embedding": -0.04208141192793846, "position": 280}, {"animal": "cat", "embedding": -0.021611368283629417, "position": 281}, {"animal": "cat", "embedding": -0.004930383060127497, "position": 282}, {"animal": "cat", "embedding": 0.027349671348929405, "position": 283}, {"animal": "cat", "embedding": 0.026824576780200005, "position": 284}, {"animal": "cat", "embedding": 0.04687768593430519, "position": 285}, {"animal": "cat", "embedding": -0.009210288524627686, "position": 286}, {"animal": "cat", "embedding": 0.05176464468240738, "position": 287}, {"animal": "cat", "embedding": -0.06490634381771088, "position": 288}, {"animal": "cat", "embedding": -0.02696290984749794, "position": 289}, {"animal": "cat", "embedding": -0.020811501890420914, "position": 290}, {"animal": "cat", "embedding": -0.07466711103916168, "position": 291}, {"animal": "cat", "embedding": -0.0031141547951847315, "position": 292}, {"animal": "cat", "embedding": -0.050411488860845566, "position": 293}, {"animal": "cat", "embedding": 0.13004563748836517, "position": 294}, {"animal": "cat", "embedding": 0.04714154452085495, "position": 295}, {"animal": "cat", "embedding": -0.08545417338609695, "position": 296}, {"animal": "cat", "embedding": -0.004048071801662445, "position": 297}, {"animal": "cat", "embedding": -0.061450060456991196, "position": 298}, {"animal": "cat", "embedding": 0.03889447823166847, "position": 299}, {"animal": "cat", "embedding": 0.005142970476299524, "position": 300}, {"animal": "cat", "embedding": 0.04706956818699837, "position": 301}, {"animal": "cat", "embedding": -0.029663976281881332, "position": 302}, {"animal": "cat", "embedding": -0.057756803929805756, "position": 303}, {"animal": "cat", "embedding": -0.0038473927415907383, "position": 304}, {"animal": "cat", "embedding": -0.04252525418996811, "position": 305}, {"animal": "cat", "embedding": -0.013100975193083286, "position": 306}, {"animal": "cat", "embedding": 0.03536299988627434, "position": 307}, {"animal": "cat", "embedding": -0.03501349315047264, "position": 308}, {"animal": "cat", "embedding": -0.06737858057022095, "position": 309}, {"animal": "cat", "embedding": 0.051769454032182693, "position": 310}, {"animal": "cat", "embedding": 0.06665308028459549, "position": 311}, {"animal": "cat", "embedding": -0.0029960705433040857, "position": 312}, {"animal": "cat", "embedding": 0.023673666641116142, "position": 313}, {"animal": "cat", "embedding": 0.0336286686360836, "position": 314}, {"animal": "cat", "embedding": 0.010094651021063328, "position": 315}, {"animal": "cat", "embedding": 0.0015439869603142142, "position": 316}, {"animal": "cat", "embedding": -0.06326888501644135, "position": 317}, {"animal": "cat", "embedding": -0.00808235164731741, "position": 318}, {"animal": "cat", "embedding": -1.3356751260573674e-08, "position": 319}, {"animal": "cat", "embedding": -0.03938533365726471, "position": 320}, {"animal": "cat", "embedding": -0.0460556261241436, "position": 321}, {"animal": "cat", "embedding": -0.08799877762794495, "position": 322}, {"animal": "cat", "embedding": 0.010793684981763363, "position": 323}, {"animal": "cat", "embedding": 0.0767190083861351, "position": 324}, {"animal": "cat", "embedding": 0.0468168742954731, "position": 325}, {"animal": "cat", "embedding": -0.024283016100525856, "position": 326}, {"animal": "cat", "embedding": -0.08208191394805908, "position": 327}, {"animal": "cat", "embedding": -0.02560182474553585, "position": 328}, {"animal": "cat", "embedding": -0.010608954355120659, "position": 329}, {"animal": "cat", "embedding": 0.05409183353185654, "position": 330}, {"animal": "cat", "embedding": -0.03235789015889168, "position": 331}, {"animal": "cat", "embedding": 0.034818634390830994, "position": 332}, {"animal": "cat", "embedding": 0.04324425011873245, "position": 333}, {"animal": "cat", "embedding": 0.07993130385875702, "position": 334}, {"animal": "cat", "embedding": 0.023873573169112206, "position": 335}, {"animal": "cat", "embedding": -0.029143504798412323, "position": 336}, {"animal": "cat", "embedding": 0.0012296894565224648, "position": 337}, {"animal": "cat", "embedding": 0.02520967274904251, "position": 338}, {"animal": "cat", "embedding": 0.11311154067516327, "position": 339}, {"animal": "cat", "embedding": -0.07022909820079803, "position": 340}, {"animal": "cat", "embedding": 0.03528955206274986, "position": 341}, {"animal": "cat", "embedding": -0.08676883578300476, "position": 342}, {"animal": "cat", "embedding": 0.03237234801054001, "position": 343}, {"animal": "cat", "embedding": -0.037393685430288315, "position": 344}, {"animal": "cat", "embedding": -0.021842287853360176, "position": 345}, {"animal": "cat", "embedding": 0.0009299059747718275, "position": 346}, {"animal": "cat", "embedding": 0.10743861645460129, "position": 347}, {"animal": "cat", "embedding": 0.007365658413618803, "position": 348}, {"animal": "cat", "embedding": -0.0174539927393198, "position": 349}, {"animal": "cat", "embedding": -0.0014842381933704019, "position": 350}, {"animal": "cat", "embedding": 0.018017098307609558, "position": 351}, {"animal": "cat", "embedding": -0.0375107116997242, "position": 352}, {"animal": "cat", "embedding": -0.07899514585733414, "position": 353}, {"animal": "cat", "embedding": 0.011136556044220924, "position": 354}, {"animal": "cat", "embedding": -0.033229053020477295, "position": 355}, {"animal": "cat", "embedding": 0.027380332350730896, "position": 356}, {"animal": "cat", "embedding": -0.07640188187360764, "position": 357}, {"animal": "cat", "embedding": 0.07584808021783829, "position": 358}, {"animal": "cat", "embedding": -0.01616724766790867, "position": 359}, {"animal": "cat", "embedding": 0.030557842925190926, "position": 360}, {"animal": "cat", "embedding": 0.05776338651776314, "position": 361}, {"animal": "cat", "embedding": 0.08141149580478668, "position": 362}, {"animal": "cat", "embedding": -0.0730246976017952, "position": 363}, {"animal": "cat", "embedding": -0.11145440489053726, "position": 364}, {"animal": "cat", "embedding": 0.0002831020683515817, "position": 365}, {"animal": "cat", "embedding": 0.029737157747149467, "position": 366}, {"animal": "cat", "embedding": -0.08533915132284164, "position": 367}, {"animal": "cat", "embedding": 0.015011357143521309, "position": 368}, {"animal": "cat", "embedding": 0.007454106118530035, "position": 369}, {"animal": "cat", "embedding": 0.001321324030868709, "position": 370}, {"animal": "cat", "embedding": 0.06907472014427185, "position": 371}, {"animal": "cat", "embedding": 0.04601537436246872, "position": 372}, {"animal": "cat", "embedding": 0.06226341798901558, "position": 373}, {"animal": "cat", "embedding": 0.002010924741625786, "position": 374}, {"animal": "cat", "embedding": 0.015723126009106636, "position": 375}, {"animal": "cat", "embedding": -0.00421560276299715, "position": 376}, {"animal": "cat", "embedding": -0.015644202008843422, "position": 377}, {"animal": "cat", "embedding": -0.03716267645359039, "position": 378}, {"animal": "cat", "embedding": 0.05307966470718384, "position": 379}, {"animal": "cat", "embedding": 0.1596624255180359, "position": 380}, {"animal": "cat", "embedding": 0.06126928701996803, "position": 381}, {"animal": "cat", "embedding": 0.06081460043787956, "position": 382}, {"animal": "cat", "embedding": 0.04928029701113701, "position": 383}, {"animal": "dog", "embedding": -0.05314704030752182, "position": 0}, {"animal": "dog", "embedding": 0.014194381423294544, "position": 1}, {"animal": "dog", "embedding": 0.007145823445171118, "position": 2}, {"animal": "dog", "embedding": 0.06860865652561188, "position": 3}, {"animal": "dog", "embedding": -0.07848034799098969, "position": 4}, {"animal": "dog", "embedding": 0.010167370550334454, "position": 5}, {"animal": "dog", "embedding": 0.10228318721055984, "position": 6}, {"animal": "dog", "embedding": -0.012064791284501553, "position": 7}, {"animal": "dog", "embedding": 0.09521343559026718, "position": 8}, {"animal": "dog", "embedding": -0.030350157991051674, "position": 9}, {"animal": "dog", "embedding": 0.00216468283906579, "position": 10}, {"animal": "dog", "embedding": -0.06486445665359497, "position": 11}, {"animal": "dog", "embedding": -0.002594356657937169, "position": 12}, {"animal": "dog", "embedding": 0.006218955386430025, "position": 13}, {"animal": "dog", "embedding": -0.003928696271032095, "position": 14}, {"animal": "dog", "embedding": -0.030624518170952797, "position": 15}, {"animal": "dog", "embedding": -0.047911498695611954, "position": 16}, {"animal": "dog", "embedding": -0.019300563260912895, "position": 17}, {"animal": "dog", "embedding": -0.05988546088337898, "position": 18}, {"animal": "dog", "embedding": -0.1041673868894577, "position": 19}, {"animal": "dog", "embedding": -0.08614886552095413, "position": 20}, {"animal": "dog", "embedding": 0.03635948523879051, "position": 21}, {"animal": "dog", "embedding": -0.025526152923703194, "position": 22}, {"animal": "dog", "embedding": 0.0016389002557843924, "position": 23}, {"animal": "dog", "embedding": -0.07144202291965485, "position": 24}, {"animal": "dog", "embedding": 0.06167998164892197, "position": 25}, {"animal": "dog", "embedding": 0.017194632440805435, "position": 26}, {"animal": "dog", "embedding": -0.0566110722720623, "position": 27}, {"animal": "dog", "embedding": 0.02481217496097088, "position": 28}, {"animal": "dog", "embedding": -0.07782232016324997, "position": 29}, {"animal": "dog", "embedding": -0.03249913826584816, "position": 30}, {"animal": "dog", "embedding": -0.008699053898453712, "position": 31}, {"animal": "dog", "embedding": -0.011532493866980076, "position": 32}, {"animal": "dog", "embedding": 0.03816734254360199, "position": 33}, {"animal": "dog", "embedding": -0.0569307804107666, "position": 34}, {"animal": "dog", "embedding": -0.05327097326517105, "position": 35}, {"animal": "dog", "embedding": 0.004925676621496677, "position": 36}, {"animal": "dog", "embedding": 0.032500606030225754, "position": 37}, {"animal": "dog", "embedding": 0.07253244519233704, "position": 38}, {"animal": "dog", "embedding": 0.03298495337367058, "position": 39}, {"animal": "dog", "embedding": 0.02472294308245182, "position": 40}, {"animal": "dog", "embedding": -0.08334524929523468, "position": 41}, {"animal": "dog", "embedding": -0.01568584330379963, "position": 42}, {"animal": "dog", "embedding": -0.04811973124742508, "position": 43}, {"animal": "dog", "embedding": -0.0034772511571645737, "position": 44}, {"animal": "dog", "embedding": 0.0043505458161234856, "position": 45}, {"animal": "dog", "embedding": -0.035895638167858124, "position": 46}, {"animal": "dog", "embedding": -0.051854055374860764, "position": 47}, {"animal": "dog", "embedding": 0.015673262998461723, "position": 48}, {"animal": "dog", "embedding": 0.0035223623272031546, "position": 49}, {"animal": "dog", "embedding": -0.010323265567421913, "position": 50}, {"animal": "dog", "embedding": 0.04764167591929436, "position": 51}, {"animal": "dog", "embedding": -0.04015855863690376, "position": 52}, {"animal": "dog", "embedding": -0.009099465794861317, "position": 53}, {"animal": "dog", "embedding": -0.03463490679860115, "position": 54}, {"animal": "dog", "embedding": -0.036981791257858276, "position": 55}, {"animal": "dog", "embedding": -0.040840186178684235, "position": 56}, {"animal": "dog", "embedding": 0.01771903596818447, "position": 57}, {"animal": "dog", "embedding": -0.009393063373863697, "position": 58}, {"animal": "dog", "embedding": -0.05363636463880539, "position": 59}, {"animal": "dog", "embedding": 0.011132970452308655, "position": 60}, {"animal": "dog", "embedding": 0.01618044637143612, "position": 61}, {"animal": "dog", "embedding": 0.013784712180495262, "position": 62}, {"animal": "dog", "embedding": 0.02831323631107807, "position": 63}, {"animal": "dog", "embedding": 0.04025879129767418, "position": 64}, {"animal": "dog", "embedding": 0.020901843905448914, "position": 65}, {"animal": "dog", "embedding": -0.01446566078811884, "position": 66}, {"animal": "dog", "embedding": -0.001599957817234099, "position": 67}, {"animal": "dog", "embedding": -0.004975095856934786, "position": 68}, {"animal": "dog", "embedding": 0.01207258552312851, "position": 69}, {"animal": "dog", "embedding": 0.04553656652569771, "position": 70}, {"animal": "dog", "embedding": 0.013122199103236198, "position": 71}, {"animal": "dog", "embedding": 0.07058051973581314, "position": 72}, {"animal": "dog", "embedding": -0.03082926571369171, "position": 73}, {"animal": "dog", "embedding": 0.030435528606176376, "position": 74}, {"animal": "dog", "embedding": -0.10847663134336472, "position": 75}, {"animal": "dog", "embedding": 0.055476654320955276, "position": 76}, {"animal": "dog", "embedding": -0.017531754449009895, "position": 77}, {"animal": "dog", "embedding": 0.1643153876066208, "position": 78}, {"animal": "dog", "embedding": 0.05145590007305145, "position": 79}, {"animal": "dog", "embedding": -0.02768351137638092, "position": 80}, {"animal": "dog", "embedding": -0.029959024861454964, "position": 81}, {"animal": "dog", "embedding": -0.05695224180817604, "position": 82}, {"animal": "dog", "embedding": 0.05682338401675224, "position": 83}, {"animal": "dog", "embedding": 0.050946734845638275, "position": 84}, {"animal": "dog", "embedding": 0.015132096596062183, "position": 85}, {"animal": "dog", "embedding": -0.0012805460719391704, "position": 86}, {"animal": "dog", "embedding": 0.023994985967874527, "position": 87}, {"animal": "dog", "embedding": -0.0632866695523262, "position": 88}, {"animal": "dog", "embedding": 0.028871750459074974, "position": 89}, {"animal": "dog", "embedding": -0.05534108728170395, "position": 90}, {"animal": "dog", "embedding": -0.034939344972372055, "position": 91}, {"animal": "dog", "embedding": 0.030283333733677864, "position": 92}, {"animal": "dog", "embedding": 0.026885908097028732, "position": 93}, {"animal": "dog", "embedding": -0.08350417017936707, "position": 94}, {"animal": "dog", "embedding": 0.018362293019890785, "position": 95}, {"animal": "dog", "embedding": -0.03515780344605446, "position": 96}, {"animal": "dog", "embedding": -0.08281918615102768, "position": 97}, {"animal": "dog", "embedding": -0.07189119607210159, "position": 98}, {"animal": "dog", "embedding": 0.19799093902111053, "position": 99}, {"animal": "dog", "embedding": 0.01641560159623623, "position": 100}, {"animal": "dog", "embedding": 0.04458478093147278, "position": 101}, {"animal": "dog", "embedding": -0.003755447454750538, "position": 102}, {"animal": "dog", "embedding": -0.03850797936320305, "position": 103}, {"animal": "dog", "embedding": 0.053483545780181885, "position": 104}, {"animal": "dog", "embedding": -0.0034694005735218525, "position": 105}, {"animal": "dog", "embedding": -0.04348180070519447, "position": 106}, {"animal": "dog", "embedding": 0.06338968873023987, "position": 107}, {"animal": "dog", "embedding": -0.013175569474697113, "position": 108}, {"animal": "dog", "embedding": -0.019762825220823288, "position": 109}, {"animal": "dog", "embedding": -0.045273832976818085, "position": 110}, {"animal": "dog", "embedding": 0.020712850615382195, "position": 111}, {"animal": "dog", "embedding": -0.05651763454079628, "position": 112}, {"animal": "dog", "embedding": 0.05744059756398201, "position": 113}, {"animal": "dog", "embedding": 0.055534280836582184, "position": 114}, {"animal": "dog", "embedding": 0.021156515926122665, "position": 115}, {"animal": "dog", "embedding": -0.1009354218840599, "position": 116}, {"animal": "dog", "embedding": -0.03430286794900894, "position": 117}, {"animal": "dog", "embedding": 0.0293644480407238, "position": 118}, {"animal": "dog", "embedding": -0.0332467183470726, "position": 119}, {"animal": "dog", "embedding": 0.028912032023072243, "position": 120}, {"animal": "dog", "embedding": 0.030096786096692085, "position": 121}, {"animal": "dog", "embedding": -0.051864609122276306, "position": 122}, {"animal": "dog", "embedding": 0.008204172365367413, "position": 123}, {"animal": "dog", "embedding": -0.016697708517313004, "position": 124}, {"animal": "dog", "embedding": -0.08435996621847153, "position": 125}, {"animal": "dog", "embedding": 0.01114204153418541, "position": 126}, {"animal": "dog", "embedding": -5.923913331860518e-33, "position": 127}, {"animal": "dog", "embedding": 0.030650777742266655, "position": 128}, {"animal": "dog", "embedding": -0.08504284918308258, "position": 129}, {"animal": "dog", "embedding": 0.0027174956630915403, "position": 130}, {"animal": "dog", "embedding": -0.04106851667165756, "position": 131}, {"animal": "dog", "embedding": -0.04272565245628357, "position": 132}, {"animal": "dog", "embedding": 0.041027553379535675, "position": 133}, {"animal": "dog", "embedding": 0.0294408667832613, "position": 134}, {"animal": "dog", "embedding": 0.03645971789956093, "position": 135}, {"animal": "dog", "embedding": -0.12123750895261765, "position": 136}, {"animal": "dog", "embedding": 0.013488640077412128, "position": 137}, {"animal": "dog", "embedding": -0.013879092410206795, "position": 138}, {"animal": "dog", "embedding": 0.03126835823059082, "position": 139}, {"animal": "dog", "embedding": -0.02161930501461029, "position": 140}, {"animal": "dog", "embedding": 0.016177335754036903, "position": 141}, {"animal": "dog", "embedding": 0.11223004758358002, "position": 142}, {"animal": "dog", "embedding": -0.006708204746246338, "position": 143}, {"animal": "dog", "embedding": -0.0018929342040792108, "position": 144}, {"animal": "dog", "embedding": 0.05322014540433884, "position": 145}, {"animal": "dog", "embedding": 0.03261099010705948, "position": 146}, {"animal": "dog", "embedding": -0.03776618838310242, "position": 147}, {"animal": "dog", "embedding": -0.04691636934876442, "position": 148}, {"animal": "dog", "embedding": 0.0619485080242157, "position": 149}, {"animal": "dog", "embedding": 0.06361379474401474, "position": 150}, {"animal": "dog", "embedding": 0.05011941120028496, "position": 151}, {"animal": "dog", "embedding": -0.007603948004543781, "position": 152}, {"animal": "dog", "embedding": -0.021480945870280266, "position": 153}, {"animal": "dog", "embedding": -0.03778751194477081, "position": 154}, {"animal": "dog", "embedding": -0.08291468769311905, "position": 155}, {"animal": "dog", "embedding": -0.026290450245141983, "position": 156}, {"animal": "dog", "embedding": 0.03614022210240364, "position": 157}, {"animal": "dog", "embedding": 0.04127701744437218, "position": 158}, {"animal": "dog", "embedding": 0.014518577605485916, "position": 159}, {"animal": "dog", "embedding": 0.0734504908323288, "position": 160}, {"animal": "dog", "embedding": 0.0006526930956169963, "position": 161}, {"animal": "dog", "embedding": -0.08143548667430878, "position": 162}, {"animal": "dog", "embedding": -0.05578257888555527, "position": 163}, {"animal": "dog", "embedding": -0.04213260859251022, "position": 164}, {"animal": "dog", "embedding": -0.09667719155550003, "position": 165}, {"animal": "dog", "embedding": -0.04012607783079147, "position": 166}, {"animal": "dog", "embedding": 0.028559522703289986, "position": 167}, {"animal": "dog", "embedding": 0.1290501356124878, "position": 168}, {"animal": "dog", "embedding": 0.01044805534183979, "position": 169}, {"animal": "dog", "embedding": 0.02510608546435833, "position": 170}, {"animal": "dog", "embedding": 0.017339762300252914, "position": 171}, {"animal": "dog", "embedding": -0.027208272367715836, "position": 172}, {"animal": "dog", "embedding": -0.0049482979811728, "position": 173}, {"animal": "dog", "embedding": 0.015734028071165085, "position": 174}, {"animal": "dog", "embedding": 0.03437737375497818, "position": 175}, {"animal": "dog", "embedding": -0.04448755457997322, "position": 176}, {"animal": "dog", "embedding": 0.02083745039999485, "position": 177}, {"animal": "dog", "embedding": 0.02751891128718853, "position": 178}, {"animal": "dog", "embedding": -0.01431448757648468, "position": 179}, {"animal": "dog", "embedding": 0.028818361461162567, "position": 180}, {"animal": "dog", "embedding": -0.021267399191856384, "position": 181}, {"animal": "dog", "embedding": 0.008817851543426514, "position": 182}, {"animal": "dog", "embedding": 0.009855779819190502, "position": 183}, {"animal": "dog", "embedding": 0.0029994479846209288, "position": 184}, {"animal": "dog", "embedding": -0.02380906231701374, "position": 185}, {"animal": "dog", "embedding": 0.01304733008146286, "position": 186}, {"animal": "dog", "embedding": 0.06634410470724106, "position": 187}, {"animal": "dog", "embedding": 0.06891762465238571, "position": 188}, {"animal": "dog", "embedding": 0.08254698663949966, "position": 189}, {"animal": "dog", "embedding": 0.008786113932728767, "position": 190}, {"animal": "dog", "embedding": -0.014059261418879032, "position": 191}, {"animal": "dog", "embedding": 0.09107065200805664, "position": 192}, {"animal": "dog", "embedding": -0.1221766248345375, "position": 193}, {"animal": "dog", "embedding": -0.04530944302678108, "position": 194}, {"animal": "dog", "embedding": -0.018081234768033028, "position": 195}, {"animal": "dog", "embedding": -0.022172048687934875, "position": 196}, {"animal": "dog", "embedding": 0.021522752940654755, "position": 197}, {"animal": "dog", "embedding": -0.038843415677547455, "position": 198}, {"animal": "dog", "embedding": -0.01955721341073513, "position": 199}, {"animal": "dog", "embedding": 0.07971450686454773, "position": 200}, {"animal": "dog", "embedding": -0.01576269045472145, "position": 201}, {"animal": "dog", "embedding": 0.06888051331043243, "position": 202}, {"animal": "dog", "embedding": -0.01556633971631527, "position": 203}, {"animal": "dog", "embedding": 0.022782083600759506, "position": 204}, {"animal": "dog", "embedding": 0.02529541775584221, "position": 205}, {"animal": "dog", "embedding": -0.031191565096378326, "position": 206}, {"animal": "dog", "embedding": -0.03350035846233368, "position": 207}, {"animal": "dog", "embedding": -0.0215879175812006, "position": 208}, {"animal": "dog", "embedding": -0.010069506242871284, "position": 209}, {"animal": "dog", "embedding": 0.00550079857930541, "position": 210}, {"animal": "dog", "embedding": 0.048977430909872055, "position": 211}, {"animal": "dog", "embedding": -0.021504582837224007, "position": 212}, {"animal": "dog", "embedding": 0.0638372004032135, "position": 213}, {"animal": "dog", "embedding": -0.019716935232281685, "position": 214}, {"animal": "dog", "embedding": -0.030271977186203003, "position": 215}, {"animal": "dog", "embedding": 0.006232741754502058, "position": 216}, {"animal": "dog", "embedding": 0.045180611312389374, "position": 217}, {"animal": "dog", "embedding": -0.04580971226096153, "position": 218}, {"animal": "dog", "embedding": -0.04915788397192955, "position": 219}, {"animal": "dog", "embedding": 0.08708895742893219, "position": 220}, {"animal": "dog", "embedding": 0.02734500542283058, "position": 221}, {"animal": "dog", "embedding": 0.0905928835272789, "position": 222}, {"animal": "dog", "embedding": 3.432160283730928e-33, "position": 223}, {"animal": "dog", "embedding": 0.0625440925359726, "position": 224}, {"animal": "dog", "embedding": 0.028967853635549545, "position": 225}, {"animal": "dog", "embedding": 5.452089317259379e-05, "position": 226}, {"animal": "dog", "embedding": 0.0914405807852745, "position": 227}, {"animal": "dog", "embedding": -0.030373184010386467, "position": 228}, {"animal": "dog", "embedding": 0.00491048488765955, "position": 229}, {"animal": "dog", "embedding": -0.02546708844602108, "position": 230}, {"animal": "dog", "embedding": 0.06670119613409042, "position": 231}, {"animal": "dog", "embedding": -0.03414908051490784, "position": 232}, {"animal": "dog", "embedding": 0.047809895128011703, "position": 233}, {"animal": "dog", "embedding": -0.034206729382276535, "position": 234}, {"animal": "dog", "embedding": 0.00790240429341793, "position": 235}, {"animal": "dog", "embedding": 0.10791854560375214, "position": 236}, {"animal": "dog", "embedding": 0.009035082533955574, "position": 237}, {"animal": "dog", "embedding": 0.007591914851218462, "position": 238}, {"animal": "dog", "embedding": 0.08858625590801239, "position": 239}, {"animal": "dog", "embedding": 0.0037384198512881994, "position": 240}, {"animal": "dog", "embedding": -0.030471039935946465, "position": 241}, {"animal": "dog", "embedding": 0.021707171574234962, "position": 242}, {"animal": "dog", "embedding": -0.004327238071709871, "position": 243}, {"animal": "dog", "embedding": -0.1447167545557022, "position": 244}, {"animal": "dog", "embedding": 0.011570536531507969, "position": 245}, {"animal": "dog", "embedding": 0.0183675866574049, "position": 246}, {"animal": "dog", "embedding": -0.02585013210773468, "position": 247}, {"animal": "dog", "embedding": -0.051939040422439575, "position": 248}, {"animal": "dog", "embedding": 0.039417412132024765, "position": 249}, {"animal": "dog", "embedding": 0.037535808980464935, "position": 250}, {"animal": "dog", "embedding": -0.014728976413607597, "position": 251}, {"animal": "dog", "embedding": -0.0222414992749691, "position": 252}, {"animal": "dog", "embedding": -0.0487109050154686, "position": 253}, {"animal": "dog", "embedding": -0.006519529037177563, "position": 254}, {"animal": "dog", "embedding": -0.039568811655044556, "position": 255}, {"animal": "dog", "embedding": -0.04127315431833267, "position": 256}, {"animal": "dog", "embedding": -0.028437381610274315, "position": 257}, {"animal": "dog", "embedding": 0.010693822056055069, "position": 258}, {"animal": "dog", "embedding": 0.15860560536384583, "position": 259}, {"animal": "dog", "embedding": 0.04765571281313896, "position": 260}, {"animal": "dog", "embedding": -0.04726944863796234, "position": 261}, {"animal": "dog", "embedding": -0.06290390342473984, "position": 262}, {"animal": "dog", "embedding": 0.00855184905230999, "position": 263}, {"animal": "dog", "embedding": 0.0599067322909832, "position": 264}, {"animal": "dog", "embedding": 0.019311314448714256, "position": 265}, {"animal": "dog", "embedding": -0.03222969174385071, "position": 266}, {"animal": "dog", "embedding": 0.11158391833305359, "position": 267}, {"animal": "dog", "embedding": 0.016122890636324883, "position": 268}, {"animal": "dog", "embedding": 0.052699293941259384, "position": 269}, {"animal": "dog", "embedding": -0.017932994291186333, "position": 270}, {"animal": "dog", "embedding": -0.005921711679548025, "position": 271}, {"animal": "dog", "embedding": 0.05291884392499924, "position": 272}, {"animal": "dog", "embedding": 0.018423588946461678, "position": 273}, {"animal": "dog", "embedding": -0.04744262993335724, "position": 274}, {"animal": "dog", "embedding": -0.01432979479432106, "position": 275}, {"animal": "dog", "embedding": 0.030034014955163002, "position": 276}, {"animal": "dog", "embedding": -0.0733371451497078, "position": 277}, {"animal": "dog", "embedding": -0.012593499384820461, "position": 278}, {"animal": "dog", "embedding": 0.004521314986050129, "position": 279}, {"animal": "dog", "embedding": -0.09498968720436096, "position": 280}, {"animal": "dog", "embedding": 0.01882064901292324, "position": 281}, {"animal": "dog", "embedding": -0.029087064787745476, "position": 282}, {"animal": "dog", "embedding": -0.005304806865751743, "position": 283}, {"animal": "dog", "embedding": -0.002841681009158492, "position": 284}, {"animal": "dog", "embedding": 0.06969695538282394, "position": 285}, {"animal": "dog", "embedding": 0.012458983808755875, "position": 286}, {"animal": "dog", "embedding": 0.1219218447804451, "position": 287}, {"animal": "dog", "embedding": -0.10483532398939133, "position": 288}, {"animal": "dog", "embedding": -0.05372532457113266, "position": 289}, {"animal": "dog", "embedding": -0.012763258069753647, "position": 290}, {"animal": "dog", "embedding": -0.027916932478547096, "position": 291}, {"animal": "dog", "embedding": 0.05001473054289818, "position": 292}, {"animal": "dog", "embedding": -0.07645857334136963, "position": 293}, {"animal": "dog", "embedding": 0.024287302047014236, "position": 294}, {"animal": "dog", "embedding": 0.04536539688706398, "position": 295}, {"animal": "dog", "embedding": -0.02898694947361946, "position": 296}, {"animal": "dog", "embedding": 0.010187732055783272, "position": 297}, {"animal": "dog", "embedding": -0.010616554878652096, "position": 298}, {"animal": "dog", "embedding": 0.031045669689774513, "position": 299}, {"animal": "dog", "embedding": -0.04648565873503685, "position": 300}, {"animal": "dog", "embedding": 0.0045740241184830666, "position": 301}, {"animal": "dog", "embedding": 0.007662663236260414, "position": 302}, {"animal": "dog", "embedding": -0.006381151732057333, "position": 303}, {"animal": "dog", "embedding": -0.07788290828466415, "position": 304}, {"animal": "dog", "embedding": -0.0652913749217987, "position": 305}, {"animal": "dog", "embedding": -0.047676824033260345, "position": 306}, {"animal": "dog", "embedding": 0.010323760099709034, "position": 307}, {"animal": "dog", "embedding": -0.056628257036209106, "position": 308}, {"animal": "dog", "embedding": -0.011250725947320461, "position": 309}, {"animal": "dog", "embedding": 0.0021042958833277225, "position": 310}, {"animal": "dog", "embedding": 0.06386008113622665, "position": 311}, {"animal": "dog", "embedding": -0.013329907320439816, "position": 312}, {"animal": "dog", "embedding": -0.03017304837703705, "position": 313}, {"animal": "dog", "embedding": -0.00982383918017149, "position": 314}, {"animal": "dog", "embedding": 0.054960258305072784, "position": 315}, {"animal": "dog", "embedding": -0.021686753258109093, "position": 316}, {"animal": "dog", "embedding": -0.053316496312618256, "position": 317}, {"animal": "dog", "embedding": -0.028597626835107803, "position": 318}, {"animal": "dog", "embedding": -1.3319516156684585e-08, "position": 319}, {"animal": "dog", "embedding": -0.02869226783514023, "position": 320}, {"animal": "dog", "embedding": -0.029173804447054863, "position": 321}, {"animal": "dog", "embedding": -0.04298397898674011, "position": 322}, {"animal": "dog", "embedding": -0.019562074914574623, "position": 323}, {"animal": "dog", "embedding": 0.09974844008684158, "position": 324}, {"animal": "dog", "embedding": 0.06951721012592316, "position": 325}, {"animal": "dog", "embedding": -0.030107151716947556, "position": 326}, {"animal": "dog", "embedding": -0.040130823850631714, "position": 327}, {"animal": "dog", "embedding": -0.0066306255757808685, "position": 328}, {"animal": "dog", "embedding": 0.026162946596741676, "position": 329}, {"animal": "dog", "embedding": 0.044257305562496185, "position": 330}, {"animal": "dog", "embedding": -0.01636774279177189, "position": 331}, {"animal": "dog", "embedding": -0.07000909000635147, "position": 332}, {"animal": "dog", "embedding": 0.013445564545691013, "position": 333}, {"animal": "dog", "embedding": 0.04655250906944275, "position": 334}, {"animal": "dog", "embedding": -0.01515033096075058, "position": 335}, {"animal": "dog", "embedding": -0.053437650203704834, "position": 336}, {"animal": "dog", "embedding": 0.0398612841963768, "position": 337}, {"animal": "dog", "embedding": 0.0628618523478508, "position": 338}, {"animal": "dog", "embedding": 0.07714782655239105, "position": 339}, {"animal": "dog", "embedding": -0.05102375149726868, "position": 340}, {"animal": "dog", "embedding": 0.030271481722593307, "position": 341}, {"animal": "dog", "embedding": 0.05550659820437431, "position": 342}, {"animal": "dog", "embedding": 0.002205820754170418, "position": 343}, {"animal": "dog", "embedding": -0.051227983087301254, "position": 344}, {"animal": "dog", "embedding": -0.035941120237112045, "position": 345}, {"animal": "dog", "embedding": 0.04560363292694092, "position": 346}, {"animal": "dog", "embedding": 0.10606122761964798, "position": 347}, {"animal": "dog", "embedding": -0.08217952400445938, "position": 348}, {"animal": "dog", "embedding": 0.03809766843914986, "position": 349}, {"animal": "dog", "embedding": -0.022630030289292336, "position": 350}, {"animal": "dog", "embedding": 0.1406117081642151, "position": 351}, {"animal": "dog", "embedding": -0.07618370652198792, "position": 352}, {"animal": "dog", "embedding": -0.030086802318692207, "position": 353}, {"animal": "dog", "embedding": -0.004035626538097858, "position": 354}, {"animal": "dog", "embedding": -0.06968802213668823, "position": 355}, {"animal": "dog", "embedding": 0.07609085738658905, "position": 356}, {"animal": "dog", "embedding": -0.07924934476613998, "position": 357}, {"animal": "dog", "embedding": 0.025034157559275627, "position": 358}, {"animal": "dog", "embedding": 0.034040551632642746, "position": 359}, {"animal": "dog", "embedding": 0.05042510852217674, "position": 360}, {"animal": "dog", "embedding": 0.15210042893886566, "position": 361}, {"animal": "dog", "embedding": -0.02008703164756298, "position": 362}, {"animal": "dog", "embedding": -0.07890965044498444, "position": 363}, {"animal": "dog", "embedding": -0.0005837315693497658, "position": 364}, {"animal": "dog", "embedding": 0.06229373440146446, "position": 365}, {"animal": "dog", "embedding": 0.026448020711541176, "position": 366}, {"animal": "dog", "embedding": -0.12159687280654907, "position": 367}, {"animal": "dog", "embedding": -0.028296884149312973, "position": 368}, {"animal": "dog", "embedding": -0.0564231351017952, "position": 369}, {"animal": "dog", "embedding": -0.09823242574930191, "position": 370}, {"animal": "dog", "embedding": -0.00741284666582942, "position": 371}, {"animal": "dog", "embedding": 0.02790716104209423, "position": 372}, {"animal": "dog", "embedding": 0.06906429678201675, "position": 373}, {"animal": "dog", "embedding": 0.01500491239130497, "position": 374}, {"animal": "dog", "embedding": 0.005070974584668875, "position": 375}, {"animal": "dog", "embedding": -0.013118354603648186, "position": 376}, {"animal": "dog", "embedding": -0.048034701496362686, "position": 377}, {"animal": "dog", "embedding": -0.016735391691327095, "position": 378}, {"animal": "dog", "embedding": 0.03667037561535835, "position": 379}, {"animal": "dog", "embedding": 0.11144455522298813, "position": 380}, {"animal": "dog", "embedding": 0.029856905341148376, "position": 381}, {"animal": "dog", "embedding": 0.02390548773109913, "position": 382}, {"animal": "dog", "embedding": 0.11009308695793152, "position": 383}]}}, {"mode": "vega-lite"});
</script>
</div>
</div>
<aside><div>
<p><a href="https://altair-viz.github.io/gallery/histogram_heatmap.html" class="uri">https://altair-viz.github.io/gallery/histogram_heatmap.html</a></p>
</div></aside></section>
<section class="slide level2 slide-code smaller">
<h2>Let’s reduce the dimensionality.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert embeddings into a 2-dimensional array</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> df_to_reduced(df):</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    reducer <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df.copy().assign(</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        embeddings<span class="op">=</span>reducer.fit_transform(np.stack(df[<span class="st">"embeddings"</span>])).tolist()</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>df_to_reduced(df1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">embeddings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">cat</td>
<td>[-0.41192373633384705, 3.2534185123722636e-08]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">dog</td>
<td>[0.4119238257408142, 3.253417801829528e-08]</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Let’s make a function for a scatterplot.</h2>

<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> altair <span class="im">as</span> alt</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scatterplot(data: pd.DataFrame, tooltips<span class="op">=</span><span class="va">False</span>, labels<span class="op">=</span><span class="va">False</span>, jitter<span class="op">=</span><span class="fl">0.0</span>, width<span class="op">=</span><span class="dv">800</span>, height<span class="op">=</span><span class="dv">200</span>):    </span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">"xJittered"</span>] <span class="op">=</span> data[<span class="st">'x'</span>] <span class="op">+</span> np.random.normal(<span class="dv">0</span>, jitter, size<span class="op">=</span><span class="bu">len</span>(data))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">"yJittered"</span>] <span class="op">=</span> data[<span class="st">'y'</span>] <span class="op">+</span> np.random.normal(<span class="dv">0</span>, jitter, size<span class="op">=</span><span class="bu">len</span>(data))</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    base_chart <span class="op">=</span> (</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        alt.Chart(data).encode(</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>            alt.X(<span class="st">"xJittered"</span>, scale<span class="op">=</span>alt.Scale(zero<span class="op">=</span><span class="va">False</span>), title<span class="op">=</span><span class="va">None</span>),</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>            alt.Y(<span class="st">"yJittered"</span>, scale<span class="op">=</span>alt.Scale(zero<span class="op">=</span><span class="va">False</span>), title<span class="op">=</span><span class="va">None</span>),</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        ).properties(width<span class="op">=</span>width, height<span class="op">=</span>height))</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> tooltips:</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        base_chart <span class="op">=</span> base_chart.encode(alt.Tooltip([<span class="st">"text"</span>]))</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    circles <span class="op">=</span> base_chart.mark_circle(size<span class="op">=</span><span class="dv">200</span>, color<span class="op">=</span><span class="st">"crimson"</span>, stroke<span class="op">=</span><span class="st">"white"</span>, strokeWidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> labels:</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> base_chart.mark_text(fontSize<span class="op">=</span><span class="dv">13</span>,align<span class="op">=</span><span class="st">"left"</span>,baseline<span class="op">=</span><span class="st">"bottom"</span>,dx<span class="op">=</span><span class="dv">5</span>).encode(text<span class="op">=</span><span class="st">"text"</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>        chart <span class="op">=</span> circles <span class="op">+</span> labels</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>        chart <span class="op">=</span> circles</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> chart</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside><div>
<p><a href="https://altair-viz.github.io/gallery/scatter_tooltips.html" class="uri">https://altair-viz.github.io/gallery/scatter_tooltips.html</a></p>
</div></aside></section>
<section class="slide level2 slide-code smaller">
<h2>Let’s display the scatterplot.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df_reduced <span class="op">=</span> df_to_reduced(df1)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>source <span class="op">=</span> pd.DataFrame({</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>: df_reduced.index,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"x"</span>: df_reduced[<span class="st">"embeddings"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="dv">0</span>]).to_list(),</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"y"</span>: df_reduced[<span class="st">"embeddings"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="dv">1</span>]).to_list(),</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>scatterplot(source, labels<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">

<style>
  #altair-viz-1f4617322ddd4488882d998324cac0cf.vega-embed {
    width: 100%;
    display: flex;
  }

  #altair-viz-1f4617322ddd4488882d998324cac0cf.vega-embed details,
  #altair-viz-1f4617322ddd4488882d998324cac0cf.vega-embed details summary {
    position: relative;
  }
</style>
<div id="altair-viz-1f4617322ddd4488882d998324cac0cf"></div>
<script type="text/javascript">
  var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-1f4617322ddd4488882d998324cac0cf") {
      outputDiv = document.getElementById("altair-viz-1f4617322ddd4488882d998324cac0cf");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm/vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm/vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm/vega-embed@6?noext",
    };

    function maybeLoadScript(lib, version) {
      var key = `${lib.replace("-", "")}_version`;
      return (VEGA_DEBUG[key] == version) ?
        Promise.resolve(paths[lib]) :
        new Promise(function(resolve, reject) {
          var s = document.createElement('script');
          document.getElementsByTagName("head")[0].appendChild(s);
          s.async = true;
          s.onload = () => {
            VEGA_DEBUG[key] = version;
            return resolve(paths[lib]);
          };
          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
          s.src = paths[lib];
        });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else {
      maybeLoadScript("vega", "5")
        .then(() => maybeLoadScript("vega-lite", "5.8.0"))
        .then(() => maybeLoadScript("vega-embed", "6"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 300, "continuousHeight": 300}}, "layer": [{"mark": {"type": "circle", "color": "crimson", "size": 200, "stroke": "white", "strokeWidth": 1}, "encoding": {"x": {"field": "xJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}, "y": {"field": "yJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}}}, {"mark": {"type": "text", "align": "left", "baseline": "bottom", "dx": 5, "fontSize": 13}, "encoding": {"text": {"field": "text", "type": "nominal"}, "x": {"field": "xJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}, "y": {"field": "yJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}}}], "data": {"name": "data-578732e8a3d570527720372f0c2b0d12"}, "height": 200, "width": 800, "$schema": "https://vega.github.io/schema/vega-lite/v5.8.0.json", "datasets": {"data-578732e8a3d570527720372f0c2b0d12": [{"text": "cat", "x": -0.41192373633384705, "y": 3.2534185123722636e-08, "xJittered": -0.41192373633384705, "yJittered": 3.2534185123722636e-08}, {"text": "dog", "x": 0.4119238257408142, "y": 3.253417801829528e-08, "xJittered": 0.4119238257408142, "yJittered": 3.253417801829528e-08}]}}, {"mode": "vega-lite"});
</script>
</div>
</div>
</section>
<section class="slide level2 slide-code">
<h2>Let’s add some more words.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> [<span class="st">"cat"</span>, <span class="st">"dog"</span>, <span class="st">"pizza"</span>, <span class="st">"coffee"</span>, <span class="st">"asymptomatic"</span>]</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.DataFrame(</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    [  [model1.encode(word)]  <span class="cf">for</span> word <span class="kw">in</span> words ],</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>words, columns<span class="op">=</span>[<span class="st">"embeddings"</span>])</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>df2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">embeddings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">cat</td>
<td>[0.03733039, 0.0511619, -0.00030606816, 0.0602...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">dog</td>
<td>[-0.05314704, 0.014194381, 0.0071458234, 0.068...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">pizza</td>
<td>[-0.08696939, 0.06991054, -0.0150973685, 0.096...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">coffee</td>
<td>[-0.03095191, 0.018730178, 0.014911181, 0.1197...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">asymptomatic</td>
<td>[0.031974357, 0.020842418, -0.064985596, 0.171...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Let’s try the scatterplot again.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>df_reduced <span class="op">=</span> df_to_reduced(df2)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>source <span class="op">=</span> pd.DataFrame({</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>: df_reduced.index,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"x"</span>: df_reduced[<span class="st">"embeddings"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="dv">0</span>]).to_list(),</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"y"</span>: df_reduced[<span class="st">"embeddings"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="dv">1</span>]).to_list(),</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>scatterplot(source, labels<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">

<style>
  #altair-viz-d1d0fc22c7f5428490ab841908d683dc.vega-embed {
    width: 100%;
    display: flex;
  }

  #altair-viz-d1d0fc22c7f5428490ab841908d683dc.vega-embed details,
  #altair-viz-d1d0fc22c7f5428490ab841908d683dc.vega-embed details summary {
    position: relative;
  }
</style>
<div id="altair-viz-d1d0fc22c7f5428490ab841908d683dc"></div>
<script type="text/javascript">
  var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-d1d0fc22c7f5428490ab841908d683dc") {
      outputDiv = document.getElementById("altair-viz-d1d0fc22c7f5428490ab841908d683dc");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm/vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm/vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm/vega-embed@6?noext",
    };

    function maybeLoadScript(lib, version) {
      var key = `${lib.replace("-", "")}_version`;
      return (VEGA_DEBUG[key] == version) ?
        Promise.resolve(paths[lib]) :
        new Promise(function(resolve, reject) {
          var s = document.createElement('script');
          document.getElementsByTagName("head")[0].appendChild(s);
          s.async = true;
          s.onload = () => {
            VEGA_DEBUG[key] = version;
            return resolve(paths[lib]);
          };
          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
          s.src = paths[lib];
        });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else {
      maybeLoadScript("vega", "5")
        .then(() => maybeLoadScript("vega-lite", "5.8.0"))
        .then(() => maybeLoadScript("vega-embed", "6"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 300, "continuousHeight": 300}}, "layer": [{"mark": {"type": "circle", "color": "crimson", "size": 200, "stroke": "white", "strokeWidth": 1}, "encoding": {"x": {"field": "xJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}, "y": {"field": "yJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}}}, {"mark": {"type": "text", "align": "left", "baseline": "bottom", "dx": 5, "fontSize": 13}, "encoding": {"text": {"field": "text", "type": "nominal"}, "x": {"field": "xJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}, "y": {"field": "yJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}}}], "data": {"name": "data-2cb5df878dff5a80c27a57291ca30c15"}, "height": 200, "width": 800, "$schema": "https://vega.github.io/schema/vega-lite/v5.8.0.json", "datasets": {"data-2cb5df878dff5a80c27a57291ca30c15": [{"text": "cat", "x": -0.32588061690330505, "y": -0.33052384853363037, "xJittered": -0.32588061690330505, "yJittered": -0.33052384853363037}, {"text": "dog", "x": -0.34687429666519165, "y": -0.4468518793582916, "xJittered": -0.34687429666519165, "yJittered": -0.4468518793582916}, {"text": "pizza", "x": -0.06750805675983429, "y": 0.4830458164215088, "xJittered": -0.06750805675983429, "yJittered": 0.4830458164215088}, {"text": "coffee", "x": -0.13563542068004608, "y": 0.48234328627586365, "xJittered": -0.13563542068004608, "yJittered": 0.48234328627586365}, {"text": "asymptomatic", "x": 0.8758982419967651, "y": -0.18801316618919373, "xJittered": 0.8758982419967651, "yJittered": -0.18801316618919373}]}}, {"mode": "vega-lite"});
</script>
</div>
</div>
</section>
<section class="slide level2 text-white quote-italic" data-background="#718096">
<h2>The Theory of Language</h2>
<h4>Ferdinand de Saussure, <em>Course in General Linguistics</em> <small>(1916)</small></h4>
<div class="columns">
<div class="column" style="width:20%;">
<p><img data-src="assets/saussure-course.png" class="border" style="background-color: #fff; border: 2px solid #fff; border-radius: 5px;" width="250"></p>
</div><div class="column" style="width:80%;">
<p>Language is a system of signs</p>
<p>Signs represent concepts, not things</p>
<p>The nature of the sign is arbitrary</p>
<blockquote>
<p>(…) what is natural to mankind is not oral speech but the faculty of constructing a&nbsp;language, i.e.&nbsp;a system of distinct signs corresponding to distinct ideas.</p>
</blockquote>
</div>
</div>
</section>
<section class="slide level2 slide-code">
<h2>Let’s try a word in a different language.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>word <span class="op">=</span> <span class="st">"kočka"</span> <span class="co"># "Cat" in Czech [ˈkot͡ʃka]</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> pd.concat([</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  df2, </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  pd.DataFrame.from_dict({<span class="st">"embeddings"</span>: { word: model1.encode(word)}}),</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>df3.loc[[<span class="st">"cat"</span>, <span class="st">"kočka"</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">embeddings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">cat</td>
<td>[0.03733039, 0.0511619, -0.00030606816, 0.0602...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">kočka</td>
<td>[-0.05706705, 0.041157562, -0.10440424, 0.0499...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Let’s try the scatterplot again.</h2>

<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>df_reduced <span class="op">=</span> df_to_reduced(df3)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>source <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>: df_reduced.index,</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"x"</span>: df_reduced[<span class="st">"embeddings"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="dv">0</span>]).to_list(),</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"y"</span>: df_reduced[<span class="st">"embeddings"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="dv">1</span>]).to_list(),</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>scatterplot(source, labels<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">

<style>
  #altair-viz-190865af092a402090a9359b0ed94090.vega-embed {
    width: 100%;
    display: flex;
  }

  #altair-viz-190865af092a402090a9359b0ed94090.vega-embed details,
  #altair-viz-190865af092a402090a9359b0ed94090.vega-embed details summary {
    position: relative;
  }
</style>
<div id="altair-viz-190865af092a402090a9359b0ed94090"></div>
<script type="text/javascript">
  var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-190865af092a402090a9359b0ed94090") {
      outputDiv = document.getElementById("altair-viz-190865af092a402090a9359b0ed94090");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm/vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm/vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm/vega-embed@6?noext",
    };

    function maybeLoadScript(lib, version) {
      var key = `${lib.replace("-", "")}_version`;
      return (VEGA_DEBUG[key] == version) ?
        Promise.resolve(paths[lib]) :
        new Promise(function(resolve, reject) {
          var s = document.createElement('script');
          document.getElementsByTagName("head")[0].appendChild(s);
          s.async = true;
          s.onload = () => {
            VEGA_DEBUG[key] = version;
            return resolve(paths[lib]);
          };
          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
          s.src = paths[lib];
        });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else {
      maybeLoadScript("vega", "5")
        .then(() => maybeLoadScript("vega-lite", "5.8.0"))
        .then(() => maybeLoadScript("vega-embed", "6"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 300, "continuousHeight": 300}}, "layer": [{"mark": {"type": "circle", "color": "crimson", "size": 200, "stroke": "white", "strokeWidth": 1}, "encoding": {"x": {"field": "xJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}, "y": {"field": "yJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}}}, {"mark": {"type": "text", "align": "left", "baseline": "bottom", "dx": 5, "fontSize": 13}, "encoding": {"text": {"field": "text", "type": "nominal"}, "x": {"field": "xJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}, "y": {"field": "yJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}}}], "data": {"name": "data-6171aac72a7c711c361561855e4b9b0a"}, "height": 200, "width": 800, "$schema": "https://vega.github.io/schema/vega-lite/v5.8.0.json", "datasets": {"data-6171aac72a7c711c361561855e4b9b0a": [{"text": "cat", "x": -0.39272603392601013, "y": -0.3096916079521179, "xJittered": -0.39272603392601013, "yJittered": -0.3096916079521179}, {"text": "dog", "x": -0.42169713973999023, "y": -0.42202842235565186, "xJittered": -0.42169713973999023, "yJittered": -0.42202842235565186}, {"text": "pizza", "x": -0.13226890563964844, "y": 0.3904246687889099, "xJittered": -0.13226890563964844, "yJittered": 0.3904246687889099}, {"text": "coffee", "x": -0.16058528423309326, "y": 0.447518527507782, "xJittered": -0.16058528423309326, "yJittered": 0.447518527507782}, {"text": "asymptomatic", "x": 0.7457429766654968, "y": -0.3583552837371826, "xJittered": 0.7457429766654968, "yJittered": -0.3583552837371826}, {"text": "ko\u010dka", "x": 0.36153465509414673, "y": 0.25213193893432617, "xJittered": 0.36153465509414673, "yJittered": 0.25213193893432617}]}}, {"mode": "vega-lite"});
</script>
</div>
</div>
<aside><div>
<p>The model has been trained on English text only.</p>
</div></aside></section>
<section class="slide level2 slide-code">
<h2>Let’s try with a different model.</h2>
<p><a href="https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"><img data-src="assets/logo-huggingface.svg" class="icon" width="40" height="40"> <code>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2</code></a></p>

<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> SentenceTransformer(<span class="st">"paraphrase-multilingual-MiniLM-L12-v2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside><div>
<p>A model trained on parallel data for more than 50 languages. <small><a href="https://www.sbert.net/docs/pretrained_models.html#multi-lingual-models" class="uri">https://www.sbert.net/docs/pretrained_models.html#multi-lingual-models</a></small></p>
</div></aside></section>
<section class="slide level2 slide-code smaller">
<h2>Let’s create the embeddings with the new model.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> df3.index.to_list()</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>df4 <span class="op">=</span> pd.DataFrame(</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    [  [model2.encode(word)] <span class="cf">for</span> word <span class="kw">in</span> words ],</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>words, columns<span class="op">=</span>[<span class="st">"embeddings"</span>])</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>df4</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">embeddings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">cat</td>
<td>[0.59055364, -0.3334293, -0.03257506, 0.543022...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">dog</td>
<td>[0.280045, -0.24335869, -0.25790253, 0.1898756...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">pizza</td>
<td>[-0.31320187, -0.17622907, -0.17177011, -0.066...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">coffee</td>
<td>[-0.19748689, -0.38310185, -0.1273405, 0.75054...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">asymptomatic</td>
<td>[0.05101946, -0.042016577, -0.04529487, 0.4346...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">kočka</td>
<td>[0.5026489, -0.23199998, -0.008454391, 0.48297...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>… and let’s try the scatterplot again.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>df_reduced <span class="op">=</span> df_to_reduced(df4)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>source <span class="op">=</span> pd.DataFrame({</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>: df_reduced.index,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"x"</span>: df_reduced[<span class="st">"embeddings"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="dv">0</span>]).to_list(),</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"y"</span>: df_reduced[<span class="st">"embeddings"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="dv">1</span>]).to_list(),</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>scatterplot(source, labels<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">

<style>
  #altair-viz-9c776296684841eca4f4970aae948675.vega-embed {
    width: 100%;
    display: flex;
  }

  #altair-viz-9c776296684841eca4f4970aae948675.vega-embed details,
  #altair-viz-9c776296684841eca4f4970aae948675.vega-embed details summary {
    position: relative;
  }
</style>
<div id="altair-viz-9c776296684841eca4f4970aae948675"></div>
<script type="text/javascript">
  var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-9c776296684841eca4f4970aae948675") {
      outputDiv = document.getElementById("altair-viz-9c776296684841eca4f4970aae948675");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm/vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm/vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm/vega-embed@6?noext",
    };

    function maybeLoadScript(lib, version) {
      var key = `${lib.replace("-", "")}_version`;
      return (VEGA_DEBUG[key] == version) ?
        Promise.resolve(paths[lib]) :
        new Promise(function(resolve, reject) {
          var s = document.createElement('script');
          document.getElementsByTagName("head")[0].appendChild(s);
          s.async = true;
          s.onload = () => {
            VEGA_DEBUG[key] = version;
            return resolve(paths[lib]);
          };
          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
          s.src = paths[lib];
        });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else {
      maybeLoadScript("vega", "5")
        .then(() => maybeLoadScript("vega-lite", "5.8.0"))
        .then(() => maybeLoadScript("vega-embed", "6"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 300, "continuousHeight": 300}}, "layer": [{"mark": {"type": "circle", "color": "crimson", "size": 200, "stroke": "white", "strokeWidth": 1}, "encoding": {"x": {"field": "xJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}, "y": {"field": "yJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}}}, {"mark": {"type": "text", "align": "left", "baseline": "bottom", "dx": 5, "fontSize": 13}, "encoding": {"text": {"field": "text", "type": "nominal"}, "x": {"field": "xJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}, "y": {"field": "yJittered", "scale": {"zero": false}, "title": null, "type": "quantitative"}}}], "data": {"name": "data-d19523b67ae6520b5dc9f944ca01a3f0"}, "height": 200, "width": 800, "$schema": "https://vega.github.io/schema/vega-lite/v5.8.0.json", "datasets": {"data-d19523b67ae6520b5dc9f944ca01a3f0": [{"text": "cat", "x": -3.484766960144043, "y": 1.4733586311340332, "xJittered": -3.484766960144043, "yJittered": 1.4733586311340332}, {"text": "dog", "x": -0.44105127453804016, "y": -3.348930597305298, "xJittered": -0.44105127453804016, "yJittered": -3.348930597305298}, {"text": "pizza", "x": 3.5124003887176514, "y": 3.8346683979034424, "xJittered": 3.5124003887176514, "yJittered": 3.8346683979034424}, {"text": "coffee", "x": 3.1995232105255127, "y": -1.5098546743392944, "xJittered": 3.1995232105255127, "yJittered": -1.5098546743392944}, {"text": "asymptomatic", "x": 0.41154372692108154, "y": -1.778046727180481, "xJittered": 0.41154372692108154, "yJittered": -1.778046727180481}, {"text": "ko\u010dka", "x": -3.197653293609619, "y": 1.3288077116012573, "xJittered": -3.197653293609619, "yJittered": 1.3288077116012573}]}}, {"mode": "vega-lite"});
</script>
</div>
</div>
</section>


<section class="slide level2 slide-code smaller">
<h2>Let’s compute similarity between a query and the other words.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell columns column-output-location" data-execution_count="19">
<div class="column">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="op">\</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> cosine_similarity</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"cat"</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>query_emb <span class="op">=</span> model2.encode(query)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>similarities <span class="op">=</span> {}</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> word, embeddings <span class="kw">in</span> df4[<span class="st">"embeddings"</span>].items():</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># query vector ⇔ word vector</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    similarities[word] <span class="op">=</span> cosine_similarity(</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>        [query_emb], </span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>        [embeddings]</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>      )[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the similarities</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>  pd.DataFrame({</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Word"</span>: [<span class="ss">f"</span><span class="sc">{</span>query<span class="sc">}</span><span class="ss"> ⇔ </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> k <span class="kw">in</span> similarities.keys()], </span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Similarity"</span>: similarities.values()</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>  .sort_values(by<span class="op">=</span>[<span class="st">"Similarity"</span>], ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>  .style</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    .hide(axis<span class="op">=</span><span class="st">"index"</span>)</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>    .set_table_attributes(<span class="st">'class="dataframe"'</span>)</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>    .bar(subset<span class="op">=</span>[<span class="st">'Similarity'</span>], color<span class="op">=</span><span class="st">'#999'</span>)</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output cell-output-display" data-execution_count="19">
<style type="text/css">
#T_79604_row0_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 100.0%, transparent 100.0%);
}
#T_79604_row1_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 98.4%, transparent 98.4%);
}
#T_79604_row2_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 30.3%, transparent 30.3%);
}
#T_79604_row3_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 25.1%, transparent 25.1%);
}
#T_79604_row4_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 21.0%, transparent 21.0%);
}
#T_79604_row5_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 11.3%, transparent 11.3%);
}
</style>

<table id="T_79604" class="dataframe" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th id="T_79604_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Word</th>
<th id="T_79604_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">Similarity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_79604_row0_col0" class="data row0 col0">cat ⇔ cat</td>
<td id="T_79604_row0_col1" class="data row0 col1">1.000000</td>
</tr>
<tr class="even">
<td id="T_79604_row1_col0" class="data row1 col0">cat ⇔ kočka</td>
<td id="T_79604_row1_col1" class="data row1 col1">0.983700</td>
</tr>
<tr class="odd">
<td id="T_79604_row2_col0" class="data row2 col0">cat ⇔ dog</td>
<td id="T_79604_row2_col1" class="data row2 col1">0.303288</td>
</tr>
<tr class="even">
<td id="T_79604_row3_col0" class="data row3 col0">cat ⇔ pizza</td>
<td id="T_79604_row3_col1" class="data row3 col1">0.250888</td>
</tr>
<tr class="odd">
<td id="T_79604_row4_col0" class="data row4 col0">cat ⇔ coffee</td>
<td id="T_79604_row4_col1" class="data row4 col1">0.209838</td>
</tr>
<tr class="even">
<td id="T_79604_row5_col0" class="data row5 col0">cat ⇔ asymptomatic</td>
<td id="T_79604_row5_col1" class="data row5 col1">0.112521</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section class="slide level2 slide-code slide-code-wide slide-grey smaller" data-background="#718096">
<h2>What is “cosine similarity”?</h2>
<div class="cell columns column-output-location" data-execution_count="386">
<div class="column">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>A, B, C <span class="op">=</span> np.array([<span class="dv">6</span>,<span class="dv">7</span>]), np.array([<span class="dv">8</span>,<span class="dv">9</span>]), np.array([<span class="dv">2</span>,<span class="dv">10</span>])</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Stack vectors into a single matrix</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>vectors <span class="op">=</span> np.vstack([A, B, C])</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vectors)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate cosine similarity matrix</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>cos_sim_matrix <span class="op">=</span> cosine_similarity(vectors)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate angles in degrees</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>theta_AB <span class="op">=</span> np.arccos(cos_sim_matrix[<span class="dv">0</span>, <span class="dv">1</span>]) <span class="op">*</span> (<span class="dv">180</span> <span class="op">/</span> np.pi)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>theta_AC <span class="op">=</span> np.arccos(cos_sim_matrix[<span class="dv">0</span>, <span class="dv">2</span>]) <span class="op">*</span> (<span class="dv">180</span> <span class="op">/</span> np.pi)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Origin coordinates</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>origin <span class="op">=</span> np.zeros((<span class="dv">3</span>, <span class="dv">2</span>))</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the "quiver" chart</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Cosine Similarity For Vectors A, B, C"</span>)</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>plt.quiver(origin[:, <span class="dv">0</span>], origin[:, <span class="dv">1</span>], vectors[:, <span class="dv">0</span>], vectors[:, <span class="dv">1</span>], </span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>           angles<span class="op">=</span><span class="st">'xy'</span>, scale_units<span class="op">=</span><span class="st">'xy'</span>, scale<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span>[<span class="st">'r'</span>, <span class="st">'g'</span>, <span class="st">'b'</span>])</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="op">-</span><span class="dv">1</span>, <span class="dv">11</span>)</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="op">-</span><span class="dv">1</span>, <span class="dv">11</span>)</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"X-axis"</span>)</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Y-axis"</span>)</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>plt.text(A[<span class="dv">0</span>], A[<span class="dv">1</span>], <span class="st">'A'</span>, color<span class="op">=</span><span class="st">'black'</span>, fontsize<span class="op">=</span><span class="dv">24</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>plt.text(B[<span class="dv">0</span>], B[<span class="dv">1</span>], <span class="st">'B'</span>, color<span class="op">=</span><span class="st">'black'</span>, fontsize<span class="op">=</span><span class="dv">24</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>plt.text(C[<span class="dv">0</span>], C[<span class="dv">1</span>], <span class="st">'C'</span>, color<span class="op">=</span><span class="st">'black'</span>, fontsize<span class="op">=</span><span class="dv">24</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>plt.text(A[<span class="dv">0</span>] <span class="op">/</span> <span class="fl">2.5</span>, A[<span class="dv">1</span>] <span class="op">/</span> <span class="fl">2.5</span>, <span class="ss">f'</span><span class="sc">{</span>theta_AB<span class="sc">:.2f}</span><span class="ss">°'</span>, color<span class="op">=</span><span class="st">'black'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, ha<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>plt.text(A[<span class="dv">0</span>] <span class="op">/</span> <span class="fl">2.5</span>, A[<span class="dv">1</span>] <span class="op">/</span> <span class="fl">1.5</span>, <span class="ss">f'</span><span class="sc">{</span>theta_AC<span class="sc">:.2f}</span><span class="ss">°'</span>, color<span class="op">=</span><span class="st">'black'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, ha<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output cell-output-stdout">
<pre><code>[[ 6  7]
 [ 8  9]
 [ 2 10]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img data-src="library-and-maze-czpycon2023_files/figure-revealjs/cell-25-output-2.png"></p>
</div>
</div>
</div>
</section>
<section class="slide level2 slide-code">
<h2>Let’s do “word arithmetics”.</h2>
<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> [<span class="st">"king"</span>, <span class="st">"man"</span>, <span class="st">"woman"</span>, <span class="st">"queen"</span>, <span class="st">"saxophone"</span>]</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>df6 <span class="op">=</span> pd.DataFrame(</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    [ [model2.encode(word)] <span class="cf">for</span> word <span class="kw">in</span> words ],</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>words, columns<span class="op">=</span>[<span class="st">"embeddings"</span>])</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>df6</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">embeddings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">king</td>
<td>[-0.009882803, 0.6362919, -0.105976604, -0.097...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">man</td>
<td>[-0.0053758374, 0.26451156, -0.1168356, -0.215...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">woman</td>
<td>[0.17876714, -0.28030494, -0.008455522, 0.4727...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">queen</td>
<td>[0.36926943, -0.03183403, 0.13288921, 0.218695...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">saxophone</td>
<td>[0.09851525, 0.36520788, 0.004772159, -0.50931...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2><code>king - man + woman = ?</code></h2>

<div class="footer">
<p>➊ What Are Text Embeddings?</p>
</div>
<div class="cell columns column-output-location" data-execution_count="312">
<div class="column">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> (</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  df6.loc[<span class="st">"king"</span>][<span class="st">"embeddings"</span>]</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="op">-</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  df6.loc[<span class="st">"man"</span>][<span class="st">"embeddings"</span>]</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="op">+</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  df6.loc[<span class="st">"woman"</span>][<span class="st">"embeddings"</span>])</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Result:"</span>, <span class="bu">list</span>(result[:<span class="dv">3</span>]) <span class="op">+</span> [<span class="st">"..."</span>])</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>similarities <span class="op">=</span> {}</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> word, embeddings <span class="kw">in</span> df6[<span class="st">"embeddings"</span>].items():</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># result vector ⇔ word vector</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>  similarities[word] <span class="op">=</span> <span class="op">\</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    cosine_similarity([result], [embeddings])[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the similarities</span></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>  pd.DataFrame({</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Word"</span>: similarities.keys(), </span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Similarity"</span>: similarities.values()</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>  .sort_values(by<span class="op">=</span>[<span class="st">"Similarity"</span>], ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>  .style</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>    .hide(axis<span class="op">=</span><span class="st">"index"</span>)</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>    .set_table_attributes(<span class="st">'class="dataframe"'</span>)</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>    .bar(subset<span class="op">=</span>[<span class="st">'Similarity'</span>], color<span class="op">=</span><span class="st">'#999'</span>)</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output cell-output-stdout">
<pre><code>Result: [0.17426018, 0.09147543, 0.0024034753, '...']</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="312">
<style type="text/css">
#T_57936_row0_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 100.0%, transparent 100.0%);
}
#T_57936_row1_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 85.5%, transparent 85.5%);
}
#T_57936_row2_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 80.9%, transparent 80.9%);
}
#T_57936_row3_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 25.9%, transparent 25.9%);
}
#T_57936_row4_col1 {
  width: 10em;
  background: linear-gradient(90deg, #999 17.9%, transparent 17.9%);
}
</style>

<table id="T_57936" class="dataframe" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th id="T_57936_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Word</th>
<th id="T_57936_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">Similarity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_57936_row0_col0" class="data row0 col0">queen</td>
<td id="T_57936_row0_col1" class="data row0 col1">0.790001</td>
</tr>
<tr class="even">
<td id="T_57936_row1_col0" class="data row1 col0">king</td>
<td id="T_57936_row1_col1" class="data row1 col1">0.675087</td>
</tr>
<tr class="odd">
<td id="T_57936_row2_col0" class="data row2 col0">woman</td>
<td id="T_57936_row2_col1" class="data row2 col1">0.639414</td>
</tr>
<tr class="even">
<td id="T_57936_row3_col0" class="data row3 col0">saxophone</td>
<td id="T_57936_row3_col1" class="data row3 col1">0.204697</td>
</tr>
<tr class="odd">
<td id="T_57936_row4_col0" class="data row4 col0">man</td>
<td id="T_57936_row4_col1" class="data row4 col1">0.141279</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<aside><div>
<p><a href="http://jalammar.github.io/illustrated-word2vec" class="uri">http://jalammar.github.io/illustrated-word2vec</a></p>
</div></aside></section>

<section class="slide level2 center" data-background="#dc143c">
<h2>➋ Semantic search</h2>
</section>
<section class="slide level2">
<h2>Semantic search</h2>
<p><em>Lexical</em> search <small>(TF-IDF, BM25, …)</small></p>
<p><em>Semantic</em> search: text embeddings and similarity</p>
<p>Meaning (“dimensions”), not terms</p>
<p>(Approximate) “Nearest Neighbors” algorithm</p>

<div class="footer">
<p>➋ Semantic search</p>
</div>
<aside><div>
<p><a href="https://txt.cohere.com/what-is-semantic-search/" class="uri">https://txt.cohere.com/what-is-semantic-search/</a></p>
</div></aside></section>
<section class="slide level2 slide-code slide-code-wide smaller">
<h2>Nearest Neighbors with <code>scikit-learn</code></h2>
<div class="footer">
<p>➋ Semantic search</p>
</div>
<div class="cell columns column-output-location" data-execution_count="306">
<div class="column">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> NearestNeighbors</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the model</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>nn <span class="op">=</span> NearestNeighbors(n_neighbors<span class="op">=</span><span class="bu">len</span>(df6[<span class="st">"embeddings"</span>]))</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Store the embeddings for efficient lookup</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>nn.fit(df2[<span class="st">"embeddings"</span>].tolist())</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the search query</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"food"</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>query_embedding <span class="op">=</span> np.array([model1.encode(query)])</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare query vector to every vector in the dataset</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>distances, indices <span class="op">=</span> nn.kneighbors(query_embedding)</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize the distances to [0-1]</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>normalized_distances <span class="op">=</span> scaler.fit_transform(distances.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the results</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>(pd.DataFrame({</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"word"</span>: df2.index[indices.flatten()],</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"distance"</span>: normalized_distances.flatten(),</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a> .style</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>    .hide(axis<span class="op">=</span><span class="st">"index"</span>)</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>    .set_table_attributes(<span class="st">'class="dataframe align-left"'</span>)</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>    .set_caption(<span class="ss">f"Query: </span><span class="sc">{</span>query<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>    .background_gradient(subset<span class="op">=</span>[<span class="st">"distance"</span>], cmap<span class="op">=</span><span class="st">"Greys"</span>, ))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output cell-output-display" data-execution_count="306">
<style type="text/css">
#T_150e2_row0_col1 {
  background-color: #ffffff;
  color: #000000;
}
#T_150e2_row1_col1 {
  background-color: #d3d3d3;
  color: #000000;
}
#T_150e2_row2_col1 {
  background-color: #c1c1c1;
  color: #000000;
}
#T_150e2_row3_col1 {
  background-color: #a0a0a0;
  color: #f1f1f1;
}
#T_150e2_row4_col1 {
  background-color: #000000;
  color: #f1f1f1;
}
</style>

<table id="T_150e2" class="dataframe align-left" data-quarto-postprocess="true">
<caption>Query: food</caption>
<thead>
<tr class="header">
<th id="T_150e2_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">word</th>
<th id="T_150e2_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">distance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_150e2_row0_col0" class="data row0 col0">pizza</td>
<td id="T_150e2_row0_col1" class="data row0 col1">0.000000</td>
</tr>
<tr class="even">
<td id="T_150e2_row1_col0" class="data row1 col0">coffee</td>
<td id="T_150e2_row1_col1" class="data row1 col1">0.279945</td>
</tr>
<tr class="odd">
<td id="T_150e2_row2_col0" class="data row2 col0">dog</td>
<td id="T_150e2_row2_col1" class="data row2 col1">0.355471</td>
</tr>
<tr class="even">
<td id="T_150e2_row3_col0" class="data row3 col0">cat</td>
<td id="T_150e2_row3_col1" class="data row3 col1">0.465242</td>
</tr>
<tr class="odd">
<td id="T_150e2_row4_col0" class="data row4 col0">asymptomatic</td>
<td id="T_150e2_row4_col1" class="data row4 col1">1.000000</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>

<section class="slide level2">
<h2>Nearest Neighbors with <em>Annoy</em></h2>
<ol type="1">
<li>Download data from <a href="https://coffee.stackexchange.com">coffee.stackexchange.com</a></li>
<li>Extract post titles from XML into Pandas’ dataframe</li>
<li>Compute the text embeddings</li>
<li>Build the <em>Annoy</em> index</li>
<li>Search the index</li>
</ol>

<div class="footer">
<p>➋ Semantic search</p>
</div>
<aside><div>
<p><a href="https://github.com/spotify/annoy" class="uri">https://github.com/spotify/annoy</a></p>
<p><a href="https://github.com/erikbern/ann-presentation" class="uri">https://github.com/erikbern/ann-presentation</a></p>
</div></aside></section>

<section class="slide level2 slide-code slide-code-wide smaller">
<h2>Extract Titles from XML into a DataFrame</h2>
<div class="footer">
<p>➋ Semantic search</p>
</div>
<div class="cell columns column-output-location" data-execution_count="438">
<div class="column">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> py7zr <span class="im">import</span> SevenZipFile <span class="im">as</span> <span class="bu">zip</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>xml_file <span class="op">=</span> <span class="st">"Posts.xml"</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>dest <span class="op">=</span> tempfile.TemporaryDirectory().name</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the file with posts</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">zip</span>(input_file_path, <span class="st">"r"</span>) <span class="im">as</span> archive:</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    archive.extract(targets<span class="op">=</span>[xml_file], path<span class="op">=</span>dest)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Read XML into a dataframe</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_xml(os.path.join(dest, xml_file), xpath<span class="op">=</span><span class="st">"//row"</span>)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep only 'Title' column and rename to 'text'</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[[<span class="st">"Title"</span>]].dropna().rename(columns<span class="op">=</span>{<span class="st">"Title"</span>: <span class="st">"text"</span>})</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>display(df.head(<span class="dv">5</span>).style.hide(axis<span class="op">=</span><span class="st">"index"</span>))</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>df<span class="sc">.</span>size<span class="sc">}</span><span class="ss"> rows"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output cell-output-display">
<style type="text/css">
</style>

<table id="T_703bc" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th id="T_703bc_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_703bc_row0_col0" class="data row0 col0">How should I store whole bean coffee?</td>
</tr>
<tr class="even">
<td id="T_703bc_row1_col0" class="data row1 col0">How fine should I grind coffee for drip/pour over coffee</td>
</tr>
<tr class="odd">
<td id="T_703bc_row2_col0" class="data row2 col0">Does the hardness of water matter when making coffee?</td>
</tr>
<tr class="even">
<td id="T_703bc_row3_col0" class="data row3 col0">What's the theory behind using thin spouted kettles when making drip/pour over coffee</td>
</tr>
<tr class="odd">
<td id="T_703bc_row4_col0" class="data row4 col0">How important is tamping coffee for an espresso machine</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>1450 rows</code></pre>
</div>
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Compute the Text Embeddings</h2>
<div class="footer">
<p>➋ Semantic search</p>
</div>
<div class="cell" data-execution_count="439">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SentenceTransformer(<span class="st">"paraphrase-multilingual-MiniLM-L12-v2"</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Register progress bar</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>tqdm.pandas(desc<span class="op">=</span><span class="st">"Process"</span>)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute embeddings</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"embeddings"</span>] <span class="op">=</span> df[<span class="st">"text"</span>].progress_apply( <span class="kw">lambda</span> x: model.encode(x) )</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>df.head(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="439">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">embeddings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>How should I store whole bean coffee?</td>
<td>[-0.4377262, 0.14942853, -0.16667569, 0.167280...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>How fine should I grind coffee for drip/pour o...</td>
<td>[-0.24292755, -0.36047038, 0.0934966, 0.396481...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Does the hardness of water matter when making ...</td>
<td>[-0.11959872, -0.2570504, 0.18188146, 0.378879...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 slide-code">
<h2>Build the Index</h2>
<div class="footer">
<p>➋ Semantic search</p>
</div>
<div class="cell" data-execution_count="440">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> annoy <span class="im">import</span> AnnoyIndex</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> df[<span class="st">"embeddings"</span>][<span class="dv">0</span>].size  <span class="co"># Vector dimensions</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> AnnoyIndex(f, <span class="st">"angular"</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, vector <span class="kw">in</span> <span class="bu">enumerate</span>(df[<span class="st">"embeddings"</span>]):</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    t.add_item(i, vector)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>t.build(<span class="dv">10</span>)  <span class="co"># 10 trees</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>t.save(os.path.join(<span class="st">"tmp"</span>, <span class="st">"coffee.ann"</span>))</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Built index with [</span><span class="sc">{</span>df<span class="sc">.</span>embeddings<span class="sc">.</span>size<span class="sc">}</span><span class="ss">] items and [</span><span class="sc">{</span>f<span class="sc">}</span><span class="ss">] dimensions"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Built index with [1450] items and [384] dimensions</code></pre>
</div>
</div>
</section>
<section class="slide level2 slide-code">
<h2>Load the Index and Define the Search Method</h2>
<div class="footer">
<p>➋ Semantic search</p>
</div>
<div class="cell" data-execution_count="441">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the saved index</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> AnnoyIndex(f, <span class="st">"angular"</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>index.load(os.path.join(<span class="st">"tmp"</span>, <span class="st">"coffee.ann"</span>))</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the search method</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> search(query, index, model, df):</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    query_embedding <span class="op">=</span> model.encode(query)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    nearest_ids <span class="op">=</span> index.get_nns_by_vector(query_embedding, <span class="dv">10</span>)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df.iloc[nearest_ids][[<span class="st">"text"</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="442">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Increase column width for display</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">"display.max_colwidth"</span>, <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Perform the Search</h2>
<div class="footer">
<p>➋ Semantic search</p>
</div>
<div class="cell" data-execution_count="456">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>search(<span class="st">"How much coffee can you drink in one day?"</span>, index, model, df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 41.9 ms, sys: 14.6 ms, total: 56.5 ms
Wall time: 42.3 ms</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="456">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">208</td>
<td>How many cups of coffee is it safe to consume per day?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1686</td>
<td>What is the limit to the amount of coffee one can consume?</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3006</td>
<td>What should be the daily coffee intake?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2270</td>
<td>How much "coffee" is there in my cup?</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3043</td>
<td>Is one cup of coffee a day good?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">792</td>
<td>Coffee on daily basis</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4424</td>
<td>How much coffee is too much?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2673</td>
<td>Coffee consuming amount</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4353</td>
<td>How Much Caffeine is Really in Your Coffee? - analysis / questions</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3218</td>
<td>How do I vary between how much froth for each coffee drink?</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Perform the Search</h2>
<div class="footer">
<p>➋ Semantic search</p>
</div>
<div class="cell" data-execution_count="449">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>search(<span class="st">"What is the maximum coffee consumption?"</span>, index, model, df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 41.5 ms, sys: 13.5 ms, total: 55 ms
Wall time: 39.9 ms</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="449">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1686</td>
<td>What is the limit to the amount of coffee one can consume?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4404</td>
<td>What is the minimum amount of coffee that produces the maximum possible concentration?</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3006</td>
<td>What should be the daily coffee intake?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2673</td>
<td>Coffee consuming amount</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">447</td>
<td>What's the minimum recommended age for drinking a coffee?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3591</td>
<td>Minimum amount of water in coffee</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3200</td>
<td>Merits &amp; demerits of coffee consumption</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">208</td>
<td>How many cups of coffee is it safe to consume per day?</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3218</td>
<td>How do I vary between how much froth for each coffee drink?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3002</td>
<td>How much caffeine delivered by eating coffee grounds</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 center center-horizontal smaller">
<h2>The “Vocabulary Mismatch” Problem</h2>
<p><em>What is the maximum coffee consumption?</em></p>

<img src="assets/screenshot-coffee-stackexchange.png" width="800" class="r-stretch"><div class="footer">
<p>➋ Semantic search</p>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Search in a Different Language</h2>
<div class="footer">
<p>➋ Semantic search</p>
</div>
<div class="cell" data-execution_count="451">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>search(<span class="st">"Kolik kafe můžu denně vypít?"</span>, index, model, df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 15 ms, sys: 3.24 ms, total: 18.2 ms
Wall time: 16 ms</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="451">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">208</td>
<td>How many cups of coffee is it safe to consume per day?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3006</td>
<td>What should be the daily coffee intake?</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1686</td>
<td>What is the limit to the amount of coffee one can consume?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2270</td>
<td>How much "coffee" is there in my cup?</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">792</td>
<td>Coffee on daily basis</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2673</td>
<td>Coffee consuming amount</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4424</td>
<td>How much coffee is too much?</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3218</td>
<td>How do I vary between how much froth for each coffee drink?</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4353</td>
<td>How Much Caffeine is Really in Your Coffee? - analysis / questions</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1073</td>
<td>How many milligrams of caffeine are in a fresh coffee bean?</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 logos">
<h2>Vector Databases</h2>
<ul>
<li><img data-src="assets/logos/postgres.png" style="top:21px" height="40"> PostgreSQL (with <code>pgvector</code>)</li>
<li><img data-src="assets/logos/elasticsearch.png" height="40"> Elasticsearch</li>
<li><img data-src="assets/logos/redis.png" height="40"> Redis</li>
<li><img data-src="assets/logos/pinecone.png" height="40"> Pinecone, <img data-src="assets/logos/weviate.png" height="40"> Weviate, <img data-src="assets/logos/vespa.png" height="40"> Vespa, <img data-src="assets/logos/milvus.jpg" height="40"> Milvus, …</li>
</ul>

<div class="footer">
<p>➋ Semantic search</p>
</div>
<aside><div>
<p><a href="https://nb.karmi.cz/semantic-search-with-elasticsearch/" class="uri">https://nb.karmi.cz/semantic-search-with-elasticsearch/</a></p>
</div></aside></section>
<section class="slide level2 center" data-background="#dc143c">
<h2>➌ Embeddings for other media</h2>
</section>
<section class="slide level2">
<h2>The LAION dataset</h2>
<ul>
<li>More than 2 <em>billions</em> of image/caption pairs</li>
<li>A “multi-modal” dataset</li>
<li>Embeddings with the <a href="https://openai.com/research/clip">CLIP</a> model by OpenAI</li>
<li>Full size: 6.2TB</li>
</ul>
<blockquote>
<p>(…) ensure you have at least 20TB of disk space available</p>
</blockquote>
<p><a href="https://clickhouse.com/blog/vector-search-clickhouse-p2" class="uri">https://clickhouse.com/blog/vector-search-clickhouse-p2</a></p>

<div class="footer">
<p>➌ Embeddings for other media</p>
</div>
<aside><div>
<p><a href="https://laion.ai/blog/laion-5b/" class="uri">https://laion.ai/blog/laion-5b/</a></p>
</div></aside></section>
<section class="slide level2 slide-code smaller">
<h2>Let’s download <em>just one file</em> from the dataset.</h2>
<p><small><a href="https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings" class="uri">https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings</a></small></p>
<div class="footer">
<p>➌ Embeddings for other media</p>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> humanize</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>DOWNLOAD_PATH <span class="op">=</span> os.path.expanduser(<span class="st">"~/Downloads"</span>)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>BASE_URL <span class="op">=</span> <span class="st">"https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings/resolve/main"</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>filenames <span class="op">=</span> {</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"metadata"</span>: <span class="st">"metadata/metadata_0000.parquet"</span>,</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"image_emb"</span>: <span class="st">"img_emb/img_emb_0000.npy"</span>,</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text_emb"</span>: <span class="st">"text_emb/text_emb_0000.npy"</span>,</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (key, filename) <span class="kw">in</span> filenames.items():</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>    url <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>BASE_URL<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>filename<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>    filepath <span class="op">=</span> os.path.join(DOWNLOAD_PATH, os.path.basename(filename))</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>    filebasename <span class="op">=</span> os.path.basename(filename)</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.path.exists(filepath):</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>        filesize <span class="op">=</span> os.path.getsize(filepath)</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Skipping download, file </span><span class="sc">{</span>filepath<span class="sc">}</span><span class="ss"> already exists (</span><span class="sc">{</span>humanize<span class="sc">.</span>naturalsize(filesize)<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> requests.get(url, stream<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>        response.raise_for_status()</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>        total_size<span class="op">=</span> <span class="bu">int</span>(response.headers.get(<span class="st">'content-length'</span>, <span class="dv">0</span>))</span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>        progress_bar <span class="op">=</span> tqdm(desc<span class="op">=</span>filebasename, total<span class="op">=</span>total_size, unit<span class="op">=</span><span class="st">'iB'</span>, unit_scale<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(filepath, <span class="st">"wb"</span>) <span class="im">as</span> f:</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> chunk <span class="kw">in</span> response.iter_content(chunk_size<span class="op">=</span><span class="dv">8192</span>): </span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> chunk:</span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a>                        progress_bar.update(<span class="bu">len</span>(chunk))</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a>                        f.write(chunk)</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">KeyboardInterrupt</span>:</span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Downloading of [</span><span class="sc">{</span>filebasename<span class="sc">}</span><span class="ss">] interrupted."</span>)</span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a>                filesize <span class="op">=</span> os.path.getsize(filepath)</span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Downloaded </span><span class="sc">{</span>filepath<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>humanize<span class="sc">.</span>naturalsize(filesize)<span class="sc">}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Skipping download, file /Users/karmi/Downloads/metadata_0000.parquet already exists (194.8 MB)
Skipping download, file /Users/karmi/Downloads/img_emb_0000.npy already exists (1.4 GB)
Skipping download, file /Users/karmi/Downloads/text_emb_0000.npy already exists (1.4 GB)</code></pre>
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Let’s peek inside the dataset.</h2>
<div class="footer">
<p>➌ Embeddings for other media</p>
</div>
<div class="cell" data-execution_count="393">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">"display.max_colwidth"</span>, <span class="dv">50</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_parquet(os.path.join(DOWNLOAD_PATH, os.path.basename(filenames[<span class="st">"metadata"</span>])))</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">"caption"</span>, <span class="st">"url"</span>, <span class="st">"exif"</span>]].head(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="393">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">caption</th>
<th data-quarto-table-cell-role="th">url</th>
<th data-quarto-table-cell-role="th">exif</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Color version PULP FICTION alternative poster art</td>
<td>http://cdn.shopify.com/s/files/1/0282/0804/pro...</td>
<td>{"Image Orientation": "Horizontal (normal)", "...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Writing A Successful Cover Letter by Cover Let...</td>
<td>http://tse3.mm.bing.net/th?id=OIP.hRMwYK1PG9pk...</td>
<td>{}</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Original Herrnhut plastic star, ORANGE (Specia...</td>
<td>https://cdn.shopify.com/s/files/1/0600/1993/pr...</td>
<td>{}</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section class="slide level2 slide-code">
<h2>Let’s display the images.</h2>
<div class="footer">
<p>➌ Embeddings for other media</p>
</div>
<div class="cell" data-execution_count="322">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Image, HTML</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> [</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>    Image(url<span class="op">=</span>row.url, alt<span class="op">=</span>row.caption, width<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> row <span class="kw">in</span> df[[<span class="st">"url"</span>, <span class="st">"caption"</span>]].head(<span class="dv">5</span>).itertuples()</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>HTML(<span class="st">""</span>.join([image._repr_html_() <span class="cf">for</span> image <span class="kw">in</span> images]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="322">

<img src="http://cdn.shopify.com/s/files/1/0282/0804/products/pulp_1024x1024.jpg?v=1474264437" width="200" alt="Color version PULP FICTION alternative poster art"><img src="http://tse3.mm.bing.net/th?id=OIP.hRMwYK1PG9pkAOq30i9QYQDyEs" width="200" alt="Writing A Successful Cover Letter by Cover Letter How To Write A Cover Letter Exles"><img src="https://cdn.shopify.com/s/files/1/0600/1993/products/A1e_Herrnhut_Stars_orange_special_edition_2016_380x@2x.png?v=1502078257" width="200" alt="Original Herrnhut plastic star, ORANGE (Special Edition 2016), ~ 13 cm / 5 inch ø"><img src="https://i.pinimg.com/originals/43/49/19/4349195deefe538d7711acdde78e2896.png" width="200" alt="Free Disney Planes Printable Coloring Pages Activity Sheets DisneyPlanes"><img src="https://i.pinimg.com/736x/3a/15/c5/3a15c55588e9d880bbbfd1a72082afe5--lady-fingers-chrissy-hynde.jpg" width="200" alt="Stevie Nicks Tee On Chrissie Hynde. Wish I could see them on their tour together.">
</div>
</div>
</section>
<section class="slide level2 slide-code smaller">
<h2>Let’s load the image embeddings and initialize the model.</h2>
<p><a href="https://huggingface.co/sentence-transformers/clip-ViT-L-14"><img data-src="assets/logo-huggingface.svg" class="icon" width="40" height="40"> <code>sentence-transformers/clip-ViT-L-14</code></a></p>
<div class="footer">
<p>➌ Embeddings for other media</p>
</div>
<div class="cell" data-execution_count="326">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>image_embeddings <span class="op">=</span> np.load(os.path.join(DOWNLOAD_PATH, os.path.basename(filenames[<span class="st">"image_emb"</span>])))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> SentenceTransformer(<span class="st">"clip-ViT-L-14"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="436">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> html <span class="im">import</span> escape</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_results(df, query, indices, <span class="op">**</span>kwargs):</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    width <span class="op">=</span> kwargs.get(<span class="st">"width"</span>, <span class="dv">200</span>)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>    df_res <span class="op">=</span> pd.DataFrame({</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"image"</span>: [</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f"&lt;img src='</span><span class="sc">{</span>df<span class="sc">.</span>url[i]<span class="sc">}</span><span class="ss">' title='</span><span class="sc">{</span>escape(df.caption[i])<span class="sc">}</span><span class="ss">' width='</span><span class="sc">{</span>width<span class="sc">}</span><span class="ss">px' onerror='this.onerror=null;this.src=</span><span class="ch">\"</span><span class="ss">https://placehold.co/400x400?text=Missing</span><span class="ch">\"</span><span class="ss">'&gt;"</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> i <span class="kw">in</span> indices.flatten() ],</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">"caption"</span>: [</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>                df[<span class="st">"caption"</span>][i]</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> i <span class="kw">in</span> indices.flatten() ],</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> HTML(</span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">""</span>.join([</span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"&lt;figure style='width: </span><span class="sc">{</span>width<span class="sc">}</span><span class="ss">px'&gt;</span><span class="sc">{</span>item<span class="sc">.</span>image<span class="sc">}</span><span class="ss">&lt;figcaption&gt;</span><span class="sc">{</span>item<span class="sc">.</span>caption<span class="sc">}</span><span class="ss">&lt;/figcaption&gt;&lt;/figure&gt;"</span></span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> item <span class="kw">in</span> df_res.itertuples() ]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section class="slide level2 slide-code">
<h2>Let’s query the dataset.</h2>
<p><small>A <strong>“cross-modality”</strong> search: searching <em>image</em> embeddings with <em>text</em> embeddings.</small></p>
<div class="footer">
<p>➌ Embeddings for other media</p>
</div>
<div class="cell" data-execution_count="437">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"cat dog pizza coffee asymptomatic"</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> NearestNeighbors</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>NUM_RESULTS <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>nn <span class="op">=</span> NearestNeighbors(n_neighbors<span class="op">=</span>NUM_RESULTS, algorithm<span class="op">=</span><span class="st">"auto"</span>)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>nn.fit(image_embeddings)</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Search *image* embeddings with *text* embeddings</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>query_embedding <span class="op">=</span> np.array([model3.encode(query)])</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>distances, indices <span class="op">=</span> nn.kneighbors(query_embedding)</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>display_results(df, query, indices)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

</section>
<section id="" class="slide level2 slide-code output-location-slide"><h2>Let’s query the dataset.</h2><div class="cell output-location-slide" data-execution_count="437">
<div class="cell-output cell-output-display" data-execution_count="437">
<figure style="width: 200px"><img src="http://rlv.zcache.co.uk/cute_quirky_cartoon_dog_mug-rb525f7f3d7df45f6a36b6eab6a951c46_x7jgr_8byvr_324.jpg" title="Cute quirky cartoon dog mugs" width="200px" onerror="this.onerror=null;this.src=&quot;https://placehold.co/400x400?text=Missing&quot;"><figcaption>Cute quirky cartoon dog mugs</figcaption></figure><figure style="width: 200px"><img src="https://rlv.zcache.co.nz/i_love_skye_terriers_mug-rd2ad2d5ae8834eafa4218fb9dc35e74e_kfpv5_324.jpg?rlvnet=1" title="I Love Skye Terriers Mug" width="200px" onerror="this.onerror=null;this.src=&quot;https://placehold.co/400x400?text=Missing&quot;"><figcaption>I Love Skye Terriers Mug</figcaption></figure><figure style="width: 200px"><img src="https://www.redwolf.in/image/cache/catalog/fridge-magnets/better-with-pizza-fridge-magnet-india-270x270.jpg" title="Better With Pizza - Scooby Doo Official Fridge Magnet" width="200px" onerror="this.onerror=null;this.src=&quot;https://placehold.co/400x400?text=Missing&quot;"><figcaption>Better With Pizza - Scooby Doo Official Fridge Magnet</figcaption></figure><figure style="width: 200px"><img src="https://cdn-images.threadless.com/threadless-media/artist_shops/shops/magnusblomster/products/949292/shirt-1552495007-f13a3438ee73bab652eedc1f9334663b.png?v=3&amp;d=eyJvbmx5X21ldGEiOiBmYWxzZSwgImZvcmNlIjogZmFsc2UsICJvcHMiOiBbWyJpZl8iLCBbeyJ0IjogImV4cHIiLCAidiI6IFsiaGFzX2FscGhhIiwgbnVsbCwgbnVsbF19LCB7InQiOiAiY29tcCIsICJ2IjogWyJ0aHJlYWRsZXNzLW1lZGlhL2FydGlzdF9zaG9wcy9zaG9wcy9tYWdudXNibG9tc3Rlci9wcm9kdWN0cy85NDkyOTIvc2hpcnQtMTU1MjQ5NTAwNy1mMTNhMzQzOGVlNzNiYWI2NTJlZWRjMWY5MzM0NjYzYi5wbmciLCBbWyJ0cmltIiwgW3RydWUsIGZhbHNlXSwge31dLCBbInJlc2l6ZSIsIFsxNjg3LjUsIDIwMDguOTI4NTcxNDI4NTcxM10sIHsibWF4X3NjYWxlIjogMy4wfV0sIFsicGFkIiwgWzMzNC44MjE0Mjg1NzE0Mjg1NiwgMjgxLjI1LCAzMzQuODIxNDI4NTcxNDI4NTYsIDI4MS4yNV0sIHsiYmFja2dyb3VuZCI6ICJmZmZmZmYifV0sIFsiY2FudmFzX2NlbnRlcmVkIiwgWzIyNTAuMCwgMjY3OC41NzE0Mjg1NzE0Mjg0XSwgeyJiYWNrZ3JvdW5kIjogImZmZmZmZiJ9XV1dfSwgeyJ0IjogImNvbXAiLCAidiI6IFsidGhyZWFkbGVzcy1tZWRpYS9hcnRpc3Rfc2hvcHMvc2hvcHMvbWFnbnVzYmxvbXN0ZXIvcHJvZHVjdHMvOTQ5MjkyL3NoaXJ0LTE1NTI0OTUwMDctZjEzYTM0MzhlZTczYmFiNjUyZWVkYzFmOTMzNDY2M2IucG5nIiwgW1sicmVzaXplIiwgWzIyNTAuMCwgMjY3OC41NzE0Mjg1NzE0Mjg0XSwgeyJtYXhfc2NhbGUiOiAzLjAsICJzdHlsZSI6ICJDUk9QIn1dLCBbImNhbnZhc19jZW50ZXJlZCIsIFsyMjUwLjAsIDI2NzguNTcxNDI4NTcxNDI4NF0sIHsiYmFja2dyb3VuZCI6ICJmZmZmZmYifV1dXX1dLCB7fV0sIFsiZW5jb2RlIiwgWyIucG5nIl0sIHsiZHBpIjogMzAwfV0sIFsicmVzaXplIiwgWzEzNzVdLCB7fV0sIFsib3ZlcmxheSIsIFsidGhyZWFkbGVzcy1tZWRpYS9hcnRpc3Rfc2hvcHMvb3ZlcmxheXMvM2Y5NjVlZjcxYjE3YjgxMTQ5ZDQyNGZiYTU2MmUzNGMvZnJvbnQtMTQ5NDAwMzkyMy04MzQxMjg5MDAyODA4YzRmMzQzMGFhOWRmYmQ0NGQ2Yy5wbmciXSwgeyJ5IjogMjA1LCAieCI6IDMxOCwgImJhY2tncm91bmQiOiAiZmZmZmZmIn1dLCBbInJlc2l6ZSIsIFs4MDBdLCB7fV0sIFsiY2FudmFzX2NlbnRlcmVkIiwgWzgwMCwgODAwLCAiI2ZmZmZmZiJdLCB7fV0sIFsiZW5jb2RlIiwgWyJqcGciLCA4NV0sIHt9XV19" title="Starving cat Home Sherpa Blanket Blanket by Magnus Blomster" width="200px" onerror="this.onerror=null;this.src=&quot;https://placehold.co/400x400?text=Missing&quot;"><figcaption>Starving cat Home Sherpa Blanket Blanket by Magnus Blomster</figcaption></figure><figure style="width: 200px"><img src="https://static1.bigstockphoto.com/0/6/8/large2/8605693.jpg" title="Dog And Cat" width="200px" onerror="this.onerror=null;this.src=&quot;https://placehold.co/400x400?text=Missing&quot;"><figcaption>Dog And Cat</figcaption></figure><figure style="width: 200px"><img src="http://ciaosoftware.com/images/Lost%20Dog%20Cafe.png" title="Lost Dog Cafe" width="200px" onerror="this.onerror=null;this.src=&quot;https://placehold.co/400x400?text=Missing&quot;"><figcaption>Lost Dog Cafe</figcaption></figure><figure style="width: 200px"><img src="https://cdn.drawception.com/images/panels/2015/1-3/hNzWG9GFYZ-10.png" title="Birthday cake, but it's a pizza with pepperoni" width="200px" onerror="this.onerror=null;this.src=&quot;https://placehold.co/400x400?text=Missing&quot;"><figcaption>Birthday cake, but it's a pizza with pepperoni</figcaption></figure><figure style="width: 200px"><img src="https://static2.bigstockphoto.com/7/3/2/large2/237136057.jpg" title="Portrait Of Kitten And Puppy On а White Background." width="200px" onerror="this.onerror=null;this.src=&quot;https://placehold.co/400x400?text=Missing&quot;"><figcaption>Portrait Of Kitten And Puppy On а White Background.</figcaption></figure><figure style="width: 200px"><img src="http://www.quotehd.com/imagequotes/authors74/tmb/jake-gyllenhaal-jake-gyllenhaal-its-funny-to-me-that-people-find.jpg" title="Jake Gyllenhaal - It's funny to me that people find other people getting coffee really interesting, or walking their dog in the dog park." width="200px" onerror="this.onerror=null;this.src=&quot;https://placehold.co/400x400?text=Missing&quot;"><figcaption>Jake Gyllenhaal - It's funny to me that people find other people getting coffee really interesting, or walking their dog in the dog park.</figcaption></figure><figure style="width: 200px"><img src="https://t0.gstatic.com/images?q=tbn:ANd9GcTjjwQUc5aMu4aYE0YQCr_HO5zGcUB2tJxITIdQxoXkz6xKjXUJjw" title="Can Starbucks Be Any Perfect Than This Imagine How Awesome" width="200px" onerror="this.onerror=null;this.src=&quot;https://placehold.co/400x400?text=Missing&quot;"><figcaption>Can Starbucks Be Any Perfect Than This Imagine How Awesome</figcaption></figure>
</div>
</div></section><section class="slide level2 slide-code smaller">
<h2>Let’s query the dataset <em>with a picture</em>.</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="https://images.unsplash.com/photo-1425913397330-cf8af2ff40a1?w=600.png"> <small><a href="https://unsplash.com/photos/MMJx78V7xS8" class="uri">https://unsplash.com/photos/MMJx78V7xS8</a></small></p>
</div><div class="column" style="width:50%;">

<!-- NOTE: Executable code is in the cell below -->
<div class="sourceCode" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>image_url <span class="op">=</span> <span class="st">"https://images.unsplash.com/photo-1425913397330-cf8af2ff40a1?w=600"</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> PIL.Image.<span class="bu">open</span>(</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>  requests.get(image_url, stream<span class="op">=</span><span class="va">True</span>).raw</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Search *image* embeddings with *image* embeddings</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>query_image_embedding <span class="op">=</span> model3.encode([image])</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>distances, indices <span class="op">=</span> nn.kneighbors(query_image_embedding)</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>display_results(df, <span class="st">"Image"</span>, indices, width<span class="op">=</span><span class="dv">400</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="footer">
<p>➌ Embeddings for other media</p>
</div>
</section>
<section class="slide level2 slide-code">
<h2></h2>
<div class="cell" data-execution_count="431">
<div class="cell-output cell-output-display" data-execution_count="431">
<figure style="width: 400px"><img src="https://earthsky.org/upl/2013/07/morning-forest-scence-300x214.jpg" title="morning-forest-scence" width="400px"><figcaption>morning-forest-scence</figcaption></figure><figure style="width: 400px"><img src="https://itsok2notbeok.files.wordpress.com/2017/07/nature-forest-trees-fog.jpeg?w=300&amp;" title="nature-forest-trees-fog" width="400px"><figcaption>nature-forest-trees-fog</figcaption></figure><figure style="width: 400px"><img src="https://media.istockphoto.com/photos/misty-forest-picture-id495880050?k=6&amp;m=495880050&amp;s=612x612&amp;w=0&amp;h=7cnyG_gm-8scWaMJ7yr1D3YJKEsY-rAZdmaXIrtPA3M=" title="misty forest - trees in mist stock pictures, royalty-free photos &amp; images" width="400px"><figcaption>misty forest - trees in mist stock pictures, royalty-free photos &amp; images</figcaption></figure><figure style="width: 400px"><img src="https://blog.ons.gov.uk/wp-content/uploads/sites/6/2021/07/Forest-630x470.jpg" title="Picture of a forest" width="400px"><figcaption>Picture of a forest</figcaption></figure><figure style="width: 400px"><img src="https://static.wixstatic.com/media/244598303d544aa899beb16d0fa95fde.jpg/v1/fill/w_390,h_585,al_c,q_80,usm_0.66_1.00_0.01/Hiking%20Path%20in%20Forest.jpg" title="Hiking Path in Forest" width="400px"><figcaption>Hiking Path in Forest</figcaption></figure><figure style="width: 400px"><img src="https://images.unsplash.com/photo-1495395226200-8fbf6b720b8c?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;w=1000&amp;q=80" title="woman walking in the forest" width="400px"><figcaption>woman walking in the forest</figcaption></figure><figure style="width: 400px"><img src="https://cdn.eyeem.com/thumb/991f5e54cb5563b3c9e5e061689421c1a672aeee-1406431509/2600/2600" title="tree, focus on foreground, branch, growth, tree trunk, close-up, nature, leaf, forest, selective focus, tranquility, plant, day, outdoors, twig, no people, sunlight, green color, beauty in nature, stem" width="400px"><figcaption>tree, focus on foreground, branch, growth, tree trunk, close-up, nature, leaf, forest, selective focus, tranquility, plant, day, outdoors, twig, no people, sunlight, green color, beauty in nature, stem</figcaption></figure><figure style="width: 400px"><img src="https://i1.wp.com/artsyforager.com/wp-content/uploads/2016/02/Redwoods4.jpg?resize=600%2C800" title="Finding Latitude. The Redwoods | artsy forager #travel #nature #photography #findinglatitude #redwoods" width="400px"><figcaption>Finding Latitude. The Redwoods | artsy forager #travel #nature #photography #findinglatitude #redwoods</figcaption></figure><figure style="width: 400px"><img src="https://0.s3.envato.com/files/217499708/preview.jpg" title="Download Morning Forest in Fog nulled download" width="400px"><figcaption>Download Morning Forest in Fog nulled download</figcaption></figure><figure style="width: 400px"><img src="https://www.commercialcafe.com/blog/wp-content/uploads/sites/10/2020/08/Best-US-Cities-by-Public-Parks-and-Walkability.jpg?w=1280&amp;h=500&amp;crop=1" title="Best US Cities by Public Parks and Walkability" width="400px"><figcaption>Best US Cities by Public Parks and Walkability</figcaption></figure>
</div>
</div>
</section>
<section class="slide level2 smaller" data-background="#FAF089">
<h2>Embeddings for … smells?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><a href="https://spectrum.ieee.org/digital-smell"><img data-src="assets/osmo-principal-odor-map.png" class="radius"></a> <small><a href="https://spectrum.ieee.org/digital-smell" class="uri">https://spectrum.ieee.org/digital-smell</a></small></p>
</div><div class="column" style="width:50%;">
<ul>
<li>A graph neural network</li>
<li>A model that maps chemical structure to odor descriptors (256 dimensions)</li>
<li>Trained on a dataset of over 5,000 molecules from fragrance industry</li>
<li>Achieves human-level reliability in describing odors</li>
</ul>
<p><a href="https://www.osmo.ai" class="uri">https://www.osmo.ai</a> <small><a href="https://doi.org/10.1101/2022.09.01.504602" class="uri">https://doi.org/10.1101/2022.09.01.504602</a></small></p>
</div>
</div>
<aside class="notes">
<p>“You can do math with numbers”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2 center center-horizontal" data-background="black">
<h2>Thank you!</h2>
<p><img data-src="assets/qr-talk-url.png" width="250" height="250"></p>
<div class="footer">
<p>Made with <a href="https://quarto.org"><strong>Quarto</strong></a></p>
</div>
</section>
<section class="slide level2 center center-horizontal" data-background="black" data-visibility="uncounted">
<h2>One more thing…</h2>
</section>
<section class="slide level2 center" data-background="#3182CE" data-visibility="uncounted">
<h2>Training a tiny transformer model</h2>
</section>
<section class="slide level2" data-visibility="uncounted">
<h2>Training a tiny transformer model</h2>
<ul>
<li><strong><code>nanoGPT</code></strong> by Andrej Karpathy</li>
<li>Implementation: <code>model.py</code>, <code>train.py</code>, <code>sample.py</code></li>
<li>Training: <code>data/shakespeare_char</code>, <code>config/train_shakespeare_char.py</code></li>
<li>All ~ 850 LOC</li>
<li>NYT: <a href="https://www.nytimes.com/interactive/2023/04/26/upshot/gpt-from-scratch.html?unlocked_article_code=l7MJ8rlrXXZWztIDZPVJMffgm9ywa9txD9FRNNt4z3gPq84LT9p-KxZiodhJ7e7IQpxXD-oWwBvfI7X3tdUbAZoojsnmn-QcW4mR-lme_ma7etxoVzD07tG8-1SaUi1xS7Uh4SM64m4ebkO1p3RVM9UJHdbbqX4u9qQH826vamoqkLJkE1HYSxUbNlXsIXH3bgwYukofD_YfxpxDwa8dQaQr0WtmObuj9U3fvDQSiWxJxEFMFzY6aJiyz6JErTVtbU0vSy6PYT1EECSeBY5UX0_YbwXIJreNN61XDe79D8LJsD6lgwSQ3VVT1NIzCE5su3vLwbvnugUupa5fLbmmNt2P0HaViZWlkA"><em>“Watch an A.I. Learn to Write by Reading Nothing but …”</em></a></li>
</ul>

<div class="footer">
<p>➍ Training a tiny transformer model</p>
</div>
<aside><div>
<p><a href="https://github.com/karpathy/nanoGPT" class="uri">https://github.com/karpathy/nanoGPT</a></p>
</div></aside></section>
<section class="slide level2 slide-code" data-visibility="uncounted">
<h2>Let’s clone the repository…</h2>
<div class="footer">
<p>➍ Training a tiny transformer model</p>
</div>
<div class="cell" data-execution_count="216">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> [ <span class="op">-</span>d <span class="st">'tmp/nanoGPT'</span> ] <span class="op">||</span> <span class="op">\</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>  git clone <span class="op">-</span>q <span class="st">'https://github.com/karmi/nanoGPT.git'</span> <span class="op">-</span>b config_python_peps <span class="st">'tmp/nanoGPT'</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> tree <span class="op">--</span>filesfirst <span class="st">'tmp/nanoGPT'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tmp/nanoGPT
├── LICENSE
├── README.md
├── bench.py
├── configurator.py
├── model.py
├── sample.py
├── scaling_laws.ipynb
├── train.py
├── transformer_sizing.ipynb
├── assets
│&nbsp;&nbsp; ├── gpt2_124M_loss.png
│&nbsp;&nbsp; └── nanogpt.jpg
├── config
│&nbsp;&nbsp; ├── eval_gpt2.py
│&nbsp;&nbsp; ├── eval_gpt2_large.py
│&nbsp;&nbsp; ├── eval_gpt2_medium.py
│&nbsp;&nbsp; ├── eval_gpt2_xl.py
│&nbsp;&nbsp; ├── finetune_python_peps.py
│&nbsp;&nbsp; ├── finetune_shakespeare.py
│&nbsp;&nbsp; ├── train_gpt2.py
│&nbsp;&nbsp; ├── train_python_peps_char.py
│&nbsp;&nbsp; └── train_shakespeare_char.py
└── data
    ├── openwebtext
    │&nbsp;&nbsp; ├── prepare.py
    │&nbsp;&nbsp; └── readme.md
    ├── python_peps
    │&nbsp;&nbsp; └── prepare.py
    ├── python_peps_char
    │&nbsp;&nbsp; └── prepare.py
    ├── shakespeare
    │&nbsp;&nbsp; ├── prepare.py
    │&nbsp;&nbsp; └── readme.md
    └── shakespeare_char
        ├── prepare.py
        └── readme.md

8 directories, 28 files</code></pre>
</div>
</div>
</section>
<section class="slide level2 slide-code" data-visibility="uncounted">
<h2>Let’s download and prepare the data…</h2>

<div class="footer">
<p>➍ Training a tiny transformer model</p>
</div>
<div class="cell" data-execution_count="219">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> python3 <span class="st">'tmp/nanoGPT/data/python_peps_char/prepare.py'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloaded ZIP to /var/folders/n8/vs92rw8d3z53yxqcfvt9nk9m0000gn/T/tmprjg5wt9q  
Extracted content to /var/folders/n8/vs92rw8d3z53yxqcfvt9nk9m0000gn/T/tmp738t2vmv
length of dataset in characters: 10,824,592                                     
all the unique characters: 
 !"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~&nbsp;¢§®°±µ½ÅÉ×ØßàáäåçèéíïñóöøúüčŁłňšżƛƴʻ̴̷̡̧̨̛̗̘̙̜̝̞̟̣̤̦̩̪̫̬̭̮̯̲̹̺̻̼͇͈͉͍͎̀̂̃̄̆̇̉̊̍̏̒̓̔̽̾̿͆ͅ͏͓͔͙͚͐͑͒͗ͤͥͧͨͩͮͯ͜͢͠͡ΒάαβγεοπτВДНСабвеиклмнорстуцяѕאךערةقمي٥߅৪୨௫ḚṮἤ‏–—‘’“”…ⁿℂℌℕℙ™℮→∀∃∅≈⊗⋅⌁⌚⒯─│┌┐└┘┬┴╌☂☃☺♨⚛✎✒✓⧟⬛スパム十大学屆年日曜月槀櫰波激火筑粹羔鈩ﬁ＞ｎ￥�𝐧𝘯🐱
vocab size: 323
train has 9,742,132 tokens
val has 1,082,460 tokens</code></pre>
</div>
</div>
<aside><div>
<p><a href="https://github.com/python/peps" class="uri">https://github.com/python/peps</a></p>
</div></aside></section>
<section class="slide level2 slide-code" data-visibility="uncounted">
<h2>Let’s run the training for 100 iterations…</h2>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Replace the <code>mps</code> device with <code>cuda</code> or <code>cpu</code> when not running on Apple M1/M2 hardware.</p>
</div>
</div>
</div>
<div class="footer">
<p>➍ Training a tiny transformer model</p>
</div>
<div class="cell" data-execution_count="226">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> (cd <span class="st">'tmp/nanoGPT'</span> <span class="op">&amp;&amp;</span> <span class="op">\</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  python3 train.py <span class="st">'config/train_python_peps_char.py'</span> \</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>device<span class="op">=</span>mps <span class="op">--</span><span class="bu">compile</span><span class="op">=</span><span class="va">False</span> <span class="op">\</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>max_iters<span class="op">=</span><span class="dv">100</span> <span class="op">--</span>log_interval<span class="op">=</span><span class="dv">10</span> <span class="op">--</span>eval_interval<span class="op">=</span><span class="dv">10</span> <span class="op">\</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>block_size<span class="op">=</span><span class="dv">128</span> <span class="op">--</span>batch_size<span class="op">=</span><span class="dv">12</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overriding config with config/train_python_peps_char.py:
# train a miniature character-level model based on Python PEPs
# https://peps.python.org/pep-0001/

out_dir = "out-python-peps-char"
eval_interval = 100
eval_iters = 20
log_interval = 1

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

wandb_log = False  # override via command line if you like
wandb_project = "python-peps-char"
wandb_run_name = None

dataset = "python_peps_char"
gradient_accumulation_steps = 1
batch_size = 64
block_size = 256  # context of up to 256 previous characters

# baby GPT model :)
n_layer = 6
n_head = 6
n_embd = 384
dropout = 0.2

learning_rate = 1e-3  # with baby networks can afford to go a bit higher
max_iters = 5000
lr_decay_iters = max_iters  # make equal to max_iters usually
min_lr = 1e-4  # learning_rate / 10 usually
beta2 = 0.99  # make a bit bigger because number of tokens per iter is small

warmup_iters = 0  # not super necessary potentially

# on macbook also add
# device = 'mps'  # run on MPS (https://github.com/karpathy/nanoGPT/issues/28)
# compile = False # do not torch compile the model

Overriding: device = mps
Overriding: compile = False
Overriding: max_iters = 100
Overriding: log_interval = 10
Overriding: eval_interval = 10
Overriding: block_size = 128
Overriding: batch_size = 12
tokens per iteration will be: 1,536
found vocab_size = 323 (inside data/python_peps_char/meta.pkl)
Initializing a new model from scratch
number of parameters: 10.75M
/opt/homebrew/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn("torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.")
num decayed parameter tensors: 26, with 10,790,016 parameters
num non-decayed parameter tensors: 13, with 4,992 parameters
using fused AdamW: False
step 0: train loss 5.7881, val loss 5.7859
iter 0: loss 5.8206, time 2051.09ms, mfu -100.00%
step 10: train loss 3.4102, val loss 3.4164
saving checkpoint to out-python-peps-char
iter 10: loss 3.2577, time 2073.89ms, mfu 0.02%
step 20: train loss 3.3962, val loss 3.4160
saving checkpoint to out-python-peps-char
iter 20: loss 3.5071, time 2063.53ms, mfu 0.02%
step 30: train loss 3.2524, val loss 3.2869
saving checkpoint to out-python-peps-char
iter 30: loss 3.2609, time 2075.96ms, mfu 0.02%
step 40: train loss 3.1787, val loss 3.1473
saving checkpoint to out-python-peps-char
iter 40: loss 3.1098, time 2068.78ms, mfu 0.02%
step 50: train loss 3.0840, val loss 3.0892
saving checkpoint to out-python-peps-char
iter 50: loss 3.0965, time 2068.53ms, mfu 0.02%
step 60: train loss 3.0588, val loss 3.0387
saving checkpoint to out-python-peps-char
iter 60: loss 2.8480, time 2037.31ms, mfu 0.02%
step 70: train loss 2.9941, val loss 2.9716
saving checkpoint to out-python-peps-char
iter 70: loss 3.0581, time 2063.60ms, mfu 0.02%
step 80: train loss 2.9373, val loss 2.9428
saving checkpoint to out-python-peps-char
iter 80: loss 2.9166, time 2058.22ms, mfu 0.02%
step 90: train loss 2.8879, val loss 2.9092
saving checkpoint to out-python-peps-char
iter 90: loss 2.9189, time 2056.94ms, mfu 0.02%
step 100: train loss 2.8599, val loss 2.8568
saving checkpoint to out-python-peps-char
iter 100: loss 2.8701, time 2097.65ms, mfu 0.02%</code></pre>
</div>
</div>
</section>
<section class="slide level2 slide-code" data-visibility="uncounted">
<h2>Let’s try the output…</h2>
<div class="footer">
<p>➍ Training a tiny transformer model</p>
</div>
<div class="cell" data-execution_count="227">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> (cd <span class="st">'tmp/nanoGPT'</span> <span class="op">&amp;&amp;</span> <span class="op">\</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    python3 sample.py <span class="op">\</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>out_dir<span class="op">=</span>out<span class="op">-</span>python<span class="op">-</span>peps<span class="op">-</span>char <span class="op">\</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>num_samples<span class="op">=</span><span class="dv">1</span> <span class="op">\</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>max_new_tokens<span class="op">=</span><span class="dv">500</span> <span class="op">\</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>device<span class="op">=</span>cpu <span class="op">\</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>seed<span class="op">=</span><span class="st">"$(date +</span><span class="sc">%s</span><span class="st">)"</span> \</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>start<span class="op">=</span><span class="st">'A good Python code is '</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overriding: out_dir = out-python-peps-char
Overriding: num_samples = 1
Overriding: max_new_tokens = 500
Overriding: device = cpu
Overriding: seed = 1694413979
Overriding: start = A good Python code is 
number of parameters: 10.75M
Loading meta from data/python_peps_char/meta.pkl...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
A good Python code is  finmos atrerenalar.-sputhe bdinaxlyfas  ano e be te gemenob enguorpllethenenmen osul minnle ad en thexbkerpos n x[ ter
s fe otife l

  nnps ausyne ans. then at/roosptoorad f me-pesico g orar us  nutheps, thitit._P anin bsesenenos tet.
.
dicor ance t
. lenesints bef sitatsere si onotanf t  d b bincedesefarn t a m e vacjowo lale nurerat4 onor age e anise g mr be onthe-xp an nacof ted tatandasiblarodorong i  thndhan leron  canserinin herd plin fon anatenanpathef s  rithere Ghucotos d tiyronsedur t...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</code></pre>
</div>
</div>
</section>
<section class="slide level2 slide-code" data-visibility="uncounted">
<h2>Let’s continue the training for 1000 iterations…</h2>
<div class="footer">
<p>➍ Training a tiny transformer model</p>
</div>
<div class="cell" data-execution_count="228">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> (cd <span class="st">'tmp/nanoGPT'</span> <span class="op">&amp;&amp;</span> <span class="op">\</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>  python3 train.py <span class="st">'config/train_python_peps_char.py'</span> \</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>device<span class="op">=</span>mps <span class="op">--</span><span class="bu">compile</span><span class="op">=</span><span class="va">False</span> <span class="op">\</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>max_iters<span class="op">=</span><span class="dv">1000</span> <span class="op">--</span>eval_interval<span class="op">=</span><span class="dv">100</span> <span class="op">--</span>log_interval<span class="op">=</span><span class="dv">10</span> <span class="op">\</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>block_size<span class="op">=</span><span class="dv">128</span> <span class="op">--</span>batch_size<span class="op">=</span><span class="dv">12</span> <span class="op">\</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>init_from<span class="op">=</span><span class="st">'resume'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overriding config with config/train_python_peps_char.py:
# train a miniature character-level model based on Python PEPs
# https://peps.python.org/pep-0001/

out_dir = "out-python-peps-char"
eval_interval = 100
eval_iters = 20
log_interval = 1

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

wandb_log = False  # override via command line if you like
wandb_project = "python-peps-char"
wandb_run_name = None

dataset = "python_peps_char"
gradient_accumulation_steps = 1
batch_size = 64
block_size = 256  # context of up to 256 previous characters

# baby GPT model :)
n_layer = 6
n_head = 6
n_embd = 384
dropout = 0.2

learning_rate = 1e-3  # with baby networks can afford to go a bit higher
max_iters = 5000
lr_decay_iters = max_iters  # make equal to max_iters usually
min_lr = 1e-4  # learning_rate / 10 usually
beta2 = 0.99  # make a bit bigger because number of tokens per iter is small

warmup_iters = 0  # not super necessary potentially

# on macbook also add
# device = 'mps'  # run on MPS (https://github.com/karpathy/nanoGPT/issues/28)
# compile = False # do not torch compile the model

Overriding: device = mps
Overriding: compile = False
Overriding: max_iters = 1000
Overriding: eval_interval = 100
Overriding: log_interval = 10
Overriding: block_size = 128
Overriding: batch_size = 12
Overriding: init_from = resume
tokens per iteration will be: 1,536
found vocab_size = 323 (inside data/python_peps_char/meta.pkl)
Resuming training from out-python-peps-char
number of parameters: 10.75M
/opt/homebrew/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn("torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.")
num decayed parameter tensors: 26, with 10,790,016 parameters
num non-decayed parameter tensors: 13, with 4,992 parameters
using fused AdamW: False
step 100: train loss 2.8493, val loss 2.8981
iter 100: loss 3.1073, time 2046.86ms, mfu -100.00%
iter 110: loss 2.8265, time 159.36ms, mfu 0.21%
iter 120: loss 2.9178, time 158.76ms, mfu 0.21%
iter 130: loss 3.0910, time 158.29ms, mfu 0.21%
iter 140: loss 2.7329, time 153.66ms, mfu 0.21%
iter 150: loss 2.7806, time 154.46ms, mfu 0.21%
iter 160: loss 2.8659, time 156.52ms, mfu 0.21%
iter 170: loss 2.7454, time 160.12ms, mfu 0.21%
iter 180: loss 2.7229, time 160.91ms, mfu 0.21%
iter 190: loss 2.7062, time 157.70ms, mfu 0.21%
step 200: train loss 2.7405, val loss 2.7242
saving checkpoint to out-python-peps-char
iter 200: loss 2.7714, time 2047.83ms, mfu 0.19%
iter 210: loss 2.9391, time 155.69ms, mfu 0.19%
iter 220: loss 2.7786, time 159.49ms, mfu 0.20%
iter 230: loss 2.5624, time 160.60ms, mfu 0.20%
iter 240: loss 2.8867, time 155.25ms, mfu 0.20%
iter 250: loss 2.6296, time 155.96ms, mfu 0.20%
iter 260: loss 2.6903, time 160.19ms, mfu 0.20%
iter 270: loss 2.6721, time 157.93ms, mfu 0.20%
iter 280: loss 2.7015, time 158.63ms, mfu 0.20%
iter 290: loss 2.8002, time 155.70ms, mfu 0.20%
step 300: train loss 2.6667, val loss 2.7120
saving checkpoint to out-python-peps-char
iter 300: loss 2.9318, time 2085.57ms, mfu 0.19%
iter 310: loss 2.7656, time 157.16ms, mfu 0.19%
iter 320: loss 2.7524, time 155.57ms, mfu 0.19%
iter 330: loss 2.8231, time 153.63ms, mfu 0.19%
iter 340: loss 2.6844, time 154.04ms, mfu 0.20%
iter 350: loss 2.6755, time 159.30ms, mfu 0.20%
iter 360: loss 2.6727, time 154.88ms, mfu 0.20%
iter 370: loss 2.6401, time 158.10ms, mfu 0.20%
iter 380: loss 2.5010, time 155.52ms, mfu 0.20%
iter 390: loss 2.5265, time 156.44ms, mfu 0.20%
step 400: train loss 2.6272, val loss 2.6283
saving checkpoint to out-python-peps-char
iter 400: loss 2.6528, time 2061.84ms, mfu 0.18%
iter 410: loss 2.6632, time 157.79ms, mfu 0.19%
iter 420: loss 2.6937, time 156.75ms, mfu 0.19%
iter 430: loss 2.3994, time 156.39ms, mfu 0.19%
iter 440: loss 2.6321, time 161.98ms, mfu 0.19%
iter 450: loss 2.5794, time 160.79ms, mfu 0.20%
iter 460: loss 2.5512, time 157.49ms, mfu 0.20%
iter 470: loss 2.6617, time 157.31ms, mfu 0.20%
iter 480: loss 2.5715, time 158.38ms, mfu 0.20%
iter 490: loss 2.6151, time 159.02ms, mfu 0.20%
step 500: train loss 2.6002, val loss 2.6242
saving checkpoint to out-python-peps-char
iter 500: loss 2.5579, time 2069.60ms, mfu 0.18%
iter 510: loss 2.6138, time 157.67ms, mfu 0.19%
iter 520: loss 2.5819, time 159.96ms, mfu 0.19%
iter 530: loss 2.6238, time 158.65ms, mfu 0.19%
iter 540: loss 2.6576, time 159.97ms, mfu 0.19%
iter 550: loss 2.4655, time 159.78ms, mfu 0.19%
iter 560: loss 2.6956, time 157.31ms, mfu 0.20%
iter 570: loss 2.4883, time 160.03ms, mfu 0.20%
iter 580: loss 2.5292, time 156.90ms, mfu 0.20%
iter 590: loss 2.7204, time 160.22ms, mfu 0.20%
step 600: train loss 2.6054, val loss 2.5751
saving checkpoint to out-python-peps-char
iter 600: loss 2.6876, time 2079.26ms, mfu 0.18%
iter 610: loss 2.6970, time 160.55ms, mfu 0.18%
iter 620: loss 2.5635, time 159.51ms, mfu 0.19%
iter 630: loss 2.5722, time 159.64ms, mfu 0.19%
iter 640: loss 2.6576, time 159.29ms, mfu 0.19%
iter 650: loss 2.6629, time 158.75ms, mfu 0.19%
iter 660: loss 2.4561, time 160.27ms, mfu 0.19%
iter 670: loss 2.5355, time 159.05ms, mfu 0.20%
iter 680: loss 2.6293, time 157.54ms, mfu 0.20%
iter 690: loss 2.4230, time 161.01ms, mfu 0.20%
step 700: train loss 2.5462, val loss 2.5384
saving checkpoint to out-python-peps-char
iter 700: loss 2.5740, time 2065.55ms, mfu 0.18%
iter 710: loss 2.4509, time 156.57ms, mfu 0.18%
iter 720: loss 2.6919, time 157.44ms, mfu 0.19%
iter 730: loss 2.4529, time 160.13ms, mfu 0.19%
iter 740: loss 2.6126, time 151.79ms, mfu 0.19%
iter 750: loss 2.6207, time 152.63ms, mfu 0.19%
iter 760: loss 2.3668, time 159.03ms, mfu 0.20%
iter 770: loss 2.5513, time 159.26ms, mfu 0.20%
iter 780: loss 2.5633, time 157.27ms, mfu 0.20%
iter 790: loss 2.4206, time 159.83ms, mfu 0.20%
step 800: train loss 2.4368, val loss 2.4322
saving checkpoint to out-python-peps-char
iter 800: loss 2.4541, time 2080.52ms, mfu 0.18%
iter 810: loss 2.4992, time 156.59ms, mfu 0.19%
iter 820: loss 2.5003, time 156.95ms, mfu 0.19%
iter 830: loss 2.4490, time 159.98ms, mfu 0.19%
iter 840: loss 2.4964, time 155.40ms, mfu 0.19%
iter 850: loss 2.4557, time 155.21ms, mfu 0.19%
iter 860: loss 2.5860, time 161.07ms, mfu 0.20%
iter 870: loss 2.4550, time 159.33ms, mfu 0.20%
iter 880: loss 2.4199, time 160.35ms, mfu 0.20%
iter 890: loss 2.5686, time 157.15ms, mfu 0.20%
step 900: train loss 2.3250, val loss 2.3649
saving checkpoint to out-python-peps-char
iter 900: loss 2.4752, time 2063.28ms, mfu 0.18%
iter 910: loss 2.4306, time 159.17ms, mfu 0.18%
iter 920: loss 2.3784, time 159.83ms, mfu 0.19%
iter 930: loss 2.3465, time 158.60ms, mfu 0.19%
iter 940: loss 2.3496, time 160.31ms, mfu 0.19%
iter 950: loss 2.2669, time 160.17ms, mfu 0.19%
iter 960: loss 2.3639, time 160.37ms, mfu 0.19%
iter 970: loss 2.3838, time 156.35ms, mfu 0.20%
iter 980: loss 2.3694, time 159.58ms, mfu 0.20%
iter 990: loss 2.3414, time 160.78ms, mfu 0.20%
step 1000: train loss 2.2963, val loss 2.3054
saving checkpoint to out-python-peps-char
iter 1000: loss 2.3887, time 2068.74ms, mfu 0.18%</code></pre>
</div>
</div>
</section>
<section class="slide level2 slide-code" data-visibility="uncounted">
<h2>… and let’s try the output again.</h2>
<div class="footer">
<p>➍ Training a tiny transformer model</p>
</div>
<div class="cell" data-execution_count="229">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> (cd <span class="st">'tmp/nanoGPT'</span> <span class="op">&amp;&amp;</span> <span class="op">\</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    python3 sample.py <span class="op">\</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>out_dir<span class="op">=</span>out<span class="op">-</span>python<span class="op">-</span>peps<span class="op">-</span>char <span class="op">\</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>num_samples<span class="op">=</span><span class="dv">1</span> <span class="op">\</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>max_new_tokens<span class="op">=</span><span class="dv">500</span> <span class="op">\</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>device<span class="op">=</span>cpu <span class="op">\</span></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>seed<span class="op">=</span><span class="st">"$(date +</span><span class="sc">%s</span><span class="st">)"</span> \</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>start<span class="op">=</span><span class="st">'A good Python code is '</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overriding: out_dir = out-python-peps-char
Overriding: num_samples = 1
Overriding: max_new_tokens = 500
Overriding: device = cpu
Overriding: seed = 1694414209
Overriding: start = A good Python code is 
number of parameters: 10.75M
Loading meta from data/python_peps_char/meta.pkl...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
A good Python code is cons cons Loutimian be taluple binte a

-------------

A cary is is and the to pron the the kally en norcly extectse fin of vally.

N    the thin-ch the pes it the wilosimpor fore``` in cle of to denc: on of ` are birerm typeppvas the pocking the vablort ancat_telle```` mef. 
-Worf the st `````__Explernclomplect exate ford alltion is to mers etuto ar Gat wsit the ust suctionche ther an
for con cas ` onctize por seas usupor she inaction
de the cover peveg rarnt is of din as ave cal `````````` all...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</code></pre>
</div>
</div>
</section>
<section class="slide level2 slide-code" data-visibility="uncounted">
<h2>Let’s run 5000 iterations…</h2>
<div class="footer">
<p>➍ Training a tiny transformer model</p>
</div>
<div class="cell" data-execution_count="230">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> (cd <span class="st">'tmp/nanoGPT'</span> <span class="op">&amp;&amp;</span> <span class="op">\</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>  python3 train.py <span class="st">'config/train_python_peps_char.py'</span> \</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>device<span class="op">=</span>mps <span class="op">--</span><span class="bu">compile</span><span class="op">=</span><span class="va">False</span> <span class="op">\</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>max_iters<span class="op">=</span><span class="dv">5000</span> <span class="op">--</span>eval_interval<span class="op">=</span><span class="dv">100</span> <span class="op">--</span>log_interval<span class="op">=</span><span class="dv">10</span> <span class="op">\</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>block_size<span class="op">=</span><span class="dv">128</span> <span class="op">--</span>batch_size<span class="op">=</span><span class="dv">12</span> <span class="op">\</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>  <span class="op">--</span>init_from<span class="op">=</span><span class="st">'resume'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overriding config with config/train_python_peps_char.py:
# train a miniature character-level model based on Python PEPs
# https://peps.python.org/pep-0001/

out_dir = "out-python-peps-char"
eval_interval = 100
eval_iters = 20
log_interval = 1

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

wandb_log = False  # override via command line if you like
wandb_project = "python-peps-char"
wandb_run_name = None

dataset = "python_peps_char"
gradient_accumulation_steps = 1
batch_size = 64
block_size = 256  # context of up to 256 previous characters

# baby GPT model :)
n_layer = 6
n_head = 6
n_embd = 384
dropout = 0.2

learning_rate = 1e-3  # with baby networks can afford to go a bit higher
max_iters = 5000
lr_decay_iters = max_iters  # make equal to max_iters usually
min_lr = 1e-4  # learning_rate / 10 usually
beta2 = 0.99  # make a bit bigger because number of tokens per iter is small

warmup_iters = 0  # not super necessary potentially

# on macbook also add
# device = 'mps'  # run on MPS (https://github.com/karpathy/nanoGPT/issues/28)
# compile = False # do not torch compile the model

Overriding: device = mps
Overriding: compile = False
Overriding: max_iters = 5000
Overriding: eval_interval = 100
Overriding: log_interval = 10
Overriding: block_size = 128
Overriding: batch_size = 12
Overriding: init_from = resume
tokens per iteration will be: 1,536
found vocab_size = 323 (inside data/python_peps_char/meta.pkl)
Resuming training from out-python-peps-char
number of parameters: 10.75M
/opt/homebrew/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn("torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.")
num decayed parameter tensors: 26, with 10,790,016 parameters
num non-decayed parameter tensors: 13, with 4,992 parameters
using fused AdamW: False
step 1000: train loss 2.2751, val loss 2.3217
iter 1000: loss 2.5321, time 2033.84ms, mfu -100.00%
iter 1010: loss 2.2959, time 159.70ms, mfu 0.21%
iter 1020: loss 2.3953, time 158.09ms, mfu 0.21%
iter 1030: loss 2.5974, time 161.79ms, mfu 0.21%
iter 1040: loss 2.2316, time 157.27ms, mfu 0.21%
iter 1050: loss 2.2440, time 156.76ms, mfu 0.21%
iter 1060: loss 2.3252, time 156.65ms, mfu 0.21%
iter 1070: loss 2.2575, time 160.99ms, mfu 0.21%
iter 1080: loss 2.2046, time 161.03ms, mfu 0.21%
iter 1090: loss 2.3116, time 163.34ms, mfu 0.21%
step 1100: train loss 2.2272, val loss 2.1941
saving checkpoint to out-python-peps-char
iter 1100: loss 2.3039, time 2091.49ms, mfu 0.19%
iter 1110: loss 2.4511, time 159.44ms, mfu 0.19%
iter 1120: loss 2.3735, time 160.46ms, mfu 0.19%
iter 1130: loss 2.0979, time 161.30ms, mfu 0.20%
iter 1140: loss 2.3787, time 160.13ms, mfu 0.20%
iter 1150: loss 2.1693, time 161.58ms, mfu 0.20%
iter 1160: loss 2.2239, time 160.76ms, mfu 0.20%
iter 1170: loss 2.2148, time 161.68ms, mfu 0.20%
iter 1180: loss 2.2410, time 158.69ms, mfu 0.20%
iter 1190: loss 2.3768, time 164.45ms, mfu 0.20%
step 1200: train loss 2.1342, val loss 2.1694
saving checkpoint to out-python-peps-char
iter 1200: loss 2.5234, time 2112.01ms, mfu 0.18%
iter 1210: loss 2.2162, time 159.61ms, mfu 0.19%
iter 1220: loss 2.2980, time 159.95ms, mfu 0.19%
iter 1230: loss 2.3325, time 161.26ms, mfu 0.19%
iter 1240: loss 2.2036, time 161.14ms, mfu 0.19%
iter 1250: loss 2.2108, time 161.39ms, mfu 0.19%
iter 1260: loss 2.2324, time 157.18ms, mfu 0.20%
iter 1270: loss 2.1259, time 157.28ms, mfu 0.20%
iter 1280: loss 2.0822, time 161.55ms, mfu 0.20%
iter 1290: loss 2.0488, time 163.20ms, mfu 0.20%
step 1300: train loss 2.0907, val loss 2.1053
saving checkpoint to out-python-peps-char
iter 1300: loss 2.1816, time 2099.70ms, mfu 0.18%
iter 1310: loss 2.2082, time 161.58ms, mfu 0.18%
iter 1320: loss 2.2260, time 163.80ms, mfu 0.19%
iter 1330: loss 1.9390, time 164.23ms, mfu 0.19%
iter 1340: loss 2.1417, time 165.60ms, mfu 0.19%
iter 1350: loss 2.1275, time 163.67ms, mfu 0.19%
iter 1360: loss 2.1526, time 165.04ms, mfu 0.19%
iter 1370: loss 2.1847, time 163.83ms, mfu 0.19%
iter 1380: loss 2.1439, time 164.30ms, mfu 0.19%
iter 1390: loss 2.1694, time 163.08ms, mfu 0.19%
step 1400: train loss 2.0535, val loss 2.0741
saving checkpoint to out-python-peps-char
iter 1400: loss 2.0581, time 2101.24ms, mfu 0.18%
iter 1410: loss 2.1750, time 162.06ms, mfu 0.18%
iter 1420: loss 2.1577, time 163.56ms, mfu 0.18%
iter 1430: loss 2.0761, time 164.24ms, mfu 0.18%
iter 1440: loss 2.1740, time 163.36ms, mfu 0.19%
iter 1450: loss 1.9313, time 164.91ms, mfu 0.19%
iter 1460: loss 2.2576, time 162.13ms, mfu 0.19%
iter 1470: loss 1.9881, time 164.06ms, mfu 0.19%
iter 1480: loss 2.0822, time 169.61ms, mfu 0.19%
iter 1490: loss 2.2081, time 168.85ms, mfu 0.19%
step 1500: train loss 2.0382, val loss 2.0223
saving checkpoint to out-python-peps-char
iter 1500: loss 2.2091, time 2107.37ms, mfu 0.18%
iter 1510: loss 2.2030, time 162.18ms, mfu 0.18%
iter 1520: loss 2.0815, time 164.80ms, mfu 0.18%
iter 1530: loss 1.9971, time 168.94ms, mfu 0.18%
iter 1540: loss 2.1914, time 163.79ms, mfu 0.18%
iter 1550: loss 2.1675, time 164.10ms, mfu 0.19%
iter 1560: loss 1.9964, time 164.74ms, mfu 0.19%
iter 1570: loss 2.0627, time 163.78ms, mfu 0.19%
iter 1580: loss 2.1765, time 164.61ms, mfu 0.19%
iter 1590: loss 1.9497, time 161.92ms, mfu 0.19%
step 1600: train loss 1.9919, val loss 1.9822
saving checkpoint to out-python-peps-char
iter 1600: loss 2.0485, time 2123.05ms, mfu 0.18%
iter 1610: loss 2.0262, time 162.55ms, mfu 0.18%
iter 1620: loss 2.2110, time 167.26ms, mfu 0.18%
iter 1630: loss 1.9454, time 164.23ms, mfu 0.18%
iter 1640: loss 2.1486, time 164.16ms, mfu 0.18%
iter 1650: loss 2.1516, time 164.55ms, mfu 0.19%
iter 1660: loss 1.9299, time 164.44ms, mfu 0.19%
iter 1670: loss 2.0477, time 165.66ms, mfu 0.19%
iter 1680: loss 2.0975, time 166.43ms, mfu 0.19%
iter 1690: loss 1.9842, time 166.54ms, mfu 0.19%
step 1700: train loss 1.9301, val loss 1.9373
saving checkpoint to out-python-peps-char
iter 1700: loss 1.9992, time 2134.01ms, mfu 0.17%
iter 1710: loss 2.0447, time 163.00ms, mfu 0.18%
iter 1720: loss 2.0757, time 167.05ms, mfu 0.18%
iter 1730: loss 2.0395, time 165.84ms, mfu 0.18%
iter 1740: loss 2.0162, time 166.06ms, mfu 0.18%
iter 1750: loss 1.9759, time 165.70ms, mfu 0.19%
iter 1760: loss 2.1395, time 165.43ms, mfu 0.19%
iter 1770: loss 2.0391, time 158.29ms, mfu 0.19%
iter 1780: loss 1.9806, time 163.78ms, mfu 0.19%
iter 1790: loss 2.1135, time 167.92ms, mfu 0.19%
step 1800: train loss 1.8766, val loss 1.9167
saving checkpoint to out-python-peps-char
iter 1800: loss 2.0355, time 2107.03ms, mfu 0.17%
iter 1810: loss 2.0390, time 155.03ms, mfu 0.18%
iter 1820: loss 2.0104, time 166.09ms, mfu 0.18%
iter 1830: loss 1.9560, time 164.62ms, mfu 0.18%
iter 1840: loss 2.0396, time 166.15ms, mfu 0.19%
iter 1850: loss 1.9310, time 164.93ms, mfu 0.19%
iter 1860: loss 1.9971, time 166.84ms, mfu 0.19%
iter 1870: loss 1.9659, time 165.48ms, mfu 0.19%
iter 1880: loss 1.9533, time 162.90ms, mfu 0.19%
iter 1890: loss 1.9889, time 166.04ms, mfu 0.19%
step 1900: train loss 1.8782, val loss 1.8935
saving checkpoint to out-python-peps-char
iter 1900: loss 2.0162, time 2109.06ms, mfu 0.17%
iter 1910: loss 2.0120, time 165.15ms, mfu 0.18%
iter 1920: loss 2.1173, time 166.94ms, mfu 0.18%
iter 1930: loss 1.9274, time 163.11ms, mfu 0.18%
iter 1940: loss 1.9207, time 163.72ms, mfu 0.18%
iter 1950: loss 1.9227, time 163.95ms, mfu 0.19%
iter 1960: loss 2.1500, time 157.30ms, mfu 0.19%
iter 1970: loss 1.9999, time 164.34ms, mfu 0.19%
iter 1980: loss 1.9464, time 163.36ms, mfu 0.19%
iter 1990: loss 2.0942, time 164.16ms, mfu 0.19%
step 2000: train loss 1.8126, val loss 1.8323
saving checkpoint to out-python-peps-char
iter 2000: loss 1.9382, time 2096.49ms, mfu 0.18%
iter 2010: loss 1.8988, time 165.74ms, mfu 0.18%
iter 2020: loss 1.9780, time 166.76ms, mfu 0.18%
iter 2030: loss 2.1929, time 163.55ms, mfu 0.18%
iter 2040: loss 2.0863, time 167.38ms, mfu 0.18%
iter 2050: loss 1.9370, time 167.84ms, mfu 0.19%
iter 2060: loss 1.8958, time 165.92ms, mfu 0.19%
iter 2070: loss 1.8126, time 167.26ms, mfu 0.19%
iter 2080: loss 2.1033, time 163.03ms, mfu 0.19%
iter 2090: loss 1.9810, time 161.12ms, mfu 0.19%
step 2100: train loss 1.8147, val loss 1.8624
iter 2100: loss 1.9501, time 1903.94ms, mfu 0.17%
iter 2110: loss 1.8082, time 164.58ms, mfu 0.18%
iter 2120: loss 1.9426, time 165.68ms, mfu 0.18%
iter 2130: loss 2.1383, time 163.34ms, mfu 0.18%
iter 2140: loss 1.9970, time 166.34ms, mfu 0.18%
iter 2150: loss 2.0046, time 166.80ms, mfu 0.19%
iter 2160: loss 2.0325, time 166.42ms, mfu 0.19%
iter 2170: loss 1.8115, time 166.18ms, mfu 0.19%
iter 2180: loss 1.9505, time 163.50ms, mfu 0.19%
iter 2190: loss 1.9368, time 164.19ms, mfu 0.19%
step 2200: train loss 1.8122, val loss 1.8284
saving checkpoint to out-python-peps-char
iter 2200: loss 2.0438, time 2130.31ms, mfu 0.17%
iter 2210: loss 1.8211, time 160.78ms, mfu 0.18%
iter 2220: loss 1.8429, time 164.96ms, mfu 0.18%
iter 2230: loss 1.8908, time 165.08ms, mfu 0.18%
iter 2240: loss 1.8971, time 165.61ms, mfu 0.18%
iter 2250: loss 1.9284, time 167.34ms, mfu 0.19%
iter 2260: loss 1.7465, time 165.35ms, mfu 0.19%
iter 2270: loss 1.8372, time 166.68ms, mfu 0.19%
iter 2280: loss 1.9061, time 162.99ms, mfu 0.19%
iter 2290: loss 1.8952, time 163.61ms, mfu 0.19%
step 2300: train loss 1.7657, val loss 1.7991
saving checkpoint to out-python-peps-char
iter 2300: loss 2.0742, time 2096.83ms, mfu 0.17%
iter 2310: loss 1.8250, time 166.97ms, mfu 0.18%
iter 2320: loss 1.7708, time 164.46ms, mfu 0.18%
iter 2330: loss 1.9168, time 166.20ms, mfu 0.18%
iter 2340: loss 1.9586, time 163.30ms, mfu 0.18%
iter 2350: loss 1.7589, time 166.18ms, mfu 0.19%
iter 2360: loss 1.9428, time 168.06ms, mfu 0.19%
iter 2370: loss 1.8045, time 164.80ms, mfu 0.19%
iter 2380: loss 1.8843, time 163.61ms, mfu 0.19%
iter 2390: loss 2.0198, time 163.90ms, mfu 0.19%
step 2400: train loss 1.7510, val loss 1.7999
iter 2400: loss 1.8528, time 1904.17ms, mfu 0.17%
iter 2410: loss 1.8748, time 164.39ms, mfu 0.18%
iter 2420: loss 1.7897, time 164.89ms, mfu 0.18%
iter 2430: loss 1.7412, time 163.11ms, mfu 0.18%
iter 2440: loss 1.8162, time 164.41ms, mfu 0.18%
iter 2450: loss 1.9715, time 165.29ms, mfu 0.19%
iter 2460: loss 1.8782, time 163.82ms, mfu 0.19%
iter 2470: loss 1.9325, time 164.61ms, mfu 0.19%
iter 2480: loss 1.7956, time 164.44ms, mfu 0.19%
iter 2490: loss 1.8469, time 164.23ms, mfu 0.19%
step 2500: train loss 1.7438, val loss 1.7246
saving checkpoint to out-python-peps-char
iter 2500: loss 1.7390, time 2134.78ms, mfu 0.17%
iter 2510: loss 1.9502, time 162.77ms, mfu 0.18%
iter 2520: loss 1.8342, time 165.67ms, mfu 0.18%
iter 2530: loss 1.7282, time 166.50ms, mfu 0.18%
iter 2540: loss 1.8788, time 164.06ms, mfu 0.18%
iter 2550: loss 1.8752, time 164.71ms, mfu 0.19%
iter 2560: loss 1.8382, time 164.10ms, mfu 0.19%
iter 2570: loss 1.7344, time 162.98ms, mfu 0.19%
iter 2580: loss 1.8608, time 166.38ms, mfu 0.19%
iter 2590: loss 1.7900, time 164.99ms, mfu 0.19%
step 2600: train loss 1.7316, val loss 1.7415
iter 2600: loss 1.8116, time 1897.27ms, mfu 0.17%
iter 2610: loss 1.8210, time 164.74ms, mfu 0.18%
iter 2620: loss 1.8711, time 164.79ms, mfu 0.18%
iter 2630: loss 1.8306, time 162.46ms, mfu 0.18%
iter 2640: loss 1.7361, time 163.82ms, mfu 0.18%
iter 2650: loss 1.7243, time 163.83ms, mfu 0.19%
iter 2660: loss 1.8159, time 163.69ms, mfu 0.19%
iter 2670: loss 1.8114, time 165.92ms, mfu 0.19%
iter 2680: loss 1.8332, time 165.18ms, mfu 0.19%
iter 2690: loss 1.8311, time 165.00ms, mfu 0.19%
step 2700: train loss 1.6947, val loss 1.7094
saving checkpoint to out-python-peps-char
iter 2700: loss 1.8775, time 2120.45ms, mfu 0.17%
iter 2710: loss 1.9892, time 159.29ms, mfu 0.18%
iter 2720: loss 1.9068, time 168.33ms, mfu 0.18%
iter 2730: loss 1.8624, time 164.18ms, mfu 0.18%
iter 2740: loss 2.0804, time 164.69ms, mfu 0.18%
iter 2750: loss 1.7825, time 165.19ms, mfu 0.19%
iter 2760: loss 1.8506, time 164.88ms, mfu 0.19%
iter 2770: loss 1.8467, time 164.96ms, mfu 0.19%
iter 2780: loss 1.7341, time 163.63ms, mfu 0.19%
iter 2790: loss 1.9544, time 164.20ms, mfu 0.19%
step 2800: train loss 1.6984, val loss 1.6776
saving checkpoint to out-python-peps-char
iter 2800: loss 1.7847, time 2130.00ms, mfu 0.17%
iter 2810: loss 1.6469, time 163.73ms, mfu 0.18%
iter 2820: loss 1.6615, time 164.24ms, mfu 0.18%
iter 2830: loss 1.8137, time 164.88ms, mfu 0.18%
iter 2840: loss 1.8090, time 165.33ms, mfu 0.18%
iter 2850: loss 1.8369, time 164.53ms, mfu 0.19%
iter 2860: loss 1.7922, time 165.48ms, mfu 0.19%
iter 2870: loss 1.7941, time 165.22ms, mfu 0.19%
iter 2880: loss 1.7938, time 165.05ms, mfu 0.19%
iter 2890: loss 1.7479, time 163.64ms, mfu 0.19%
step 2900: train loss 1.6336, val loss 1.6960
iter 2900: loss 1.7545, time 1893.25ms, mfu 0.17%
iter 2910: loss 1.8330, time 164.16ms, mfu 0.18%
iter 2920: loss 1.8226, time 164.29ms, mfu 0.18%
iter 2930: loss 1.8460, time 163.23ms, mfu 0.18%
iter 2940: loss 1.7338, time 167.41ms, mfu 0.18%
iter 2950: loss 1.7633, time 164.08ms, mfu 0.19%
iter 2960: loss 1.8092, time 163.60ms, mfu 0.19%
iter 2970: loss 1.7407, time 163.96ms, mfu 0.19%
iter 2980: loss 1.8220, time 165.03ms, mfu 0.19%
iter 2990: loss 1.8005, time 166.81ms, mfu 0.19%
step 3000: train loss 1.7105, val loss 1.6684
saving checkpoint to out-python-peps-char
iter 3000: loss 1.7108, time 2129.25ms, mfu 0.17%
iter 3010: loss 1.7510, time 164.12ms, mfu 0.18%
iter 3020: loss 1.6979, time 167.62ms, mfu 0.18%
iter 3030: loss 1.7289, time 163.67ms, mfu 0.18%
iter 3040: loss 2.0497, time 163.84ms, mfu 0.18%
iter 3050: loss 1.5651, time 166.91ms, mfu 0.19%
iter 3060: loss 1.8488, time 163.34ms, mfu 0.19%
iter 3070: loss 1.7764, time 164.49ms, mfu 0.19%
iter 3080: loss 1.6803, time 162.05ms, mfu 0.19%
iter 3090: loss 1.7195, time 167.62ms, mfu 0.19%
step 3100: train loss 1.6231, val loss 1.6290
saving checkpoint to out-python-peps-char
iter 3100: loss 1.7252, time 2211.81ms, mfu 0.17%
iter 3110: loss 1.6458, time 166.28ms, mfu 0.18%
iter 3120: loss 1.7342, time 184.71ms, mfu 0.18%
iter 3130: loss 1.6939, time 195.95ms, mfu 0.18%
iter 3140: loss 1.5731, time 185.48ms, mfu 0.18%
iter 3150: loss 1.7253, time 181.55ms, mfu 0.18%
iter 3160: loss 1.6695, time 182.20ms, mfu 0.18%
iter 3170: loss 1.6104, time 192.99ms, mfu 0.18%
iter 3180: loss 1.7872, time 183.29ms, mfu 0.18%
iter 3190: loss 1.7972, time 182.51ms, mfu 0.18%
step 3200: train loss 1.5629, val loss 1.6022
saving checkpoint to out-python-peps-char
iter 3200: loss 1.6589, time 2416.18ms, mfu 0.16%
iter 3210: loss 1.6352, time 207.36ms, mfu 0.16%
iter 3220: loss 1.6786, time 161.76ms, mfu 0.17%
iter 3230: loss 1.6589, time 163.28ms, mfu 0.17%
iter 3240: loss 1.7947, time 164.05ms, mfu 0.17%
iter 3250: loss 1.5852, time 164.32ms, mfu 0.18%
iter 3260: loss 1.6043, time 162.75ms, mfu 0.18%
iter 3270: loss 1.5508, time 165.27ms, mfu 0.18%
iter 3280: loss 1.7505, time 165.98ms, mfu 0.18%
iter 3290: loss 1.7231, time 162.76ms, mfu 0.19%
step 3300: train loss 1.6104, val loss 1.5974
saving checkpoint to out-python-peps-char
iter 3300: loss 1.6592, time 2108.82ms, mfu 0.17%
iter 3310: loss 1.5303, time 165.20ms, mfu 0.17%
iter 3320: loss 1.7430, time 161.06ms, mfu 0.18%
iter 3330: loss 1.8581, time 161.36ms, mfu 0.18%
iter 3340: loss 1.6117, time 168.71ms, mfu 0.18%
iter 3350: loss 1.7177, time 158.68ms, mfu 0.18%
iter 3360: loss 1.5891, time 163.76ms, mfu 0.19%
iter 3370: loss 1.6948, time 162.09ms, mfu 0.19%
iter 3380: loss 1.7693, time 161.96ms, mfu 0.19%
iter 3390: loss 1.7800, time 160.02ms, mfu 0.19%
step 3400: train loss 1.6072, val loss 1.5938
saving checkpoint to out-python-peps-char
iter 3400: loss 1.8502, time 2099.53ms, mfu 0.17%
iter 3410: loss 1.9017, time 161.89ms, mfu 0.18%
iter 3420: loss 1.6999, time 164.67ms, mfu 0.18%
iter 3430: loss 1.7368, time 165.29ms, mfu 0.18%
iter 3440: loss 1.8204, time 161.01ms, mfu 0.18%
iter 3450: loss 1.7604, time 160.92ms, mfu 0.19%
iter 3460: loss 2.0020, time 162.01ms, mfu 0.19%
iter 3470: loss 1.6922, time 167.04ms, mfu 0.19%
iter 3480: loss 1.6569, time 160.47ms, mfu 0.19%
iter 3490: loss 1.6549, time 161.89ms, mfu 0.19%
step 3500: train loss 1.5491, val loss 1.5649
saving checkpoint to out-python-peps-char
iter 3500: loss 1.7571, time 2106.34ms, mfu 0.18%
iter 3510: loss 1.5435, time 160.65ms, mfu 0.18%
iter 3520: loss 1.7043, time 164.98ms, mfu 0.18%
iter 3530: loss 1.7491, time 165.80ms, mfu 0.18%
iter 3540: loss 1.5602, time 162.39ms, mfu 0.19%
iter 3550: loss 1.6158, time 162.54ms, mfu 0.19%
iter 3560: loss 1.8871, time 168.39ms, mfu 0.19%
iter 3570: loss 1.6485, time 162.32ms, mfu 0.19%
iter 3580: loss 1.6221, time 160.89ms, mfu 0.19%
iter 3590: loss 1.8020, time 162.11ms, mfu 0.19%
step 3600: train loss 1.5348, val loss 1.5987
iter 3600: loss 1.7566, time 1898.96ms, mfu 0.18%
iter 3610: loss 1.7522, time 162.16ms, mfu 0.18%
iter 3620: loss 1.7873, time 180.97ms, mfu 0.18%
iter 3630: loss 1.6991, time 163.17ms, mfu 0.18%
iter 3640: loss 1.6118, time 161.46ms, mfu 0.18%
iter 3650: loss 1.4223, time 163.61ms, mfu 0.19%
iter 3660: loss 1.6822, time 162.17ms, mfu 0.19%
iter 3670: loss 1.6539, time 164.36ms, mfu 0.19%
iter 3680: loss 1.6619, time 165.50ms, mfu 0.19%
iter 3690: loss 2.0044, time 158.69ms, mfu 0.19%
step 3700: train loss 1.5574, val loss 1.5598
saving checkpoint to out-python-peps-char
iter 3700: loss 1.6842, time 2099.83ms, mfu 0.18%
iter 3710: loss 1.7363, time 163.41ms, mfu 0.18%
iter 3720: loss 1.7340, time 160.78ms, mfu 0.18%
iter 3730: loss 1.5837, time 166.60ms, mfu 0.18%
iter 3740: loss 1.5616, time 162.80ms, mfu 0.19%
iter 3750: loss 1.7806, time 164.93ms, mfu 0.19%
iter 3760: loss 1.7392, time 166.84ms, mfu 0.19%
iter 3770: loss 1.5292, time 162.36ms, mfu 0.19%
iter 3780: loss 1.7059, time 163.48ms, mfu 0.19%
iter 3790: loss 1.6123, time 162.79ms, mfu 0.19%
step 3800: train loss 1.4965, val loss 1.5963
iter 3800: loss 1.6724, time 1910.53ms, mfu 0.18%
iter 3810: loss 1.6942, time 163.19ms, mfu 0.18%
iter 3820: loss 1.6521, time 163.01ms, mfu 0.18%
iter 3830: loss 1.6288, time 162.13ms, mfu 0.18%
iter 3840: loss 1.9918, time 182.46ms, mfu 0.18%
iter 3850: loss 1.5846, time 163.91ms, mfu 0.19%
iter 3860: loss 1.5575, time 163.38ms, mfu 0.19%
iter 3870: loss 1.6518, time 166.00ms, mfu 0.19%
iter 3880: loss 1.7276, time 163.78ms, mfu 0.19%
iter 3890: loss 1.6459, time 164.85ms, mfu 0.19%
step 3900: train loss 1.4477, val loss 1.5269
saving checkpoint to out-python-peps-char
iter 3900: loss 1.4394, time 2197.16ms, mfu 0.17%
iter 3910: loss 1.6200, time 179.92ms, mfu 0.18%
iter 3920: loss 1.7070, time 167.86ms, mfu 0.18%
iter 3930: loss 1.7698, time 161.85ms, mfu 0.18%
iter 3940: loss 1.5829, time 161.94ms, mfu 0.18%
iter 3950: loss 1.6896, time 163.17ms, mfu 0.19%
iter 3960: loss 1.5704, time 161.78ms, mfu 0.19%
iter 3970: loss 1.4399, time 172.25ms, mfu 0.19%
iter 3980: loss 1.7062, time 168.82ms, mfu 0.19%
iter 3990: loss 1.5533, time 187.08ms, mfu 0.19%
step 4000: train loss 1.5597, val loss 1.5972
iter 4000: loss 1.7324, time 1894.53ms, mfu 0.17%
iter 4010: loss 1.6720, time 188.81ms, mfu 0.17%
iter 4020: loss 1.6675, time 161.73ms, mfu 0.18%
iter 4030: loss 1.6128, time 165.12ms, mfu 0.18%
iter 4040: loss 1.6251, time 161.60ms, mfu 0.18%
iter 4050: loss 1.6048, time 162.37ms, mfu 0.18%
iter 4060: loss 1.5914, time 163.45ms, mfu 0.19%
iter 4070: loss 1.7058, time 163.59ms, mfu 0.19%
iter 4080: loss 1.6742, time 180.85ms, mfu 0.19%
iter 4090: loss 1.6749, time 164.07ms, mfu 0.19%
step 4100: train loss 1.4870, val loss 1.5240
saving checkpoint to out-python-peps-char
iter 4100: loss 1.6794, time 2164.64ms, mfu 0.17%
iter 4110: loss 1.5833, time 165.95ms, mfu 0.17%
iter 4120: loss 1.4470, time 185.83ms, mfu 0.18%
iter 4130: loss 1.6898, time 160.90ms, mfu 0.18%
iter 4140: loss 1.4611, time 165.60ms, mfu 0.18%
iter 4150: loss 1.7284, time 163.37ms, mfu 0.18%
iter 4160: loss 1.4878, time 183.35ms, mfu 0.18%
iter 4170: loss 1.5392, time 160.89ms, mfu 0.19%
iter 4180: loss 1.6032, time 163.09ms, mfu 0.19%
iter 4190: loss 1.6347, time 162.95ms, mfu 0.19%
step 4200: train loss 1.5239, val loss 1.5373
iter 4200: loss 1.6192, time 1885.46ms, mfu 0.17%
iter 4210: loss 1.5643, time 164.74ms, mfu 0.18%
iter 4220: loss 1.5764, time 164.68ms, mfu 0.18%
iter 4230: loss 1.6121, time 185.84ms, mfu 0.18%
iter 4240: loss 1.7452, time 167.00ms, mfu 0.18%
iter 4250: loss 1.7670, time 166.09ms, mfu 0.18%
iter 4260: loss 1.6667, time 163.55ms, mfu 0.18%
iter 4270: loss 1.6600, time 163.45ms, mfu 0.19%
iter 4280: loss 1.4909, time 165.07ms, mfu 0.19%
iter 4290: loss 1.5410, time 169.44ms, mfu 0.19%
step 4300: train loss 1.5069, val loss 1.5214
saving checkpoint to out-python-peps-char
iter 4300: loss 1.6056, time 2306.62ms, mfu 0.17%
iter 4310: loss 1.7149, time 165.90ms, mfu 0.17%
iter 4320: loss 1.6821, time 162.67ms, mfu 0.18%
iter 4330: loss 1.6915, time 161.66ms, mfu 0.18%
iter 4340: loss 1.5789, time 168.08ms, mfu 0.18%
iter 4350: loss 1.7868, time 163.27ms, mfu 0.18%
iter 4360: loss 1.6744, time 161.43ms, mfu 0.19%
iter 4370: loss 1.7203, time 161.55ms, mfu 0.19%
iter 4380: loss 1.6064, time 165.75ms, mfu 0.19%
iter 4390: loss 1.7470, time 162.24ms, mfu 0.19%
step 4400: train loss 1.4723, val loss 1.5509
iter 4400: loss 1.5397, time 1896.89ms, mfu 0.17%
iter 4410: loss 1.5611, time 168.01ms, mfu 0.18%
iter 4420: loss 1.5778, time 165.88ms, mfu 0.18%
iter 4430: loss 1.5911, time 179.10ms, mfu 0.18%
iter 4440: loss 1.7101, time 162.29ms, mfu 0.18%
iter 4450: loss 1.7752, time 161.45ms, mfu 0.19%
iter 4460: loss 1.6612, time 160.77ms, mfu 0.19%
iter 4470: loss 1.6011, time 164.17ms, mfu 0.19%
iter 4480: loss 1.6383, time 161.11ms, mfu 0.19%
iter 4490: loss 1.6578, time 162.92ms, mfu 0.19%
step 4500: train loss 1.4625, val loss 1.4841
saving checkpoint to out-python-peps-char
iter 4500: loss 1.5765, time 2070.37ms, mfu 0.17%
iter 4510: loss 1.5513, time 161.39ms, mfu 0.18%
iter 4520: loss 1.5143, time 160.98ms, mfu 0.18%
iter 4530: loss 1.7307, time 179.88ms, mfu 0.18%
iter 4540: loss 1.6566, time 163.43ms, mfu 0.18%
iter 4550: loss 1.7524, time 162.34ms, mfu 0.19%
iter 4560: loss 1.6054, time 163.84ms, mfu 0.19%
iter 4570: loss 1.6432, time 162.32ms, mfu 0.19%
iter 4580: loss 1.6222, time 173.01ms, mfu 0.19%
iter 4590: loss 1.5922, time 159.84ms, mfu 0.19%
step 4600: train loss 1.4737, val loss 1.4831
saving checkpoint to out-python-peps-char
iter 4600: loss 1.6498, time 2098.05ms, mfu 0.17%
iter 4610: loss 1.5962, time 161.52ms, mfu 0.18%
iter 4620: loss 1.6292, time 162.32ms, mfu 0.18%
iter 4630: loss 1.5728, time 162.26ms, mfu 0.18%
iter 4640: loss 1.6465, time 165.81ms, mfu 0.19%
iter 4650: loss 1.3893, time 161.83ms, mfu 0.19%
iter 4660: loss 1.5676, time 170.61ms, mfu 0.19%
iter 4670: loss 1.6933, time 163.18ms, mfu 0.19%
iter 4680: loss 1.7008, time 164.96ms, mfu 0.19%
iter 4690: loss 1.4823, time 161.03ms, mfu 0.19%
step 4700: train loss 1.4691, val loss 1.4626
saving checkpoint to out-python-peps-char
iter 4700: loss 1.5413, time 2091.03ms, mfu 0.18%
iter 4710: loss 1.6946, time 161.74ms, mfu 0.18%
iter 4720: loss 1.5913, time 167.41ms, mfu 0.18%
iter 4730: loss 1.5271, time 162.47ms, mfu 0.18%
iter 4740: loss 1.5656, time 162.64ms, mfu 0.19%
iter 4750: loss 1.5622, time 162.24ms, mfu 0.19%
iter 4760: loss 1.6752, time 161.58ms, mfu 0.19%
iter 4770: loss 1.5303, time 163.06ms, mfu 0.19%
iter 4780: loss 1.5878, time 162.75ms, mfu 0.19%
iter 4790: loss 1.5533, time 164.12ms, mfu 0.19%
step 4800: train loss 1.4403, val loss 1.5020
iter 4800: loss 1.5425, time 1883.88ms, mfu 0.18%
iter 4810: loss 1.6820, time 163.45ms, mfu 0.18%
iter 4820: loss 1.5900, time 162.54ms, mfu 0.18%
iter 4830: loss 1.6629, time 161.99ms, mfu 0.18%
iter 4840: loss 1.5858, time 162.08ms, mfu 0.19%
iter 4850: loss 1.6204, time 163.16ms, mfu 0.19%
iter 4860: loss 1.4941, time 162.83ms, mfu 0.19%
iter 4870: loss 1.4298, time 165.45ms, mfu 0.19%
iter 4880: loss 1.5327, time 162.88ms, mfu 0.19%
iter 4890: loss 1.6551, time 162.14ms, mfu 0.19%
step 4900: train loss 1.4436, val loss 1.4341
saving checkpoint to out-python-peps-char
iter 4900: loss 1.4756, time 2090.28ms, mfu 0.18%
iter 4910: loss 1.4568, time 163.83ms, mfu 0.18%
iter 4920: loss 1.7181, time 169.17ms, mfu 0.18%
iter 4930: loss 1.5902, time 162.39ms, mfu 0.18%
iter 4940: loss 1.7921, time 164.22ms, mfu 0.19%
iter 4950: loss 1.6566, time 161.02ms, mfu 0.19%
iter 4960: loss 1.4211, time 165.87ms, mfu 0.19%
iter 4970: loss 1.4426, time 162.19ms, mfu 0.19%
iter 4980: loss 1.5027, time 164.04ms, mfu 0.19%
iter 4990: loss 1.5483, time 159.71ms, mfu 0.19%
step 5000: train loss 1.4438, val loss 1.4542
iter 5000: loss 1.4665, time 1889.73ms, mfu 0.18%</code></pre>
</div>
</div>
</section>
<section class="slide level2 slide-code" data-visibility="uncounted">
<h2>… and let’s try the output again.</h2>
<div class="footer">
<p>➍ Training a tiny transformer model</p>
</div>
<div class="cell" data-execution_count="233">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> (cd <span class="st">'tmp/nanoGPT'</span> <span class="op">&amp;&amp;</span> <span class="op">\</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>    python3 sample.py <span class="op">\</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>out_dir<span class="op">=</span>out<span class="op">-</span>python<span class="op">-</span>peps<span class="op">-</span>char <span class="op">\</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>num_samples<span class="op">=</span><span class="dv">1</span> <span class="op">\</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>max_new_tokens<span class="op">=</span><span class="dv">500</span> <span class="op">\</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>device<span class="op">=</span>cpu <span class="op">\</span></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>seed<span class="op">=</span><span class="st">"$(date +</span><span class="sc">%s</span><span class="st">)"</span> \</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">--</span>start<span class="op">=</span><span class="st">'A good Python code is '</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overriding: out_dir = out-python-peps-char
Overriding: num_samples = 1
Overriding: max_new_tokens = 500
Overriding: device = cpu
Overriding: seed = 1694416832
Overriding: start = A good Python code is 
number of parameters: 10.75M
Loading meta from data/python_peps_char/meta.pkl...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
A good Python code is not performatication
or to problem and systems. The allowing may are supported to be value of
expected ``except`` and ``updatementer``none``. The is `size to work the
``index.tarse`` auth the path that of the same to referreferent and like
attributed to item, for version 1.4 is a possible in the version the from
statementially returning the part stated by a value of the feel file
the beginal for all namest a respured to proposes of the example with ``__``, it implementation is methods
developer ...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</code></pre>
</div>
</div>
</section>
<section class="slide level2 center center-horizontal smaller" data-visibility="uncounted">
<h2><small>Weights &amp; Biases Integration</small></h2>
<p><small> <a href="https://api.wandb.ai/links/karmi/2501lunz" class="uri">https://api.wandb.ai/links/karmi/2501lunz</a> </small></p>
<iframe src="https://api.wandb.ai/links/karmi/2501lunz" frameborder="0" width="1024" height="550" style="border: 2px solid #ccc; border-radius: 5px; padding: 10px; box-shadow: 0.3em 0.3em 1em rgba(0, 0, 0, 0.3);">
</iframe>
<div class="footer">
<p>➍ Training a tiny transformer model</p>
</div>
</section>
<section class="slide level2 center center-horizontal" data-background="black">
<h2>The End</h2>
<div class="footer footer-default">

</div>
</section>

    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="library-and-maze-czpycon2023_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="library-and-maze-czpycon2023_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="library-and-maze-czpycon2023_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="library-and-maze-czpycon2023_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="library-and-maze-czpycon2023_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="library-and-maze-czpycon2023_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="library-and-maze-czpycon2023_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="library-and-maze-czpycon2023_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="library-and-maze-czpycon2023_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="library-and-maze-czpycon2023_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: false,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'fast',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>