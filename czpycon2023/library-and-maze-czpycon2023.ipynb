{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "tags": [
     "metadata"
    ]
   },
   "source": [
    "---\n",
    "title: \"The Library <br>and <br>the Maze\"\n",
    "subtitle: CZ PyCon 2023\n",
    "author: Karel Minařík\n",
    "jupyter: python3\n",
    "\n",
    "format:\n",
    "  revealjs: \n",
    "    theme: [default]\n",
    "    slide-number: true\n",
    "    hash-type: number\n",
    "    transition: slide\n",
    "    transition-speed: fast\n",
    "    css: style.css\n",
    "    progress: false\n",
    "    execute:\n",
    "      echo: true\n",
    "      warning: false\n",
    "    code-line-numbers: false\n",
    "    scrollable: true\n",
    "    revealjs-plugins:\n",
    "      - no-shift-keys\n",
    "\n",
    "title-slide-attributes:\n",
    "  data-background-color: \"#000\"\n",
    "  data-background-image: assets/the-library-of-babel.png\n",
    "  data-background-opacity: \"0.5\"\n",
    "\n",
    "callout-appearance: minimal\n",
    "\n",
    "# Documentation: https://quarto.org/docs/reference/formats/presentations/revealjs.html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Talk is a Jupyter Notebook\n",
    "\n",
    ":::: columns\n",
    "\n",
    "::: {.column width=\"45%\"}\n",
    "![](assets/qr-talk-source.png)\n",
    "\n",
    "[github.com/karmi/talks](https://github.com/karmi/talks/blob/main/czpycon2023/library-and-maze-czpycon2023.ipynb){style=\"font-size: 80%;\"}\n",
    ":::\n",
    "\n",
    "::: {.column width=\"55%\"}\n",
    "Software Developer\n",
    "\n",
    "<small>ex-</small>Elastic.co\n",
    "\n",
    "<small>ex-</small>Česko.Digital\n",
    "\n",
    "MA in Philosophy\n",
    "\n",
    "[https://karmi.cz](https://karmi.cz){class=underline}\n",
    "\n",
    "<p style=\"margin-top: 40px; margin-bottom:0; line-height: 1;\"><img src=\"assets/icons/github-square.svg\" width=\"25\" class=\"icon small\" style=\"opacity: 0.3; top: 4px;\"><small><code><a href=\"https://github.com/karmi\">@karmi</a></code></small></p>\n",
    "<p style=\"margin-top:0; line-height: 1;\"><img src=\"assets/icons/twitter-square.svg\" width=\"25\" class=\"icon small\" style=\"opacity: 0.3;top: 4px;\"><small><code><a href=\"https://twitter.com/karmiq\">@karmiq</a></code></small></p>\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Notebook {.center visibility=hidden}\n",
    "\n",
    "<p style=\"font-size: 55%\">\n",
    "<a href=\"https://github.com/karmi/talks/blob/main/czpycon2023/library-and-maze-czpycon2023.ipynb\" style=\"color: #999; border-bottom: 1px solid #999;\">\n",
    "<strong>github.com/karmi/talks</strong>/blob/main/czpycon2023/library-and-maze-czpycon2023.ipynb\n",
    "</a>\n",
    "</p>\n",
    "\n",
    "![](assets/qr-talk-source.png){width=\"250\" height=\"250\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Library of Babel {background-color=\"#000\" background-image=\"assets/the-library-of-babel.png\" background-opacity=\"0.5\" class=\"text-white\" visibility=\"hidden\"}\n",
    "\n",
    ":::: columns\n",
    "\n",
    "::: {.column width=\"30%\"}\n",
    "![](assets/borges-portrait.jpg){width=250 class=border style=\"border: 2px solid #fff; border-radius: 5px\"}\n",
    ":::\n",
    "\n",
    "::: {.column width=\"70%\"}\n",
    "A short story by Jorge Luis Borges (1941)\n",
    "\n",
    "Library contains every possible combination of 22 characters\n",
    "\n",
    "$10^{1,830,000}$ <small>... one followed by over a million of zeros</small>\n",
    "\n",
    "Librarians search for the \"master book\"\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "\n",
    "::: {.notes}\n",
    "The number is $10^{1,830,000}$ in scientific notation.\n",
    "\n",
    "The estimated number of atoms in observable universe is $10^{80}$.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT by OpenAI\n",
    "\n",
    ":::: columns\n",
    "\n",
    "::: {.column width=\"30%\"}\n",
    "[![](assets/screenshot-chatgpt-announcement.png)](https://openai.com/blog/chatgpt)\n",
    ":::\n",
    "\n",
    "::: {.column width=\"70%\"}\n",
    "Announced in November 2022\n",
    "\n",
    "A \"cambrian explosion\" of interest in artificial intelligence\n",
    "\n",
    "Every problem in IT will be<br>\n",
    "reframed as an AI problem\n",
    "\n",
    "<small>\n",
    "Trivial example: extracting data from text\n",
    "</small>\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "::: {.notes}\n",
    "Example, extracting data from text: regex pattern or few-shot learning?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubic Cube by OpenAI {background=black background-video=assets/video-openai-rubic-cube-short.mp4 background-video-muted=true background-video-loop=true background-opacity=0.8 class=text-white}\n",
    "\n",
    "Training in virtual simulation, then in physical reality\n",
    "\n",
    "Equivalent of 10,000 human years ^[Metz, Cade. \"Genius Makers: The Mavericks Who Brought AI to Google, Facebook, and the World.\" Dutton, 2021. Kindle Edition, loc 277]\n",
    "\n",
    "Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{.quotes-grid}\n",
    "-----\n",
    "\n",
    "<div class=\"quotes\">\n",
    "> \"The self-attention mechanism uses multiple heads to capture different aspects of the sequence. Each head uses scaled dot-product attention to weight the importance of various parts of the input sequence when producing each element of the output sequence.\"\n",
    "\n",
    "> \"The vanishing gradient problem in RNNs is often mitigated by adopting architectures like LSTM (Long Short-Term Memory) or GRU (Gated Recurrent Units), which introduce gating mechanisms to control the flow of information.\"\n",
    "\n",
    "> \"The masked language model (MLM) pre-training objective allows BERT to learn bidirectional representations by randomly masking tokens and predicting them based on their context, using the Transformer's encoder architecture. Fine-tuning is then performed using a task-specific head layer over the pre-trained embeddings.\"\n",
    "\n",
    "> \"The model is trained using stochastic gradient descent (SGD) with a learning rate decay, optimized on the cross-entropy loss. The final output layer uses a softmax activation function to produce class probabilities, which are converted to logits for evaluation.\"\n",
    "\n",
    "> \"LoRA augments pre-trained Transformer models by adding learnable, layer-wise recurrent mechanisms. This enables the model to adapt to new tasks without requiring extensive fine-tuning and mitigates the catastrophic forgetting problem.\"\n",
    "\n",
    "> \"The embeddings are initialized randomly and updated via backpropagation. These high-dimensional vectors capture syntactic and semantic information and are fed into a stack of convolutional and fully connected layers for downstream tasks.\"\n",
    "\n",
    "<div class=\"quotes-description\">(Content generated by AI)</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "{background=black background-image=\"assets/meme-math-lady.jpg\" background-transition=fade transition=fade transition-speed=slow}\n",
    "------\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "$$\n",
    "\\theta_{j} := \\theta_{j} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)}\n",
    "$$\n",
    "\n",
    "::: {.notes}\n",
    "It's perfectly understandable to be completely confused by this.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\theta_{j} := \\theta_{j} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)}$ {background=\"#999\" class=\"text-white\" background-transition=fade transition=fade visibility=\"hidden\"}\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "The \"Gradient Descent\" algorithm\n",
    "\n",
    "The formula is **intimidating**, but the concept is not\n",
    "\n",
    "You don't need a PhD in mathematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Itinerary {background=black background-image=\"assets/big-maze.png\" background-opacity=0.6 background-transition=fade class=\"text-white\"}\n",
    "\n",
    "* What are text embeddings?\n",
    "* Use case: *Semantic Search*\n",
    "* Embeddings for other media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ➊ What Are Text Embeddings? {background=\"#dc143c\" .center}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are Text Embeddings?\n",
    "\n",
    "<br>\n",
    "\n",
    "- Basic mechanism for natural language processing\n",
    "  <small>(LLMs, machine translation, sentiment analysis, …)</small>\n",
    "\n",
    "- Numerical representations of text\n",
    "\n",
    "- \"Long lists of numbers\"\n",
    "\n",
    "- \"GPS coordinates\" for meaning\n",
    "\n",
    "- \"DNA sequence\" for words or phrases\n",
    "\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "\n",
    "# Setup for the following code (dependencies etc)\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "%pip install -q pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's initialize a small model. {.slide-code}\n",
    "\n",
    "[![](assets/logo-huggingface.svg){class=\"icon\" width=\"40\" height=\"40\"} `sentence-transformers/all-MiniLM-L6-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::\n",
    "\n",
    "::: notes\n",
    "\"Self-supervised contrastive learning objective\" – given a sentence from pair, predict the best pairing.\n",
    "\n",
    "Training data is more than 1 billion sentences (scientific papers, Reddit, StackExchange, MS Marco, Yahoo, ...)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "%pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model1 = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: aside\n",
    "<https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2>\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create embeddings for two words. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03733039, 0.0511619, -0.00030606816, 0.060209926, -0.11749442, '...']\n"
     ]
    }
   ],
   "source": [
    "embeddings_for_cat = model1.encode(\"cat\")\n",
    "print(list(embeddings_for_cat)[:5] + [\"...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05314704, 0.014194381, 0.0071458234, 0.06860866, -0.07848035, '...']\n"
     ]
    }
   ],
   "source": [
    "embeddings_for_dog = model1.encode(\"dog\")\n",
    "print(list(embeddings_for_dog)[:5] + [\"...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_for_dog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "print(model1.get_sentence_embedding_dimension())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are the \"Dimensions\"? {background=\"#718096\" .text-white}\n",
    "\n",
    "```\n",
    "print(len(embeddings_for_dog))\n",
    "# => 384\n",
    "print(model1.get_sentence_embedding_dimension())\n",
    "# => 384\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "The model captures 384 different aspects of the word's meaning, usage, or context.\n",
    "\n",
    "For example:\n",
    "\n",
    "- the **emotional tone** (positive, negative, neutral?)\n",
    "- the **usage patterns** (common or rare? in which genre?)\n",
    "- the **social setting** (formal or informal?)\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's put the embeddings into a *pandas* dataframe,<br> so we can make transformations and manipulations. {.slide-code}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>[0.03733039, 0.0511619, -0.00030606816, 0.0602...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>[-0.05314704, 0.014194381, 0.0071458234, 0.068...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            embeddings\n",
       "cat  [0.03733039, 0.0511619, -0.00030606816, 0.0602...\n",
       "dog  [-0.05314704, 0.014194381, 0.0071458234, 0.068..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "    [\n",
    "      [embeddings_for_cat],\n",
    "      [embeddings_for_dog],\n",
    "    ],\n",
    "    index=[\"cat\", \"dog\"], columns=[\"embeddings\"])\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's transform the data for a visualization. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>embedding</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>0.03733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>0.051162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>0.06021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>-0.117494</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.03667</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.111445</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.029857</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.023905</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.110093</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   animal embedding position\n",
       "0     cat   0.03733        0\n",
       "0     cat  0.051162        1\n",
       "0     cat -0.000306        2\n",
       "0     cat   0.06021        3\n",
       "0     cat -0.117494        4\n",
       "..    ...       ...      ...\n",
       "1     dog   0.03667      379\n",
       "1     dog  0.111445      380\n",
       "1     dog  0.029857      381\n",
       "1     dog  0.023905      382\n",
       "1     dog  0.110093      383\n",
       "\n",
       "[768 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output-location: column\n",
    "\n",
    "def df_for_heatmap(df):\n",
    "  return (\n",
    "    df.copy(deep=True)\n",
    "    \n",
    "    # Store the embeddings index as `position`\n",
    "    .assign(\n",
    "      position=[\n",
    "        list(range(len(x))) for x in df.embeddings\n",
    "      ])\n",
    "    \n",
    "    # Convert the index into a regular column\n",
    "    .reset_index()\n",
    "    \n",
    "    # Convert from \"wide\" to \"long\" format\n",
    "    .explode([\"embeddings\", \"position\"])\n",
    "    \n",
    "    # Rename columns for more clarity\n",
    "    .rename(\n",
    "      columns={\"index\": \"animal\",  \n",
    "               \"embeddings\": \"embedding\"})\n",
    "  )\n",
    "\n",
    "source = df_for_heatmap(df1)\n",
    "source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make a simple *heatmap* visualization. {.slide-code .smaller}\n",
    "\n",
    "::: aside\n",
    "<https://altair-viz.github.io/gallery/histogram_heatmap.html>\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-5278ba93b017469b9a08f308108517c5.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-5278ba93b017469b9a08f308108517c5.vega-embed details,\n",
       "  #altair-viz-5278ba93b017469b9a08f308108517c5.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-5278ba93b017469b9a08f308108517c5\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-5278ba93b017469b9a08f308108517c5\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-5278ba93b017469b9a08f308108517c5\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"domain\": false, \"grid\": false}}, \"data\": {\"name\": \"data-8efba1ba53a4bb618665f8f43a86d300\"}, \"mark\": {\"type\": \"rect\", \"width\": 3}, \"encoding\": {\"color\": {\"field\": \"embedding\", \"legend\": null, \"scale\": {\"scheme\": \"goldred\"}, \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false}, \"field\": \"position\", \"title\": \"\", \"type\": \"nominal\"}, \"y\": {\"axis\": {\"labelLimit\": 300, \"tickWidth\": 0, \"labelFontWeight\": \"bold\"}, \"field\": \"animal\", \"sort\": [\"cat\", \"dog\"], \"title\": \"\", \"type\": \"nominal\"}}, \"height\": {\"step\": 50}, \"width\": {\"step\": 3}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-8efba1ba53a4bb618665f8f43a86d300\": [{\"animal\": \"cat\", \"embedding\": 0.03733038902282715, \"position\": 0}, {\"animal\": \"cat\", \"embedding\": 0.05116190016269684, \"position\": 1}, {\"animal\": \"cat\", \"embedding\": -0.00030606816289946437, \"position\": 2}, {\"animal\": \"cat\", \"embedding\": 0.06020992621779442, \"position\": 3}, {\"animal\": \"cat\", \"embedding\": -0.11749441921710968, \"position\": 4}, {\"animal\": \"cat\", \"embedding\": -0.014230103231966496, \"position\": 5}, {\"animal\": \"cat\", \"embedding\": 0.10577624291181564, \"position\": 6}, {\"animal\": \"cat\", \"embedding\": 0.02678622677922249, \"position\": 7}, {\"animal\": \"cat\", \"embedding\": 0.02633771300315857, \"position\": 8}, {\"animal\": \"cat\", \"embedding\": -0.025700822472572327, \"position\": 9}, {\"animal\": \"cat\", \"embedding\": -0.023490382358431816, \"position\": 10}, {\"animal\": \"cat\", \"embedding\": -0.059555213898420334, \"position\": 11}, {\"animal\": \"cat\", \"embedding\": -0.030213920399546623, \"position\": 12}, {\"animal\": \"cat\", \"embedding\": 0.01632016710937023, \"position\": 13}, {\"animal\": \"cat\", \"embedding\": -0.029070131480693817, \"position\": 14}, {\"animal\": \"cat\", \"embedding\": -0.021689726039767265, \"position\": 15}, {\"animal\": \"cat\", \"embedding\": -0.06624991446733475, \"position\": 16}, {\"animal\": \"cat\", \"embedding\": 0.0018566468497738242, \"position\": 17}, {\"animal\": \"cat\", \"embedding\": -0.02400624379515648, \"position\": 18}, {\"animal\": \"cat\", \"embedding\": -0.028462519869208336, \"position\": 19}, {\"animal\": \"cat\", \"embedding\": -0.04663162678480148, \"position\": 20}, {\"animal\": \"cat\", \"embedding\": 0.04970483109354973, \"position\": 21}, {\"animal\": \"cat\", \"embedding\": 0.0030829671304672956, \"position\": 22}, {\"animal\": \"cat\", \"embedding\": 0.0017627303022891283, \"position\": 23}, {\"animal\": \"cat\", \"embedding\": -0.0677575021982193, \"position\": 24}, {\"animal\": \"cat\", \"embedding\": 0.07610169798135757, \"position\": 25}, {\"animal\": \"cat\", \"embedding\": -0.04533000662922859, \"position\": 26}, {\"animal\": \"cat\", \"embedding\": -0.03643454983830452, \"position\": 27}, {\"animal\": \"cat\", \"embedding\": -0.01879478245973587, \"position\": 28}, {\"animal\": \"cat\", \"embedding\": -0.059158362448215485, \"position\": 29}, {\"animal\": \"cat\", \"embedding\": -0.06607434153556824, \"position\": 30}, {\"animal\": \"cat\", \"embedding\": -0.00032660627039149404, \"position\": 31}, {\"animal\": \"cat\", \"embedding\": -0.00892042275518179, \"position\": 32}, {\"animal\": \"cat\", \"embedding\": 0.0534161739051342, \"position\": 33}, {\"animal\": \"cat\", \"embedding\": -0.05470164492726326, \"position\": 34}, {\"animal\": \"cat\", \"embedding\": -0.05120444297790527, \"position\": 35}, {\"animal\": \"cat\", \"embedding\": -0.009808437898755074, \"position\": 36}, {\"animal\": \"cat\", \"embedding\": 0.001138185034506023, \"position\": 37}, {\"animal\": \"cat\", \"embedding\": 0.05640072748064995, \"position\": 38}, {\"animal\": \"cat\", \"embedding\": 0.06178216636180878, \"position\": 39}, {\"animal\": \"cat\", \"embedding\": -0.03502189368009567, \"position\": 40}, {\"animal\": \"cat\", \"embedding\": -0.08470239490270615, \"position\": 41}, {\"animal\": \"cat\", \"embedding\": -0.027238626033067703, \"position\": 42}, {\"animal\": \"cat\", \"embedding\": -0.01921604946255684, \"position\": 43}, {\"animal\": \"cat\", \"embedding\": -0.0301410760730505, \"position\": 44}, {\"animal\": \"cat\", \"embedding\": 0.004264598712325096, \"position\": 45}, {\"animal\": \"cat\", \"embedding\": 0.029739808291196823, \"position\": 46}, {\"animal\": \"cat\", \"embedding\": -0.061798322945833206, \"position\": 47}, {\"animal\": \"cat\", \"embedding\": 0.04495337978005409, \"position\": 48}, {\"animal\": \"cat\", \"embedding\": -0.003923146519809961, \"position\": 49}, {\"animal\": \"cat\", \"embedding\": -0.06464503705501556, \"position\": 50}, {\"animal\": \"cat\", \"embedding\": 0.02069356106221676, \"position\": 51}, {\"animal\": \"cat\", \"embedding\": -0.0368909053504467, \"position\": 52}, {\"animal\": \"cat\", \"embedding\": -0.005059054587036371, \"position\": 53}, {\"animal\": \"cat\", \"embedding\": -0.01631752960383892, \"position\": 54}, {\"animal\": \"cat\", \"embedding\": 0.0001643513242015615, \"position\": 55}, {\"animal\": \"cat\", \"embedding\": 0.05130369961261749, \"position\": 56}, {\"animal\": \"cat\", \"embedding\": -0.018979744985699654, \"position\": 57}, {\"animal\": \"cat\", \"embedding\": -0.025225350633263588, \"position\": 58}, {\"animal\": \"cat\", \"embedding\": -0.029659781605005264, \"position\": 59}, {\"animal\": \"cat\", \"embedding\": 0.004612454213202, \"position\": 60}, {\"animal\": \"cat\", \"embedding\": 0.010547024197876453, \"position\": 61}, {\"animal\": \"cat\", \"embedding\": -0.00012563458585646003, \"position\": 62}, {\"animal\": \"cat\", \"embedding\": 0.07811744511127472, \"position\": 63}, {\"animal\": \"cat\", \"embedding\": 0.025477126240730286, \"position\": 64}, {\"animal\": \"cat\", \"embedding\": -3.3329724828945473e-06, \"position\": 65}, {\"animal\": \"cat\", \"embedding\": 0.0002755826571956277, \"position\": 66}, {\"animal\": \"cat\", \"embedding\": 0.009694824926555157, \"position\": 67}, {\"animal\": \"cat\", \"embedding\": 0.04977673664689064, \"position\": 68}, {\"animal\": \"cat\", \"embedding\": -0.011180022731423378, \"position\": 69}, {\"animal\": \"cat\", \"embedding\": 0.012095801532268524, \"position\": 70}, {\"animal\": \"cat\", \"embedding\": 0.03868110850453377, \"position\": 71}, {\"animal\": \"cat\", \"embedding\": -0.029366565868258476, \"position\": 72}, {\"animal\": \"cat\", \"embedding\": -0.00028453633422032, \"position\": 73}, {\"animal\": \"cat\", \"embedding\": 0.019265014678239822, \"position\": 74}, {\"animal\": \"cat\", \"embedding\": -0.0329861044883728, \"position\": 75}, {\"animal\": \"cat\", \"embedding\": 0.13171620666980743, \"position\": 76}, {\"animal\": \"cat\", \"embedding\": -0.007330453954637051, \"position\": 77}, {\"animal\": \"cat\", \"embedding\": 0.10367878526449203, \"position\": 78}, {\"animal\": \"cat\", \"embedding\": 0.01577475108206272, \"position\": 79}, {\"animal\": \"cat\", \"embedding\": -0.006975072436034679, \"position\": 80}, {\"animal\": \"cat\", \"embedding\": 0.028203023597598076, \"position\": 81}, {\"animal\": \"cat\", \"embedding\": -0.026833834126591682, \"position\": 82}, {\"animal\": \"cat\", \"embedding\": 0.03720366954803467, \"position\": 83}, {\"animal\": \"cat\", \"embedding\": 0.04000026360154152, \"position\": 84}, {\"animal\": \"cat\", \"embedding\": 0.06586140394210815, \"position\": 85}, {\"animal\": \"cat\", \"embedding\": -0.001760500599630177, \"position\": 86}, {\"animal\": \"cat\", \"embedding\": 0.016396649181842804, \"position\": 87}, {\"animal\": \"cat\", \"embedding\": -0.06748654693365097, \"position\": 88}, {\"animal\": \"cat\", \"embedding\": 0.02065412700176239, \"position\": 89}, {\"animal\": \"cat\", \"embedding\": 0.0171644426882267, \"position\": 90}, {\"animal\": \"cat\", \"embedding\": -0.010133227333426476, \"position\": 91}, {\"animal\": \"cat\", \"embedding\": 0.06467209756374359, \"position\": 92}, {\"animal\": \"cat\", \"embedding\": 0.014943447895348072, \"position\": 93}, {\"animal\": \"cat\", \"embedding\": -0.11084962636232376, \"position\": 94}, {\"animal\": \"cat\", \"embedding\": 0.03118159994482994, \"position\": 95}, {\"animal\": \"cat\", \"embedding\": -0.0077262986451387405, \"position\": 96}, {\"animal\": \"cat\", \"embedding\": -0.07746338099241257, \"position\": 97}, {\"animal\": \"cat\", \"embedding\": -0.04207180067896843, \"position\": 98}, {\"animal\": \"cat\", \"embedding\": 0.23520731925964355, \"position\": 99}, {\"animal\": \"cat\", \"embedding\": 0.02549399808049202, \"position\": 100}, {\"animal\": \"cat\", \"embedding\": 0.02585536614060402, \"position\": 101}, {\"animal\": \"cat\", \"embedding\": -0.04416589438915253, \"position\": 102}, {\"animal\": \"cat\", \"embedding\": 0.056878671050071716, \"position\": 103}, {\"animal\": \"cat\", \"embedding\": 0.00432342616841197, \"position\": 104}, {\"animal\": \"cat\", \"embedding\": -0.015330181457102299, \"position\": 105}, {\"animal\": \"cat\", \"embedding\": 0.011216405779123306, \"position\": 106}, {\"animal\": \"cat\", \"embedding\": 0.0017130991909652948, \"position\": 107}, {\"animal\": \"cat\", \"embedding\": 0.006893873680382967, \"position\": 108}, {\"animal\": \"cat\", \"embedding\": 0.014921043068170547, \"position\": 109}, {\"animal\": \"cat\", \"embedding\": -0.0020004312973469496, \"position\": 110}, {\"animal\": \"cat\", \"embedding\": -0.04708622768521309, \"position\": 111}, {\"animal\": \"cat\", \"embedding\": -0.05938082933425903, \"position\": 112}, {\"animal\": \"cat\", \"embedding\": 0.054582782089710236, \"position\": 113}, {\"animal\": \"cat\", \"embedding\": 0.0366448275744915, \"position\": 114}, {\"animal\": \"cat\", \"embedding\": 0.021196236833930016, \"position\": 115}, {\"animal\": \"cat\", \"embedding\": -0.022666316479444504, \"position\": 116}, {\"animal\": \"cat\", \"embedding\": -0.033385489135980606, \"position\": 117}, {\"animal\": \"cat\", \"embedding\": 0.08896197378635406, \"position\": 118}, {\"animal\": \"cat\", \"embedding\": -0.01806301809847355, \"position\": 119}, {\"animal\": \"cat\", \"embedding\": 0.03752695024013519, \"position\": 120}, {\"animal\": \"cat\", \"embedding\": -0.009956763125956059, \"position\": 121}, {\"animal\": \"cat\", \"embedding\": -0.04760892689228058, \"position\": 122}, {\"animal\": \"cat\", \"embedding\": -0.011007025837898254, \"position\": 123}, {\"animal\": \"cat\", \"embedding\": -0.0520976223051548, \"position\": 124}, {\"animal\": \"cat\", \"embedding\": -0.08540461212396622, \"position\": 125}, {\"animal\": \"cat\", \"embedding\": -0.04771364480257034, \"position\": 126}, {\"animal\": \"cat\", \"embedding\": -4.5456480422313094e-33, \"position\": 127}, {\"animal\": \"cat\", \"embedding\": -0.0048442017287015915, \"position\": 128}, {\"animal\": \"cat\", \"embedding\": -0.0976090058684349, \"position\": 129}, {\"animal\": \"cat\", \"embedding\": 0.014730213209986687, \"position\": 130}, {\"animal\": \"cat\", \"embedding\": -0.02608395740389824, \"position\": 131}, {\"animal\": \"cat\", \"embedding\": 0.04912848398089409, \"position\": 132}, {\"animal\": \"cat\", \"embedding\": 0.05850321054458618, \"position\": 133}, {\"animal\": \"cat\", \"embedding\": 0.0028911400586366653, \"position\": 134}, {\"animal\": \"cat\", \"embedding\": 0.02906510978937149, \"position\": 135}, {\"animal\": \"cat\", \"embedding\": -0.08842658996582031, \"position\": 136}, {\"animal\": \"cat\", \"embedding\": 0.016123125329613686, \"position\": 137}, {\"animal\": \"cat\", \"embedding\": -0.08860384672880173, \"position\": 138}, {\"animal\": \"cat\", \"embedding\": 0.012519451789557934, \"position\": 139}, {\"animal\": \"cat\", \"embedding\": -0.07366228848695755, \"position\": 140}, {\"animal\": \"cat\", \"embedding\": -0.012363078072667122, \"position\": 141}, {\"animal\": \"cat\", \"embedding\": 0.03294412046670914, \"position\": 142}, {\"animal\": \"cat\", \"embedding\": -0.009775564074516296, \"position\": 143}, {\"animal\": \"cat\", \"embedding\": -0.013371375389397144, \"position\": 144}, {\"animal\": \"cat\", \"embedding\": 0.022750822827219963, \"position\": 145}, {\"animal\": \"cat\", \"embedding\": -0.03435720130801201, \"position\": 146}, {\"animal\": \"cat\", \"embedding\": 0.01697033829987049, \"position\": 147}, {\"animal\": \"cat\", \"embedding\": -0.01303133275359869, \"position\": 148}, {\"animal\": \"cat\", \"embedding\": 0.07845914363861084, \"position\": 149}, {\"animal\": \"cat\", \"embedding\": 0.07198294997215271, \"position\": 150}, {\"animal\": \"cat\", \"embedding\": 0.07821457833051682, \"position\": 151}, {\"animal\": \"cat\", \"embedding\": -0.004803099203854799, \"position\": 152}, {\"animal\": \"cat\", \"embedding\": -0.08423855900764465, \"position\": 153}, {\"animal\": \"cat\", \"embedding\": -0.03150900825858116, \"position\": 154}, {\"animal\": \"cat\", \"embedding\": -0.08608413487672806, \"position\": 155}, {\"animal\": \"cat\", \"embedding\": -0.016402896493673325, \"position\": 156}, {\"animal\": \"cat\", \"embedding\": 0.010649312287569046, \"position\": 157}, {\"animal\": \"cat\", \"embedding\": 0.052741192281246185, \"position\": 158}, {\"animal\": \"cat\", \"embedding\": -0.00983115378767252, \"position\": 159}, {\"animal\": \"cat\", \"embedding\": 0.0637749433517456, \"position\": 160}, {\"animal\": \"cat\", \"embedding\": -0.003886570455506444, \"position\": 161}, {\"animal\": \"cat\", \"embedding\": -0.09037613123655319, \"position\": 162}, {\"animal\": \"cat\", \"embedding\": -0.12911859154701233, \"position\": 163}, {\"animal\": \"cat\", \"embedding\": -0.0193893164396286, \"position\": 164}, {\"animal\": \"cat\", \"embedding\": -0.04714939743280411, \"position\": 165}, {\"animal\": \"cat\", \"embedding\": 0.017238669097423553, \"position\": 166}, {\"animal\": \"cat\", \"embedding\": 0.024575872346758842, \"position\": 167}, {\"animal\": \"cat\", \"embedding\": 0.04931345954537392, \"position\": 168}, {\"animal\": \"cat\", \"embedding\": 0.015245893970131874, \"position\": 169}, {\"animal\": \"cat\", \"embedding\": 0.052764177322387695, \"position\": 170}, {\"animal\": \"cat\", \"embedding\": 0.021206554025411606, \"position\": 171}, {\"animal\": \"cat\", \"embedding\": 0.007927180267870426, \"position\": 172}, {\"animal\": \"cat\", \"embedding\": 0.006518141366541386, \"position\": 173}, {\"animal\": \"cat\", \"embedding\": 0.0398627370595932, \"position\": 174}, {\"animal\": \"cat\", \"embedding\": 0.084649957716465, \"position\": 175}, {\"animal\": \"cat\", \"embedding\": -0.06809552758932114, \"position\": 176}, {\"animal\": \"cat\", \"embedding\": 0.058130018413066864, \"position\": 177}, {\"animal\": \"cat\", \"embedding\": 0.08200763165950775, \"position\": 178}, {\"animal\": \"cat\", \"embedding\": -0.02538556605577469, \"position\": 179}, {\"animal\": \"cat\", \"embedding\": -0.016495410352945328, \"position\": 180}, {\"animal\": \"cat\", \"embedding\": -0.02540753223001957, \"position\": 181}, {\"animal\": \"cat\", \"embedding\": -0.02050221525132656, \"position\": 182}, {\"animal\": \"cat\", \"embedding\": -0.010569297708570957, \"position\": 183}, {\"animal\": \"cat\", \"embedding\": -0.012290237471461296, \"position\": 184}, {\"animal\": \"cat\", \"embedding\": -0.06475042551755905, \"position\": 185}, {\"animal\": \"cat\", \"embedding\": -0.0017496290383860469, \"position\": 186}, {\"animal\": \"cat\", \"embedding\": 0.10200170427560806, \"position\": 187}, {\"animal\": \"cat\", \"embedding\": 0.02206496335566044, \"position\": 188}, {\"animal\": \"cat\", \"embedding\": 0.0765802413225174, \"position\": 189}, {\"animal\": \"cat\", \"embedding\": 0.09286633133888245, \"position\": 190}, {\"animal\": \"cat\", \"embedding\": 0.02781105227768421, \"position\": 191}, {\"animal\": \"cat\", \"embedding\": 0.06639950722455978, \"position\": 192}, {\"animal\": \"cat\", \"embedding\": -0.09011589735746384, \"position\": 193}, {\"animal\": \"cat\", \"embedding\": 0.05881255865097046, \"position\": 194}, {\"animal\": \"cat\", \"embedding\": -0.010556093417108059, \"position\": 195}, {\"animal\": \"cat\", \"embedding\": 0.10835209488868713, \"position\": 196}, {\"animal\": \"cat\", \"embedding\": 0.04515175148844719, \"position\": 197}, {\"animal\": \"cat\", \"embedding\": -0.09467636793851852, \"position\": 198}, {\"animal\": \"cat\", \"embedding\": -0.003975188825279474, \"position\": 199}, {\"animal\": \"cat\", \"embedding\": 0.05559930205345154, \"position\": 200}, {\"animal\": \"cat\", \"embedding\": -0.07512973994016647, \"position\": 201}, {\"animal\": \"cat\", \"embedding\": 0.0425630621612072, \"position\": 202}, {\"animal\": \"cat\", \"embedding\": -0.04162270575761795, \"position\": 203}, {\"animal\": \"cat\", \"embedding\": -0.03164689242839813, \"position\": 204}, {\"animal\": \"cat\", \"embedding\": 0.022920027375221252, \"position\": 205}, {\"animal\": \"cat\", \"embedding\": -0.07881384342908859, \"position\": 206}, {\"animal\": \"cat\", \"embedding\": 0.02434290573000908, \"position\": 207}, {\"animal\": \"cat\", \"embedding\": -0.0004664689186029136, \"position\": 208}, {\"animal\": \"cat\", \"embedding\": -0.0020791019778698683, \"position\": 209}, {\"animal\": \"cat\", \"embedding\": 0.06402021646499634, \"position\": 210}, {\"animal\": \"cat\", \"embedding\": 0.04672593995928764, \"position\": 211}, {\"animal\": \"cat\", \"embedding\": -0.05104973912239075, \"position\": 212}, {\"animal\": \"cat\", \"embedding\": 0.08571244031190872, \"position\": 213}, {\"animal\": \"cat\", \"embedding\": -0.003941823728382587, \"position\": 214}, {\"animal\": \"cat\", \"embedding\": -0.08086039870977402, \"position\": 215}, {\"animal\": \"cat\", \"embedding\": -0.001296516042202711, \"position\": 216}, {\"animal\": \"cat\", \"embedding\": 0.09354415535926819, \"position\": 217}, {\"animal\": \"cat\", \"embedding\": -0.08106525242328644, \"position\": 218}, {\"animal\": \"cat\", \"embedding\": 0.05914008617401123, \"position\": 219}, {\"animal\": \"cat\", \"embedding\": 0.04921571537852287, \"position\": 220}, {\"animal\": \"cat\", \"embedding\": -0.07231651991605759, \"position\": 221}, {\"animal\": \"cat\", \"embedding\": 0.058873023837804794, \"position\": 222}, {\"animal\": \"cat\", \"embedding\": 3.7824829468729096e-33, \"position\": 223}, {\"animal\": \"cat\", \"embedding\": 0.012545853853225708, \"position\": 224}, {\"animal\": \"cat\", \"embedding\": -0.04446148872375488, \"position\": 225}, {\"animal\": \"cat\", \"embedding\": -0.024489810690283775, \"position\": 226}, {\"animal\": \"cat\", \"embedding\": 0.04101358354091644, \"position\": 227}, {\"animal\": \"cat\", \"embedding\": -0.08004330098628998, \"position\": 228}, {\"animal\": \"cat\", \"embedding\": 0.054829951375722885, \"position\": 229}, {\"animal\": \"cat\", \"embedding\": 0.03494759649038315, \"position\": 230}, {\"animal\": \"cat\", \"embedding\": -0.019040284678339958, \"position\": 231}, {\"animal\": \"cat\", \"embedding\": -0.026668254286050797, \"position\": 232}, {\"animal\": \"cat\", \"embedding\": 0.090579092502594, \"position\": 233}, {\"animal\": \"cat\", \"embedding\": -0.040876492857933044, \"position\": 234}, {\"animal\": \"cat\", \"embedding\": 0.0605093277990818, \"position\": 235}, {\"animal\": \"cat\", \"embedding\": 0.12900973856449127, \"position\": 236}, {\"animal\": \"cat\", \"embedding\": 0.012991182506084442, \"position\": 237}, {\"animal\": \"cat\", \"embedding\": 0.03803068771958351, \"position\": 238}, {\"animal\": \"cat\", \"embedding\": 0.03300974890589714, \"position\": 239}, {\"animal\": \"cat\", \"embedding\": -0.014435109682381153, \"position\": 240}, {\"animal\": \"cat\", \"embedding\": -0.03980138525366783, \"position\": 241}, {\"animal\": \"cat\", \"embedding\": 0.03257004916667938, \"position\": 242}, {\"animal\": \"cat\", \"embedding\": 0.011381683871150017, \"position\": 243}, {\"animal\": \"cat\", \"embedding\": -0.07342980802059174, \"position\": 244}, {\"animal\": \"cat\", \"embedding\": -0.010433388873934746, \"position\": 245}, {\"animal\": \"cat\", \"embedding\": -0.07071487605571747, \"position\": 246}, {\"animal\": \"cat\", \"embedding\": 0.03186000511050224, \"position\": 247}, {\"animal\": \"cat\", \"embedding\": 0.017511023208498955, \"position\": 248}, {\"animal\": \"cat\", \"embedding\": -0.006756139453500509, \"position\": 249}, {\"animal\": \"cat\", \"embedding\": 0.02524220384657383, \"position\": 250}, {\"animal\": \"cat\", \"embedding\": 0.0011837746715173125, \"position\": 251}, {\"animal\": \"cat\", \"embedding\": 0.03266751393675804, \"position\": 252}, {\"animal\": \"cat\", \"embedding\": -0.15093408524990082, \"position\": 253}, {\"animal\": \"cat\", \"embedding\": 0.031178871169686317, \"position\": 254}, {\"animal\": \"cat\", \"embedding\": -0.059040218591690063, \"position\": 255}, {\"animal\": \"cat\", \"embedding\": -0.014013662934303284, \"position\": 256}, {\"animal\": \"cat\", \"embedding\": -0.033383652567863464, \"position\": 257}, {\"animal\": \"cat\", \"embedding\": 0.008506729267537594, \"position\": 258}, {\"animal\": \"cat\", \"embedding\": 0.125481516122818, \"position\": 259}, {\"animal\": \"cat\", \"embedding\": -0.016623444855213165, \"position\": 260}, {\"animal\": \"cat\", \"embedding\": -0.02540566585958004, \"position\": 261}, {\"animal\": \"cat\", \"embedding\": -0.023232221603393555, \"position\": 262}, {\"animal\": \"cat\", \"embedding\": -0.005709399003535509, \"position\": 263}, {\"animal\": \"cat\", \"embedding\": 0.02903098426759243, \"position\": 264}, {\"animal\": \"cat\", \"embedding\": 0.0447402223944664, \"position\": 265}, {\"animal\": \"cat\", \"embedding\": -0.015073765069246292, \"position\": 266}, {\"animal\": \"cat\", \"embedding\": 0.0722578912973404, \"position\": 267}, {\"animal\": \"cat\", \"embedding\": -0.05189726501703262, \"position\": 268}, {\"animal\": \"cat\", \"embedding\": -0.02070474810898304, \"position\": 269}, {\"animal\": \"cat\", \"embedding\": -0.03925088420510292, \"position\": 270}, {\"animal\": \"cat\", \"embedding\": 0.0036010397598147392, \"position\": 271}, {\"animal\": \"cat\", \"embedding\": 0.040269169956445694, \"position\": 272}, {\"animal\": \"cat\", \"embedding\": 0.017428286373615265, \"position\": 273}, {\"animal\": \"cat\", \"embedding\": -0.08170264959335327, \"position\": 274}, {\"animal\": \"cat\", \"embedding\": -0.06424960494041443, \"position\": 275}, {\"animal\": \"cat\", \"embedding\": -0.0008617308922111988, \"position\": 276}, {\"animal\": \"cat\", \"embedding\": -0.03882838785648346, \"position\": 277}, {\"animal\": \"cat\", \"embedding\": 0.02205195277929306, \"position\": 278}, {\"animal\": \"cat\", \"embedding\": 0.019644981250166893, \"position\": 279}, {\"animal\": \"cat\", \"embedding\": -0.04208141192793846, \"position\": 280}, {\"animal\": \"cat\", \"embedding\": -0.021611368283629417, \"position\": 281}, {\"animal\": \"cat\", \"embedding\": -0.004930383060127497, \"position\": 282}, {\"animal\": \"cat\", \"embedding\": 0.027349671348929405, \"position\": 283}, {\"animal\": \"cat\", \"embedding\": 0.026824576780200005, \"position\": 284}, {\"animal\": \"cat\", \"embedding\": 0.04687768593430519, \"position\": 285}, {\"animal\": \"cat\", \"embedding\": -0.009210288524627686, \"position\": 286}, {\"animal\": \"cat\", \"embedding\": 0.05176464468240738, \"position\": 287}, {\"animal\": \"cat\", \"embedding\": -0.06490634381771088, \"position\": 288}, {\"animal\": \"cat\", \"embedding\": -0.02696290984749794, \"position\": 289}, {\"animal\": \"cat\", \"embedding\": -0.020811501890420914, \"position\": 290}, {\"animal\": \"cat\", \"embedding\": -0.07466711103916168, \"position\": 291}, {\"animal\": \"cat\", \"embedding\": -0.0031141547951847315, \"position\": 292}, {\"animal\": \"cat\", \"embedding\": -0.050411488860845566, \"position\": 293}, {\"animal\": \"cat\", \"embedding\": 0.13004563748836517, \"position\": 294}, {\"animal\": \"cat\", \"embedding\": 0.04714154452085495, \"position\": 295}, {\"animal\": \"cat\", \"embedding\": -0.08545417338609695, \"position\": 296}, {\"animal\": \"cat\", \"embedding\": -0.004048071801662445, \"position\": 297}, {\"animal\": \"cat\", \"embedding\": -0.061450060456991196, \"position\": 298}, {\"animal\": \"cat\", \"embedding\": 0.03889447823166847, \"position\": 299}, {\"animal\": \"cat\", \"embedding\": 0.005142970476299524, \"position\": 300}, {\"animal\": \"cat\", \"embedding\": 0.04706956818699837, \"position\": 301}, {\"animal\": \"cat\", \"embedding\": -0.029663976281881332, \"position\": 302}, {\"animal\": \"cat\", \"embedding\": -0.057756803929805756, \"position\": 303}, {\"animal\": \"cat\", \"embedding\": -0.0038473927415907383, \"position\": 304}, {\"animal\": \"cat\", \"embedding\": -0.04252525418996811, \"position\": 305}, {\"animal\": \"cat\", \"embedding\": -0.013100975193083286, \"position\": 306}, {\"animal\": \"cat\", \"embedding\": 0.03536299988627434, \"position\": 307}, {\"animal\": \"cat\", \"embedding\": -0.03501349315047264, \"position\": 308}, {\"animal\": \"cat\", \"embedding\": -0.06737858057022095, \"position\": 309}, {\"animal\": \"cat\", \"embedding\": 0.051769454032182693, \"position\": 310}, {\"animal\": \"cat\", \"embedding\": 0.06665308028459549, \"position\": 311}, {\"animal\": \"cat\", \"embedding\": -0.0029960705433040857, \"position\": 312}, {\"animal\": \"cat\", \"embedding\": 0.023673666641116142, \"position\": 313}, {\"animal\": \"cat\", \"embedding\": 0.0336286686360836, \"position\": 314}, {\"animal\": \"cat\", \"embedding\": 0.010094651021063328, \"position\": 315}, {\"animal\": \"cat\", \"embedding\": 0.0015439869603142142, \"position\": 316}, {\"animal\": \"cat\", \"embedding\": -0.06326888501644135, \"position\": 317}, {\"animal\": \"cat\", \"embedding\": -0.00808235164731741, \"position\": 318}, {\"animal\": \"cat\", \"embedding\": -1.3356751260573674e-08, \"position\": 319}, {\"animal\": \"cat\", \"embedding\": -0.03938533365726471, \"position\": 320}, {\"animal\": \"cat\", \"embedding\": -0.0460556261241436, \"position\": 321}, {\"animal\": \"cat\", \"embedding\": -0.08799877762794495, \"position\": 322}, {\"animal\": \"cat\", \"embedding\": 0.010793684981763363, \"position\": 323}, {\"animal\": \"cat\", \"embedding\": 0.0767190083861351, \"position\": 324}, {\"animal\": \"cat\", \"embedding\": 0.0468168742954731, \"position\": 325}, {\"animal\": \"cat\", \"embedding\": -0.024283016100525856, \"position\": 326}, {\"animal\": \"cat\", \"embedding\": -0.08208191394805908, \"position\": 327}, {\"animal\": \"cat\", \"embedding\": -0.02560182474553585, \"position\": 328}, {\"animal\": \"cat\", \"embedding\": -0.010608954355120659, \"position\": 329}, {\"animal\": \"cat\", \"embedding\": 0.05409183353185654, \"position\": 330}, {\"animal\": \"cat\", \"embedding\": -0.03235789015889168, \"position\": 331}, {\"animal\": \"cat\", \"embedding\": 0.034818634390830994, \"position\": 332}, {\"animal\": \"cat\", \"embedding\": 0.04324425011873245, \"position\": 333}, {\"animal\": \"cat\", \"embedding\": 0.07993130385875702, \"position\": 334}, {\"animal\": \"cat\", \"embedding\": 0.023873573169112206, \"position\": 335}, {\"animal\": \"cat\", \"embedding\": -0.029143504798412323, \"position\": 336}, {\"animal\": \"cat\", \"embedding\": 0.0012296894565224648, \"position\": 337}, {\"animal\": \"cat\", \"embedding\": 0.02520967274904251, \"position\": 338}, {\"animal\": \"cat\", \"embedding\": 0.11311154067516327, \"position\": 339}, {\"animal\": \"cat\", \"embedding\": -0.07022909820079803, \"position\": 340}, {\"animal\": \"cat\", \"embedding\": 0.03528955206274986, \"position\": 341}, {\"animal\": \"cat\", \"embedding\": -0.08676883578300476, \"position\": 342}, {\"animal\": \"cat\", \"embedding\": 0.03237234801054001, \"position\": 343}, {\"animal\": \"cat\", \"embedding\": -0.037393685430288315, \"position\": 344}, {\"animal\": \"cat\", \"embedding\": -0.021842287853360176, \"position\": 345}, {\"animal\": \"cat\", \"embedding\": 0.0009299059747718275, \"position\": 346}, {\"animal\": \"cat\", \"embedding\": 0.10743861645460129, \"position\": 347}, {\"animal\": \"cat\", \"embedding\": 0.007365658413618803, \"position\": 348}, {\"animal\": \"cat\", \"embedding\": -0.0174539927393198, \"position\": 349}, {\"animal\": \"cat\", \"embedding\": -0.0014842381933704019, \"position\": 350}, {\"animal\": \"cat\", \"embedding\": 0.018017098307609558, \"position\": 351}, {\"animal\": \"cat\", \"embedding\": -0.0375107116997242, \"position\": 352}, {\"animal\": \"cat\", \"embedding\": -0.07899514585733414, \"position\": 353}, {\"animal\": \"cat\", \"embedding\": 0.011136556044220924, \"position\": 354}, {\"animal\": \"cat\", \"embedding\": -0.033229053020477295, \"position\": 355}, {\"animal\": \"cat\", \"embedding\": 0.027380332350730896, \"position\": 356}, {\"animal\": \"cat\", \"embedding\": -0.07640188187360764, \"position\": 357}, {\"animal\": \"cat\", \"embedding\": 0.07584808021783829, \"position\": 358}, {\"animal\": \"cat\", \"embedding\": -0.01616724766790867, \"position\": 359}, {\"animal\": \"cat\", \"embedding\": 0.030557842925190926, \"position\": 360}, {\"animal\": \"cat\", \"embedding\": 0.05776338651776314, \"position\": 361}, {\"animal\": \"cat\", \"embedding\": 0.08141149580478668, \"position\": 362}, {\"animal\": \"cat\", \"embedding\": -0.0730246976017952, \"position\": 363}, {\"animal\": \"cat\", \"embedding\": -0.11145440489053726, \"position\": 364}, {\"animal\": \"cat\", \"embedding\": 0.0002831020683515817, \"position\": 365}, {\"animal\": \"cat\", \"embedding\": 0.029737157747149467, \"position\": 366}, {\"animal\": \"cat\", \"embedding\": -0.08533915132284164, \"position\": 367}, {\"animal\": \"cat\", \"embedding\": 0.015011357143521309, \"position\": 368}, {\"animal\": \"cat\", \"embedding\": 0.007454106118530035, \"position\": 369}, {\"animal\": \"cat\", \"embedding\": 0.001321324030868709, \"position\": 370}, {\"animal\": \"cat\", \"embedding\": 0.06907472014427185, \"position\": 371}, {\"animal\": \"cat\", \"embedding\": 0.04601537436246872, \"position\": 372}, {\"animal\": \"cat\", \"embedding\": 0.06226341798901558, \"position\": 373}, {\"animal\": \"cat\", \"embedding\": 0.002010924741625786, \"position\": 374}, {\"animal\": \"cat\", \"embedding\": 0.015723126009106636, \"position\": 375}, {\"animal\": \"cat\", \"embedding\": -0.00421560276299715, \"position\": 376}, {\"animal\": \"cat\", \"embedding\": -0.015644202008843422, \"position\": 377}, {\"animal\": \"cat\", \"embedding\": -0.03716267645359039, \"position\": 378}, {\"animal\": \"cat\", \"embedding\": 0.05307966470718384, \"position\": 379}, {\"animal\": \"cat\", \"embedding\": 0.1596624255180359, \"position\": 380}, {\"animal\": \"cat\", \"embedding\": 0.06126928701996803, \"position\": 381}, {\"animal\": \"cat\", \"embedding\": 0.06081460043787956, \"position\": 382}, {\"animal\": \"cat\", \"embedding\": 0.04928029701113701, \"position\": 383}, {\"animal\": \"dog\", \"embedding\": -0.05314704030752182, \"position\": 0}, {\"animal\": \"dog\", \"embedding\": 0.014194381423294544, \"position\": 1}, {\"animal\": \"dog\", \"embedding\": 0.007145823445171118, \"position\": 2}, {\"animal\": \"dog\", \"embedding\": 0.06860865652561188, \"position\": 3}, {\"animal\": \"dog\", \"embedding\": -0.07848034799098969, \"position\": 4}, {\"animal\": \"dog\", \"embedding\": 0.010167370550334454, \"position\": 5}, {\"animal\": \"dog\", \"embedding\": 0.10228318721055984, \"position\": 6}, {\"animal\": \"dog\", \"embedding\": -0.012064791284501553, \"position\": 7}, {\"animal\": \"dog\", \"embedding\": 0.09521343559026718, \"position\": 8}, {\"animal\": \"dog\", \"embedding\": -0.030350157991051674, \"position\": 9}, {\"animal\": \"dog\", \"embedding\": 0.00216468283906579, \"position\": 10}, {\"animal\": \"dog\", \"embedding\": -0.06486445665359497, \"position\": 11}, {\"animal\": \"dog\", \"embedding\": -0.002594356657937169, \"position\": 12}, {\"animal\": \"dog\", \"embedding\": 0.006218955386430025, \"position\": 13}, {\"animal\": \"dog\", \"embedding\": -0.003928696271032095, \"position\": 14}, {\"animal\": \"dog\", \"embedding\": -0.030624518170952797, \"position\": 15}, {\"animal\": \"dog\", \"embedding\": -0.047911498695611954, \"position\": 16}, {\"animal\": \"dog\", \"embedding\": -0.019300563260912895, \"position\": 17}, {\"animal\": \"dog\", \"embedding\": -0.05988546088337898, \"position\": 18}, {\"animal\": \"dog\", \"embedding\": -0.1041673868894577, \"position\": 19}, {\"animal\": \"dog\", \"embedding\": -0.08614886552095413, \"position\": 20}, {\"animal\": \"dog\", \"embedding\": 0.03635948523879051, \"position\": 21}, {\"animal\": \"dog\", \"embedding\": -0.025526152923703194, \"position\": 22}, {\"animal\": \"dog\", \"embedding\": 0.0016389002557843924, \"position\": 23}, {\"animal\": \"dog\", \"embedding\": -0.07144202291965485, \"position\": 24}, {\"animal\": \"dog\", \"embedding\": 0.06167998164892197, \"position\": 25}, {\"animal\": \"dog\", \"embedding\": 0.017194632440805435, \"position\": 26}, {\"animal\": \"dog\", \"embedding\": -0.0566110722720623, \"position\": 27}, {\"animal\": \"dog\", \"embedding\": 0.02481217496097088, \"position\": 28}, {\"animal\": \"dog\", \"embedding\": -0.07782232016324997, \"position\": 29}, {\"animal\": \"dog\", \"embedding\": -0.03249913826584816, \"position\": 30}, {\"animal\": \"dog\", \"embedding\": -0.008699053898453712, \"position\": 31}, {\"animal\": \"dog\", \"embedding\": -0.011532493866980076, \"position\": 32}, {\"animal\": \"dog\", \"embedding\": 0.03816734254360199, \"position\": 33}, {\"animal\": \"dog\", \"embedding\": -0.0569307804107666, \"position\": 34}, {\"animal\": \"dog\", \"embedding\": -0.05327097326517105, \"position\": 35}, {\"animal\": \"dog\", \"embedding\": 0.004925676621496677, \"position\": 36}, {\"animal\": \"dog\", \"embedding\": 0.032500606030225754, \"position\": 37}, {\"animal\": \"dog\", \"embedding\": 0.07253244519233704, \"position\": 38}, {\"animal\": \"dog\", \"embedding\": 0.03298495337367058, \"position\": 39}, {\"animal\": \"dog\", \"embedding\": 0.02472294308245182, \"position\": 40}, {\"animal\": \"dog\", \"embedding\": -0.08334524929523468, \"position\": 41}, {\"animal\": \"dog\", \"embedding\": -0.01568584330379963, \"position\": 42}, {\"animal\": \"dog\", \"embedding\": -0.04811973124742508, \"position\": 43}, {\"animal\": \"dog\", \"embedding\": -0.0034772511571645737, \"position\": 44}, {\"animal\": \"dog\", \"embedding\": 0.0043505458161234856, \"position\": 45}, {\"animal\": \"dog\", \"embedding\": -0.035895638167858124, \"position\": 46}, {\"animal\": \"dog\", \"embedding\": -0.051854055374860764, \"position\": 47}, {\"animal\": \"dog\", \"embedding\": 0.015673262998461723, \"position\": 48}, {\"animal\": \"dog\", \"embedding\": 0.0035223623272031546, \"position\": 49}, {\"animal\": \"dog\", \"embedding\": -0.010323265567421913, \"position\": 50}, {\"animal\": \"dog\", \"embedding\": 0.04764167591929436, \"position\": 51}, {\"animal\": \"dog\", \"embedding\": -0.04015855863690376, \"position\": 52}, {\"animal\": \"dog\", \"embedding\": -0.009099465794861317, \"position\": 53}, {\"animal\": \"dog\", \"embedding\": -0.03463490679860115, \"position\": 54}, {\"animal\": \"dog\", \"embedding\": -0.036981791257858276, \"position\": 55}, {\"animal\": \"dog\", \"embedding\": -0.040840186178684235, \"position\": 56}, {\"animal\": \"dog\", \"embedding\": 0.01771903596818447, \"position\": 57}, {\"animal\": \"dog\", \"embedding\": -0.009393063373863697, \"position\": 58}, {\"animal\": \"dog\", \"embedding\": -0.05363636463880539, \"position\": 59}, {\"animal\": \"dog\", \"embedding\": 0.011132970452308655, \"position\": 60}, {\"animal\": \"dog\", \"embedding\": 0.01618044637143612, \"position\": 61}, {\"animal\": \"dog\", \"embedding\": 0.013784712180495262, \"position\": 62}, {\"animal\": \"dog\", \"embedding\": 0.02831323631107807, \"position\": 63}, {\"animal\": \"dog\", \"embedding\": 0.04025879129767418, \"position\": 64}, {\"animal\": \"dog\", \"embedding\": 0.020901843905448914, \"position\": 65}, {\"animal\": \"dog\", \"embedding\": -0.01446566078811884, \"position\": 66}, {\"animal\": \"dog\", \"embedding\": -0.001599957817234099, \"position\": 67}, {\"animal\": \"dog\", \"embedding\": -0.004975095856934786, \"position\": 68}, {\"animal\": \"dog\", \"embedding\": 0.01207258552312851, \"position\": 69}, {\"animal\": \"dog\", \"embedding\": 0.04553656652569771, \"position\": 70}, {\"animal\": \"dog\", \"embedding\": 0.013122199103236198, \"position\": 71}, {\"animal\": \"dog\", \"embedding\": 0.07058051973581314, \"position\": 72}, {\"animal\": \"dog\", \"embedding\": -0.03082926571369171, \"position\": 73}, {\"animal\": \"dog\", \"embedding\": 0.030435528606176376, \"position\": 74}, {\"animal\": \"dog\", \"embedding\": -0.10847663134336472, \"position\": 75}, {\"animal\": \"dog\", \"embedding\": 0.055476654320955276, \"position\": 76}, {\"animal\": \"dog\", \"embedding\": -0.017531754449009895, \"position\": 77}, {\"animal\": \"dog\", \"embedding\": 0.1643153876066208, \"position\": 78}, {\"animal\": \"dog\", \"embedding\": 0.05145590007305145, \"position\": 79}, {\"animal\": \"dog\", \"embedding\": -0.02768351137638092, \"position\": 80}, {\"animal\": \"dog\", \"embedding\": -0.029959024861454964, \"position\": 81}, {\"animal\": \"dog\", \"embedding\": -0.05695224180817604, \"position\": 82}, {\"animal\": \"dog\", \"embedding\": 0.05682338401675224, \"position\": 83}, {\"animal\": \"dog\", \"embedding\": 0.050946734845638275, \"position\": 84}, {\"animal\": \"dog\", \"embedding\": 0.015132096596062183, \"position\": 85}, {\"animal\": \"dog\", \"embedding\": -0.0012805460719391704, \"position\": 86}, {\"animal\": \"dog\", \"embedding\": 0.023994985967874527, \"position\": 87}, {\"animal\": \"dog\", \"embedding\": -0.0632866695523262, \"position\": 88}, {\"animal\": \"dog\", \"embedding\": 0.028871750459074974, \"position\": 89}, {\"animal\": \"dog\", \"embedding\": -0.05534108728170395, \"position\": 90}, {\"animal\": \"dog\", \"embedding\": -0.034939344972372055, \"position\": 91}, {\"animal\": \"dog\", \"embedding\": 0.030283333733677864, \"position\": 92}, {\"animal\": \"dog\", \"embedding\": 0.026885908097028732, \"position\": 93}, {\"animal\": \"dog\", \"embedding\": -0.08350417017936707, \"position\": 94}, {\"animal\": \"dog\", \"embedding\": 0.018362293019890785, \"position\": 95}, {\"animal\": \"dog\", \"embedding\": -0.03515780344605446, \"position\": 96}, {\"animal\": \"dog\", \"embedding\": -0.08281918615102768, \"position\": 97}, {\"animal\": \"dog\", \"embedding\": -0.07189119607210159, \"position\": 98}, {\"animal\": \"dog\", \"embedding\": 0.19799093902111053, \"position\": 99}, {\"animal\": \"dog\", \"embedding\": 0.01641560159623623, \"position\": 100}, {\"animal\": \"dog\", \"embedding\": 0.04458478093147278, \"position\": 101}, {\"animal\": \"dog\", \"embedding\": -0.003755447454750538, \"position\": 102}, {\"animal\": \"dog\", \"embedding\": -0.03850797936320305, \"position\": 103}, {\"animal\": \"dog\", \"embedding\": 0.053483545780181885, \"position\": 104}, {\"animal\": \"dog\", \"embedding\": -0.0034694005735218525, \"position\": 105}, {\"animal\": \"dog\", \"embedding\": -0.04348180070519447, \"position\": 106}, {\"animal\": \"dog\", \"embedding\": 0.06338968873023987, \"position\": 107}, {\"animal\": \"dog\", \"embedding\": -0.013175569474697113, \"position\": 108}, {\"animal\": \"dog\", \"embedding\": -0.019762825220823288, \"position\": 109}, {\"animal\": \"dog\", \"embedding\": -0.045273832976818085, \"position\": 110}, {\"animal\": \"dog\", \"embedding\": 0.020712850615382195, \"position\": 111}, {\"animal\": \"dog\", \"embedding\": -0.05651763454079628, \"position\": 112}, {\"animal\": \"dog\", \"embedding\": 0.05744059756398201, \"position\": 113}, {\"animal\": \"dog\", \"embedding\": 0.055534280836582184, \"position\": 114}, {\"animal\": \"dog\", \"embedding\": 0.021156515926122665, \"position\": 115}, {\"animal\": \"dog\", \"embedding\": -0.1009354218840599, \"position\": 116}, {\"animal\": \"dog\", \"embedding\": -0.03430286794900894, \"position\": 117}, {\"animal\": \"dog\", \"embedding\": 0.0293644480407238, \"position\": 118}, {\"animal\": \"dog\", \"embedding\": -0.0332467183470726, \"position\": 119}, {\"animal\": \"dog\", \"embedding\": 0.028912032023072243, \"position\": 120}, {\"animal\": \"dog\", \"embedding\": 0.030096786096692085, \"position\": 121}, {\"animal\": \"dog\", \"embedding\": -0.051864609122276306, \"position\": 122}, {\"animal\": \"dog\", \"embedding\": 0.008204172365367413, \"position\": 123}, {\"animal\": \"dog\", \"embedding\": -0.016697708517313004, \"position\": 124}, {\"animal\": \"dog\", \"embedding\": -0.08435996621847153, \"position\": 125}, {\"animal\": \"dog\", \"embedding\": 0.01114204153418541, \"position\": 126}, {\"animal\": \"dog\", \"embedding\": -5.923913331860518e-33, \"position\": 127}, {\"animal\": \"dog\", \"embedding\": 0.030650777742266655, \"position\": 128}, {\"animal\": \"dog\", \"embedding\": -0.08504284918308258, \"position\": 129}, {\"animal\": \"dog\", \"embedding\": 0.0027174956630915403, \"position\": 130}, {\"animal\": \"dog\", \"embedding\": -0.04106851667165756, \"position\": 131}, {\"animal\": \"dog\", \"embedding\": -0.04272565245628357, \"position\": 132}, {\"animal\": \"dog\", \"embedding\": 0.041027553379535675, \"position\": 133}, {\"animal\": \"dog\", \"embedding\": 0.0294408667832613, \"position\": 134}, {\"animal\": \"dog\", \"embedding\": 0.03645971789956093, \"position\": 135}, {\"animal\": \"dog\", \"embedding\": -0.12123750895261765, \"position\": 136}, {\"animal\": \"dog\", \"embedding\": 0.013488640077412128, \"position\": 137}, {\"animal\": \"dog\", \"embedding\": -0.013879092410206795, \"position\": 138}, {\"animal\": \"dog\", \"embedding\": 0.03126835823059082, \"position\": 139}, {\"animal\": \"dog\", \"embedding\": -0.02161930501461029, \"position\": 140}, {\"animal\": \"dog\", \"embedding\": 0.016177335754036903, \"position\": 141}, {\"animal\": \"dog\", \"embedding\": 0.11223004758358002, \"position\": 142}, {\"animal\": \"dog\", \"embedding\": -0.006708204746246338, \"position\": 143}, {\"animal\": \"dog\", \"embedding\": -0.0018929342040792108, \"position\": 144}, {\"animal\": \"dog\", \"embedding\": 0.05322014540433884, \"position\": 145}, {\"animal\": \"dog\", \"embedding\": 0.03261099010705948, \"position\": 146}, {\"animal\": \"dog\", \"embedding\": -0.03776618838310242, \"position\": 147}, {\"animal\": \"dog\", \"embedding\": -0.04691636934876442, \"position\": 148}, {\"animal\": \"dog\", \"embedding\": 0.0619485080242157, \"position\": 149}, {\"animal\": \"dog\", \"embedding\": 0.06361379474401474, \"position\": 150}, {\"animal\": \"dog\", \"embedding\": 0.05011941120028496, \"position\": 151}, {\"animal\": \"dog\", \"embedding\": -0.007603948004543781, \"position\": 152}, {\"animal\": \"dog\", \"embedding\": -0.021480945870280266, \"position\": 153}, {\"animal\": \"dog\", \"embedding\": -0.03778751194477081, \"position\": 154}, {\"animal\": \"dog\", \"embedding\": -0.08291468769311905, \"position\": 155}, {\"animal\": \"dog\", \"embedding\": -0.026290450245141983, \"position\": 156}, {\"animal\": \"dog\", \"embedding\": 0.03614022210240364, \"position\": 157}, {\"animal\": \"dog\", \"embedding\": 0.04127701744437218, \"position\": 158}, {\"animal\": \"dog\", \"embedding\": 0.014518577605485916, \"position\": 159}, {\"animal\": \"dog\", \"embedding\": 0.0734504908323288, \"position\": 160}, {\"animal\": \"dog\", \"embedding\": 0.0006526930956169963, \"position\": 161}, {\"animal\": \"dog\", \"embedding\": -0.08143548667430878, \"position\": 162}, {\"animal\": \"dog\", \"embedding\": -0.05578257888555527, \"position\": 163}, {\"animal\": \"dog\", \"embedding\": -0.04213260859251022, \"position\": 164}, {\"animal\": \"dog\", \"embedding\": -0.09667719155550003, \"position\": 165}, {\"animal\": \"dog\", \"embedding\": -0.04012607783079147, \"position\": 166}, {\"animal\": \"dog\", \"embedding\": 0.028559522703289986, \"position\": 167}, {\"animal\": \"dog\", \"embedding\": 0.1290501356124878, \"position\": 168}, {\"animal\": \"dog\", \"embedding\": 0.01044805534183979, \"position\": 169}, {\"animal\": \"dog\", \"embedding\": 0.02510608546435833, \"position\": 170}, {\"animal\": \"dog\", \"embedding\": 0.017339762300252914, \"position\": 171}, {\"animal\": \"dog\", \"embedding\": -0.027208272367715836, \"position\": 172}, {\"animal\": \"dog\", \"embedding\": -0.0049482979811728, \"position\": 173}, {\"animal\": \"dog\", \"embedding\": 0.015734028071165085, \"position\": 174}, {\"animal\": \"dog\", \"embedding\": 0.03437737375497818, \"position\": 175}, {\"animal\": \"dog\", \"embedding\": -0.04448755457997322, \"position\": 176}, {\"animal\": \"dog\", \"embedding\": 0.02083745039999485, \"position\": 177}, {\"animal\": \"dog\", \"embedding\": 0.02751891128718853, \"position\": 178}, {\"animal\": \"dog\", \"embedding\": -0.01431448757648468, \"position\": 179}, {\"animal\": \"dog\", \"embedding\": 0.028818361461162567, \"position\": 180}, {\"animal\": \"dog\", \"embedding\": -0.021267399191856384, \"position\": 181}, {\"animal\": \"dog\", \"embedding\": 0.008817851543426514, \"position\": 182}, {\"animal\": \"dog\", \"embedding\": 0.009855779819190502, \"position\": 183}, {\"animal\": \"dog\", \"embedding\": 0.0029994479846209288, \"position\": 184}, {\"animal\": \"dog\", \"embedding\": -0.02380906231701374, \"position\": 185}, {\"animal\": \"dog\", \"embedding\": 0.01304733008146286, \"position\": 186}, {\"animal\": \"dog\", \"embedding\": 0.06634410470724106, \"position\": 187}, {\"animal\": \"dog\", \"embedding\": 0.06891762465238571, \"position\": 188}, {\"animal\": \"dog\", \"embedding\": 0.08254698663949966, \"position\": 189}, {\"animal\": \"dog\", \"embedding\": 0.008786113932728767, \"position\": 190}, {\"animal\": \"dog\", \"embedding\": -0.014059261418879032, \"position\": 191}, {\"animal\": \"dog\", \"embedding\": 0.09107065200805664, \"position\": 192}, {\"animal\": \"dog\", \"embedding\": -0.1221766248345375, \"position\": 193}, {\"animal\": \"dog\", \"embedding\": -0.04530944302678108, \"position\": 194}, {\"animal\": \"dog\", \"embedding\": -0.018081234768033028, \"position\": 195}, {\"animal\": \"dog\", \"embedding\": -0.022172048687934875, \"position\": 196}, {\"animal\": \"dog\", \"embedding\": 0.021522752940654755, \"position\": 197}, {\"animal\": \"dog\", \"embedding\": -0.038843415677547455, \"position\": 198}, {\"animal\": \"dog\", \"embedding\": -0.01955721341073513, \"position\": 199}, {\"animal\": \"dog\", \"embedding\": 0.07971450686454773, \"position\": 200}, {\"animal\": \"dog\", \"embedding\": -0.01576269045472145, \"position\": 201}, {\"animal\": \"dog\", \"embedding\": 0.06888051331043243, \"position\": 202}, {\"animal\": \"dog\", \"embedding\": -0.01556633971631527, \"position\": 203}, {\"animal\": \"dog\", \"embedding\": 0.022782083600759506, \"position\": 204}, {\"animal\": \"dog\", \"embedding\": 0.02529541775584221, \"position\": 205}, {\"animal\": \"dog\", \"embedding\": -0.031191565096378326, \"position\": 206}, {\"animal\": \"dog\", \"embedding\": -0.03350035846233368, \"position\": 207}, {\"animal\": \"dog\", \"embedding\": -0.0215879175812006, \"position\": 208}, {\"animal\": \"dog\", \"embedding\": -0.010069506242871284, \"position\": 209}, {\"animal\": \"dog\", \"embedding\": 0.00550079857930541, \"position\": 210}, {\"animal\": \"dog\", \"embedding\": 0.048977430909872055, \"position\": 211}, {\"animal\": \"dog\", \"embedding\": -0.021504582837224007, \"position\": 212}, {\"animal\": \"dog\", \"embedding\": 0.0638372004032135, \"position\": 213}, {\"animal\": \"dog\", \"embedding\": -0.019716935232281685, \"position\": 214}, {\"animal\": \"dog\", \"embedding\": -0.030271977186203003, \"position\": 215}, {\"animal\": \"dog\", \"embedding\": 0.006232741754502058, \"position\": 216}, {\"animal\": \"dog\", \"embedding\": 0.045180611312389374, \"position\": 217}, {\"animal\": \"dog\", \"embedding\": -0.04580971226096153, \"position\": 218}, {\"animal\": \"dog\", \"embedding\": -0.04915788397192955, \"position\": 219}, {\"animal\": \"dog\", \"embedding\": 0.08708895742893219, \"position\": 220}, {\"animal\": \"dog\", \"embedding\": 0.02734500542283058, \"position\": 221}, {\"animal\": \"dog\", \"embedding\": 0.0905928835272789, \"position\": 222}, {\"animal\": \"dog\", \"embedding\": 3.432160283730928e-33, \"position\": 223}, {\"animal\": \"dog\", \"embedding\": 0.0625440925359726, \"position\": 224}, {\"animal\": \"dog\", \"embedding\": 0.028967853635549545, \"position\": 225}, {\"animal\": \"dog\", \"embedding\": 5.452089317259379e-05, \"position\": 226}, {\"animal\": \"dog\", \"embedding\": 0.0914405807852745, \"position\": 227}, {\"animal\": \"dog\", \"embedding\": -0.030373184010386467, \"position\": 228}, {\"animal\": \"dog\", \"embedding\": 0.00491048488765955, \"position\": 229}, {\"animal\": \"dog\", \"embedding\": -0.02546708844602108, \"position\": 230}, {\"animal\": \"dog\", \"embedding\": 0.06670119613409042, \"position\": 231}, {\"animal\": \"dog\", \"embedding\": -0.03414908051490784, \"position\": 232}, {\"animal\": \"dog\", \"embedding\": 0.047809895128011703, \"position\": 233}, {\"animal\": \"dog\", \"embedding\": -0.034206729382276535, \"position\": 234}, {\"animal\": \"dog\", \"embedding\": 0.00790240429341793, \"position\": 235}, {\"animal\": \"dog\", \"embedding\": 0.10791854560375214, \"position\": 236}, {\"animal\": \"dog\", \"embedding\": 0.009035082533955574, \"position\": 237}, {\"animal\": \"dog\", \"embedding\": 0.007591914851218462, \"position\": 238}, {\"animal\": \"dog\", \"embedding\": 0.08858625590801239, \"position\": 239}, {\"animal\": \"dog\", \"embedding\": 0.0037384198512881994, \"position\": 240}, {\"animal\": \"dog\", \"embedding\": -0.030471039935946465, \"position\": 241}, {\"animal\": \"dog\", \"embedding\": 0.021707171574234962, \"position\": 242}, {\"animal\": \"dog\", \"embedding\": -0.004327238071709871, \"position\": 243}, {\"animal\": \"dog\", \"embedding\": -0.1447167545557022, \"position\": 244}, {\"animal\": \"dog\", \"embedding\": 0.011570536531507969, \"position\": 245}, {\"animal\": \"dog\", \"embedding\": 0.0183675866574049, \"position\": 246}, {\"animal\": \"dog\", \"embedding\": -0.02585013210773468, \"position\": 247}, {\"animal\": \"dog\", \"embedding\": -0.051939040422439575, \"position\": 248}, {\"animal\": \"dog\", \"embedding\": 0.039417412132024765, \"position\": 249}, {\"animal\": \"dog\", \"embedding\": 0.037535808980464935, \"position\": 250}, {\"animal\": \"dog\", \"embedding\": -0.014728976413607597, \"position\": 251}, {\"animal\": \"dog\", \"embedding\": -0.0222414992749691, \"position\": 252}, {\"animal\": \"dog\", \"embedding\": -0.0487109050154686, \"position\": 253}, {\"animal\": \"dog\", \"embedding\": -0.006519529037177563, \"position\": 254}, {\"animal\": \"dog\", \"embedding\": -0.039568811655044556, \"position\": 255}, {\"animal\": \"dog\", \"embedding\": -0.04127315431833267, \"position\": 256}, {\"animal\": \"dog\", \"embedding\": -0.028437381610274315, \"position\": 257}, {\"animal\": \"dog\", \"embedding\": 0.010693822056055069, \"position\": 258}, {\"animal\": \"dog\", \"embedding\": 0.15860560536384583, \"position\": 259}, {\"animal\": \"dog\", \"embedding\": 0.04765571281313896, \"position\": 260}, {\"animal\": \"dog\", \"embedding\": -0.04726944863796234, \"position\": 261}, {\"animal\": \"dog\", \"embedding\": -0.06290390342473984, \"position\": 262}, {\"animal\": \"dog\", \"embedding\": 0.00855184905230999, \"position\": 263}, {\"animal\": \"dog\", \"embedding\": 0.0599067322909832, \"position\": 264}, {\"animal\": \"dog\", \"embedding\": 0.019311314448714256, \"position\": 265}, {\"animal\": \"dog\", \"embedding\": -0.03222969174385071, \"position\": 266}, {\"animal\": \"dog\", \"embedding\": 0.11158391833305359, \"position\": 267}, {\"animal\": \"dog\", \"embedding\": 0.016122890636324883, \"position\": 268}, {\"animal\": \"dog\", \"embedding\": 0.052699293941259384, \"position\": 269}, {\"animal\": \"dog\", \"embedding\": -0.017932994291186333, \"position\": 270}, {\"animal\": \"dog\", \"embedding\": -0.005921711679548025, \"position\": 271}, {\"animal\": \"dog\", \"embedding\": 0.05291884392499924, \"position\": 272}, {\"animal\": \"dog\", \"embedding\": 0.018423588946461678, \"position\": 273}, {\"animal\": \"dog\", \"embedding\": -0.04744262993335724, \"position\": 274}, {\"animal\": \"dog\", \"embedding\": -0.01432979479432106, \"position\": 275}, {\"animal\": \"dog\", \"embedding\": 0.030034014955163002, \"position\": 276}, {\"animal\": \"dog\", \"embedding\": -0.0733371451497078, \"position\": 277}, {\"animal\": \"dog\", \"embedding\": -0.012593499384820461, \"position\": 278}, {\"animal\": \"dog\", \"embedding\": 0.004521314986050129, \"position\": 279}, {\"animal\": \"dog\", \"embedding\": -0.09498968720436096, \"position\": 280}, {\"animal\": \"dog\", \"embedding\": 0.01882064901292324, \"position\": 281}, {\"animal\": \"dog\", \"embedding\": -0.029087064787745476, \"position\": 282}, {\"animal\": \"dog\", \"embedding\": -0.005304806865751743, \"position\": 283}, {\"animal\": \"dog\", \"embedding\": -0.002841681009158492, \"position\": 284}, {\"animal\": \"dog\", \"embedding\": 0.06969695538282394, \"position\": 285}, {\"animal\": \"dog\", \"embedding\": 0.012458983808755875, \"position\": 286}, {\"animal\": \"dog\", \"embedding\": 0.1219218447804451, \"position\": 287}, {\"animal\": \"dog\", \"embedding\": -0.10483532398939133, \"position\": 288}, {\"animal\": \"dog\", \"embedding\": -0.05372532457113266, \"position\": 289}, {\"animal\": \"dog\", \"embedding\": -0.012763258069753647, \"position\": 290}, {\"animal\": \"dog\", \"embedding\": -0.027916932478547096, \"position\": 291}, {\"animal\": \"dog\", \"embedding\": 0.05001473054289818, \"position\": 292}, {\"animal\": \"dog\", \"embedding\": -0.07645857334136963, \"position\": 293}, {\"animal\": \"dog\", \"embedding\": 0.024287302047014236, \"position\": 294}, {\"animal\": \"dog\", \"embedding\": 0.04536539688706398, \"position\": 295}, {\"animal\": \"dog\", \"embedding\": -0.02898694947361946, \"position\": 296}, {\"animal\": \"dog\", \"embedding\": 0.010187732055783272, \"position\": 297}, {\"animal\": \"dog\", \"embedding\": -0.010616554878652096, \"position\": 298}, {\"animal\": \"dog\", \"embedding\": 0.031045669689774513, \"position\": 299}, {\"animal\": \"dog\", \"embedding\": -0.04648565873503685, \"position\": 300}, {\"animal\": \"dog\", \"embedding\": 0.0045740241184830666, \"position\": 301}, {\"animal\": \"dog\", \"embedding\": 0.007662663236260414, \"position\": 302}, {\"animal\": \"dog\", \"embedding\": -0.006381151732057333, \"position\": 303}, {\"animal\": \"dog\", \"embedding\": -0.07788290828466415, \"position\": 304}, {\"animal\": \"dog\", \"embedding\": -0.0652913749217987, \"position\": 305}, {\"animal\": \"dog\", \"embedding\": -0.047676824033260345, \"position\": 306}, {\"animal\": \"dog\", \"embedding\": 0.010323760099709034, \"position\": 307}, {\"animal\": \"dog\", \"embedding\": -0.056628257036209106, \"position\": 308}, {\"animal\": \"dog\", \"embedding\": -0.011250725947320461, \"position\": 309}, {\"animal\": \"dog\", \"embedding\": 0.0021042958833277225, \"position\": 310}, {\"animal\": \"dog\", \"embedding\": 0.06386008113622665, \"position\": 311}, {\"animal\": \"dog\", \"embedding\": -0.013329907320439816, \"position\": 312}, {\"animal\": \"dog\", \"embedding\": -0.03017304837703705, \"position\": 313}, {\"animal\": \"dog\", \"embedding\": -0.00982383918017149, \"position\": 314}, {\"animal\": \"dog\", \"embedding\": 0.054960258305072784, \"position\": 315}, {\"animal\": \"dog\", \"embedding\": -0.021686753258109093, \"position\": 316}, {\"animal\": \"dog\", \"embedding\": -0.053316496312618256, \"position\": 317}, {\"animal\": \"dog\", \"embedding\": -0.028597626835107803, \"position\": 318}, {\"animal\": \"dog\", \"embedding\": -1.3319516156684585e-08, \"position\": 319}, {\"animal\": \"dog\", \"embedding\": -0.02869226783514023, \"position\": 320}, {\"animal\": \"dog\", \"embedding\": -0.029173804447054863, \"position\": 321}, {\"animal\": \"dog\", \"embedding\": -0.04298397898674011, \"position\": 322}, {\"animal\": \"dog\", \"embedding\": -0.019562074914574623, \"position\": 323}, {\"animal\": \"dog\", \"embedding\": 0.09974844008684158, \"position\": 324}, {\"animal\": \"dog\", \"embedding\": 0.06951721012592316, \"position\": 325}, {\"animal\": \"dog\", \"embedding\": -0.030107151716947556, \"position\": 326}, {\"animal\": \"dog\", \"embedding\": -0.040130823850631714, \"position\": 327}, {\"animal\": \"dog\", \"embedding\": -0.0066306255757808685, \"position\": 328}, {\"animal\": \"dog\", \"embedding\": 0.026162946596741676, \"position\": 329}, {\"animal\": \"dog\", \"embedding\": 0.044257305562496185, \"position\": 330}, {\"animal\": \"dog\", \"embedding\": -0.01636774279177189, \"position\": 331}, {\"animal\": \"dog\", \"embedding\": -0.07000909000635147, \"position\": 332}, {\"animal\": \"dog\", \"embedding\": 0.013445564545691013, \"position\": 333}, {\"animal\": \"dog\", \"embedding\": 0.04655250906944275, \"position\": 334}, {\"animal\": \"dog\", \"embedding\": -0.01515033096075058, \"position\": 335}, {\"animal\": \"dog\", \"embedding\": -0.053437650203704834, \"position\": 336}, {\"animal\": \"dog\", \"embedding\": 0.0398612841963768, \"position\": 337}, {\"animal\": \"dog\", \"embedding\": 0.0628618523478508, \"position\": 338}, {\"animal\": \"dog\", \"embedding\": 0.07714782655239105, \"position\": 339}, {\"animal\": \"dog\", \"embedding\": -0.05102375149726868, \"position\": 340}, {\"animal\": \"dog\", \"embedding\": 0.030271481722593307, \"position\": 341}, {\"animal\": \"dog\", \"embedding\": 0.05550659820437431, \"position\": 342}, {\"animal\": \"dog\", \"embedding\": 0.002205820754170418, \"position\": 343}, {\"animal\": \"dog\", \"embedding\": -0.051227983087301254, \"position\": 344}, {\"animal\": \"dog\", \"embedding\": -0.035941120237112045, \"position\": 345}, {\"animal\": \"dog\", \"embedding\": 0.04560363292694092, \"position\": 346}, {\"animal\": \"dog\", \"embedding\": 0.10606122761964798, \"position\": 347}, {\"animal\": \"dog\", \"embedding\": -0.08217952400445938, \"position\": 348}, {\"animal\": \"dog\", \"embedding\": 0.03809766843914986, \"position\": 349}, {\"animal\": \"dog\", \"embedding\": -0.022630030289292336, \"position\": 350}, {\"animal\": \"dog\", \"embedding\": 0.1406117081642151, \"position\": 351}, {\"animal\": \"dog\", \"embedding\": -0.07618370652198792, \"position\": 352}, {\"animal\": \"dog\", \"embedding\": -0.030086802318692207, \"position\": 353}, {\"animal\": \"dog\", \"embedding\": -0.004035626538097858, \"position\": 354}, {\"animal\": \"dog\", \"embedding\": -0.06968802213668823, \"position\": 355}, {\"animal\": \"dog\", \"embedding\": 0.07609085738658905, \"position\": 356}, {\"animal\": \"dog\", \"embedding\": -0.07924934476613998, \"position\": 357}, {\"animal\": \"dog\", \"embedding\": 0.025034157559275627, \"position\": 358}, {\"animal\": \"dog\", \"embedding\": 0.034040551632642746, \"position\": 359}, {\"animal\": \"dog\", \"embedding\": 0.05042510852217674, \"position\": 360}, {\"animal\": \"dog\", \"embedding\": 0.15210042893886566, \"position\": 361}, {\"animal\": \"dog\", \"embedding\": -0.02008703164756298, \"position\": 362}, {\"animal\": \"dog\", \"embedding\": -0.07890965044498444, \"position\": 363}, {\"animal\": \"dog\", \"embedding\": -0.0005837315693497658, \"position\": 364}, {\"animal\": \"dog\", \"embedding\": 0.06229373440146446, \"position\": 365}, {\"animal\": \"dog\", \"embedding\": 0.026448020711541176, \"position\": 366}, {\"animal\": \"dog\", \"embedding\": -0.12159687280654907, \"position\": 367}, {\"animal\": \"dog\", \"embedding\": -0.028296884149312973, \"position\": 368}, {\"animal\": \"dog\", \"embedding\": -0.0564231351017952, \"position\": 369}, {\"animal\": \"dog\", \"embedding\": -0.09823242574930191, \"position\": 370}, {\"animal\": \"dog\", \"embedding\": -0.00741284666582942, \"position\": 371}, {\"animal\": \"dog\", \"embedding\": 0.02790716104209423, \"position\": 372}, {\"animal\": \"dog\", \"embedding\": 0.06906429678201675, \"position\": 373}, {\"animal\": \"dog\", \"embedding\": 0.01500491239130497, \"position\": 374}, {\"animal\": \"dog\", \"embedding\": 0.005070974584668875, \"position\": 375}, {\"animal\": \"dog\", \"embedding\": -0.013118354603648186, \"position\": 376}, {\"animal\": \"dog\", \"embedding\": -0.048034701496362686, \"position\": 377}, {\"animal\": \"dog\", \"embedding\": -0.016735391691327095, \"position\": 378}, {\"animal\": \"dog\", \"embedding\": 0.03667037561535835, \"position\": 379}, {\"animal\": \"dog\", \"embedding\": 0.11144455522298813, \"position\": 380}, {\"animal\": \"dog\", \"embedding\": 0.029856905341148376, \"position\": 381}, {\"animal\": \"dog\", \"embedding\": 0.02390548773109913, \"position\": 382}, {\"animal\": \"dog\", \"embedding\": 0.11009308695793152, \"position\": 383}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "def heatmap(df):\n",
    "    return alt.Chart(\n",
    "        df\n",
    "    ).encode(\n",
    "        alt.X(\"position:N\", title=\"\").axis(labels=False, ticks=False),\n",
    "        alt.Y(\"animal:N\", title=\"\", sort=df[\"animal\"].unique()).axis(labelLimit=300, tickWidth=0, labelFontWeight=\"bold\"),\n",
    "        alt.Color(\"embedding:Q\").scale(scheme=\"goldred\").legend(None),\n",
    "    ).mark_rect(\n",
    "        width=3\n",
    "    ).properties(\n",
    "        width=alt.Step(3), height=alt.Step(50)\n",
    "    ).configure_axis(\n",
    "        grid=False,\n",
    "        domain=False\n",
    "    )\n",
    "\n",
    "heatmap(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's reduce the dimensionality. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>[-0.41192373633384705, 3.2534185123722636e-08]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>[0.4119238257408142, 3.253417801829528e-08]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         embeddings\n",
       "cat  [-0.41192373633384705, 3.2534185123722636e-08]\n",
       "dog     [0.4119238257408142, 3.253417801829528e-08]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def df_to_reduced(df):\n",
    "  # Convert embeddings into a 2-dimensional array\n",
    "  reducer = PCA(n_components=2)\n",
    "\n",
    "  \n",
    "  return (\n",
    "    df.copy()\n",
    "    \n",
    "    .assign(\n",
    "      embeddings=reducer.fit_transform(\n",
    "        np.stack(df[\"embeddings\"])\n",
    "      ).tolist())\n",
    "  )\n",
    "\n",
    "df_to_reduced(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make a function for a scatterplot. {.slide-code .smaller}\n",
    "\n",
    "::: aside\n",
    "<https://altair-viz.github.io/gallery/scatter_tooltips.html>\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "def scatterplot(data: pd.DataFrame, tooltips=False, labels=False, jitter=0.0, width=800, height=200):    \n",
    "    data[\"xJittered\"] = data['x'] + np.random.normal(0, jitter, size=len(data))\n",
    "    data[\"yJittered\"] = data['y'] + np.random.normal(0, jitter, size=len(data))\n",
    "    \n",
    "    base_chart = (\n",
    "        alt.Chart(data).encode(\n",
    "            alt.X(\"xJittered\", scale=alt.Scale(zero=False), title=None),\n",
    "            alt.Y(\"yJittered\", scale=alt.Scale(zero=False), title=None),\n",
    "        ).properties(width=width, height=height))\n",
    "\n",
    "    if tooltips:\n",
    "        base_chart = base_chart.encode(alt.Tooltip([\"text\"]))\n",
    "\n",
    "    circles = base_chart.mark_circle(size=200, color=\"crimson\", stroke=\"white\", strokeWidth=1)\n",
    "\n",
    "    if labels:\n",
    "        labels = base_chart.mark_text(fontSize=13,align=\"left\",baseline=\"bottom\",dx=5).encode(text=\"text\")\n",
    "        chart = circles + labels\n",
    "    else:\n",
    "        chart = circles\n",
    "\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's display the scatterplot. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4947ff4f6d454a8db7be8abdff85a9b0.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4947ff4f6d454a8db7be8abdff85a9b0.vega-embed details,\n",
       "  #altair-viz-4947ff4f6d454a8db7be8abdff85a9b0.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4947ff4f6d454a8db7be8abdff85a9b0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4947ff4f6d454a8db7be8abdff85a9b0\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4947ff4f6d454a8db7be8abdff85a9b0\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"crimson\", \"size\": 200, \"stroke\": \"white\", \"strokeWidth\": 1}, \"encoding\": {\"x\": {\"field\": \"xJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}, \"y\": {\"field\": \"yJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"bottom\", \"dx\": 5, \"fontSize\": 13}, \"encoding\": {\"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"xJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}, \"y\": {\"field\": \"yJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-578732e8a3d570527720372f0c2b0d12\"}, \"height\": 200, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-578732e8a3d570527720372f0c2b0d12\": [{\"text\": \"cat\", \"x\": -0.41192373633384705, \"y\": 3.2534185123722636e-08, \"xJittered\": -0.41192373633384705, \"yJittered\": 3.2534185123722636e-08}, {\"text\": \"dog\", \"x\": 0.4119238257408142, \"y\": 3.253417801829528e-08, \"xJittered\": 0.4119238257408142, \"yJittered\": 3.253417801829528e-08}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced = df_to_reduced(df1)\n",
    "\n",
    "source = pd.DataFrame({\n",
    "    \"text\": df_reduced.index,\n",
    "    \"x\": df_reduced[\"embeddings\"].apply(lambda x: x[0]).to_list(),\n",
    "    \"y\": df_reduced[\"embeddings\"].apply(lambda x: x[1]).to_list(),\n",
    "})\n",
    "\n",
    "scatterplot(source, labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add some more words. {.slide-code}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>[0.03733039, 0.0511619, -0.00030606816, 0.0602...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>[-0.05314704, 0.014194381, 0.0071458234, 0.068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pizza</th>\n",
       "      <td>[-0.08696939, 0.06991054, -0.0150973685, 0.096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>[-0.03095191, 0.018730178, 0.014911181, 0.1197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asymptomatic</th>\n",
       "      <td>[0.031974357, 0.020842418, -0.064985596, 0.171...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     embeddings\n",
       "cat           [0.03733039, 0.0511619, -0.00030606816, 0.0602...\n",
       "dog           [-0.05314704, 0.014194381, 0.0071458234, 0.068...\n",
       "pizza         [-0.08696939, 0.06991054, -0.0150973685, 0.096...\n",
       "coffee        [-0.03095191, 0.018730178, 0.014911181, 0.1197...\n",
       "asymptomatic  [0.031974357, 0.020842418, -0.064985596, 0.171..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"cat\", \"dog\", \"pizza\", \"coffee\", \"asymptomatic\"]\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    [  [model1.encode(word)]  for word in words ],\n",
    "    index=words, columns=[\"embeddings\"])\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try the scatterplot again. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-bc86f29acf644804b3c0da3dd89fe4f8.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-bc86f29acf644804b3c0da3dd89fe4f8.vega-embed details,\n",
       "  #altair-viz-bc86f29acf644804b3c0da3dd89fe4f8.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-bc86f29acf644804b3c0da3dd89fe4f8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-bc86f29acf644804b3c0da3dd89fe4f8\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-bc86f29acf644804b3c0da3dd89fe4f8\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"crimson\", \"size\": 200, \"stroke\": \"white\", \"strokeWidth\": 1}, \"encoding\": {\"x\": {\"field\": \"xJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}, \"y\": {\"field\": \"yJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"bottom\", \"dx\": 5, \"fontSize\": 13}, \"encoding\": {\"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"xJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}, \"y\": {\"field\": \"yJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-2cb5df878dff5a80c27a57291ca30c15\"}, \"height\": 200, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-2cb5df878dff5a80c27a57291ca30c15\": [{\"text\": \"cat\", \"x\": -0.32588061690330505, \"y\": -0.33052384853363037, \"xJittered\": -0.32588061690330505, \"yJittered\": -0.33052384853363037}, {\"text\": \"dog\", \"x\": -0.34687429666519165, \"y\": -0.4468518793582916, \"xJittered\": -0.34687429666519165, \"yJittered\": -0.4468518793582916}, {\"text\": \"pizza\", \"x\": -0.06750805675983429, \"y\": 0.4830458164215088, \"xJittered\": -0.06750805675983429, \"yJittered\": 0.4830458164215088}, {\"text\": \"coffee\", \"x\": -0.13563542068004608, \"y\": 0.48234328627586365, \"xJittered\": -0.13563542068004608, \"yJittered\": 0.48234328627586365}, {\"text\": \"asymptomatic\", \"x\": 0.8758982419967651, \"y\": -0.18801316618919373, \"xJittered\": 0.8758982419967651, \"yJittered\": -0.18801316618919373}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced = df_to_reduced(df2)\n",
    "\n",
    "source = pd.DataFrame({\n",
    "    \"text\": df_reduced.index,\n",
    "    \"x\": df_reduced[\"embeddings\"].apply(lambda x: x[0]).to_list(),\n",
    "    \"y\": df_reduced[\"embeddings\"].apply(lambda x: x[1]).to_list(),\n",
    "})\n",
    "\n",
    "scatterplot(source, labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Theory of Language  {background=\"#718096\" .text-white .quote-italic}\n",
    "\n",
    "#### Ferdinand de Saussure, *Course in General Linguistics* <small>(1916)</small>\n",
    "\n",
    ":::: columns\n",
    "\n",
    "::: {.column width=\"20%\"}\n",
    "![](assets/saussure-course.png){width=250 class=border style=\"background-color: #fff; border: 2px solid #fff; border-radius: 5px;\"}\n",
    ":::\n",
    "\n",
    "::: {.column width=\"80%\"}\n",
    "Language is a system of signs\n",
    "\n",
    "Signs represent concepts, not things\n",
    "\n",
    "The nature of the sign is arbitrary\n",
    "\n",
    "> (...) what is natural to mankind is not oral speech but the faculty of constructing a language, i.e. a system of distinct signs corresponding to distinct ideas.\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a word in a different language. {.slide-code}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>[0.03733039, 0.0511619, -0.00030606816, 0.0602...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kočka</th>\n",
       "      <td>[-0.05706705, 0.041157562, -0.10440424, 0.0499...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              embeddings\n",
       "cat    [0.03733039, 0.0511619, -0.00030606816, 0.0602...\n",
       "kočka  [-0.05706705, 0.041157562, -0.10440424, 0.0499..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"kočka\" # \"Cat\" in Czech [ˈkot͡ʃka]\n",
    "\n",
    "df3 = pd.concat([\n",
    "  df2, \n",
    "  pd.DataFrame.from_dict({\"embeddings\": { word: model1.encode(word)}}),\n",
    "])\n",
    "\n",
    "df3.loc[[\"cat\", \"kočka\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try the scatterplot again. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9467ca3bc0b94cfb9e4ede89a6794b93.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9467ca3bc0b94cfb9e4ede89a6794b93.vega-embed details,\n",
       "  #altair-viz-9467ca3bc0b94cfb9e4ede89a6794b93.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9467ca3bc0b94cfb9e4ede89a6794b93\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9467ca3bc0b94cfb9e4ede89a6794b93\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9467ca3bc0b94cfb9e4ede89a6794b93\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"crimson\", \"size\": 200, \"stroke\": \"white\", \"strokeWidth\": 1}, \"encoding\": {\"x\": {\"field\": \"xJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}, \"y\": {\"field\": \"yJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"bottom\", \"dx\": 5, \"fontSize\": 13}, \"encoding\": {\"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"xJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}, \"y\": {\"field\": \"yJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-6171aac72a7c711c361561855e4b9b0a\"}, \"height\": 200, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-6171aac72a7c711c361561855e4b9b0a\": [{\"text\": \"cat\", \"x\": -0.39272603392601013, \"y\": -0.3096916079521179, \"xJittered\": -0.39272603392601013, \"yJittered\": -0.3096916079521179}, {\"text\": \"dog\", \"x\": -0.42169713973999023, \"y\": -0.42202842235565186, \"xJittered\": -0.42169713973999023, \"yJittered\": -0.42202842235565186}, {\"text\": \"pizza\", \"x\": -0.13226890563964844, \"y\": 0.3904246687889099, \"xJittered\": -0.13226890563964844, \"yJittered\": 0.3904246687889099}, {\"text\": \"coffee\", \"x\": -0.16058528423309326, \"y\": 0.447518527507782, \"xJittered\": -0.16058528423309326, \"yJittered\": 0.447518527507782}, {\"text\": \"asymptomatic\", \"x\": 0.7457429766654968, \"y\": -0.3583552837371826, \"xJittered\": 0.7457429766654968, \"yJittered\": -0.3583552837371826}, {\"text\": \"ko\\u010dka\", \"x\": 0.36153465509414673, \"y\": 0.25213193893432617, \"xJittered\": 0.36153465509414673, \"yJittered\": 0.25213193893432617}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced = df_to_reduced(df3)\n",
    "\n",
    "source = pd.DataFrame({\n",
    "    \"text\": df_reduced.index,\n",
    "    \"x\": df_reduced[\"embeddings\"].apply(lambda x: x[0]).to_list(),\n",
    "    \"y\": df_reduced[\"embeddings\"].apply(lambda x: x[1]).to_list(),\n",
    "})\n",
    "\n",
    "scatterplot(source, labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try with a different model. {.slide-code}\n",
    "\n",
    "[![](assets/logo-huggingface.svg){class=\"icon\" width=\"40\" height=\"40\"} `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2)\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model2 = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create the embeddings with the new model. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>[0.59055364, -0.3334293, -0.03257506, 0.543022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>[0.280045, -0.24335869, -0.25790253, 0.1898756...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pizza</th>\n",
       "      <td>[-0.31320187, -0.17622907, -0.17177011, -0.066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>[-0.19748689, -0.38310185, -0.1273405, 0.75054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asymptomatic</th>\n",
       "      <td>[0.05101946, -0.042016577, -0.04529487, 0.4346...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kočka</th>\n",
       "      <td>[0.5026489, -0.23199998, -0.008454391, 0.48297...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     embeddings\n",
       "cat           [0.59055364, -0.3334293, -0.03257506, 0.543022...\n",
       "dog           [0.280045, -0.24335869, -0.25790253, 0.1898756...\n",
       "pizza         [-0.31320187, -0.17622907, -0.17177011, -0.066...\n",
       "coffee        [-0.19748689, -0.38310185, -0.1273405, 0.75054...\n",
       "asymptomatic  [0.05101946, -0.042016577, -0.04529487, 0.4346...\n",
       "kočka         [0.5026489, -0.23199998, -0.008454391, 0.48297..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = df3.index.to_list()\n",
    "\n",
    "df4 = pd.DataFrame(\n",
    "    [  [model2.encode(word)]  for word in words ],\n",
    "    index=words, columns=[\"embeddings\"])\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... and let's try the scatterplot again. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-06cbfbdb40264c3c85d579a06f5e30cc.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-06cbfbdb40264c3c85d579a06f5e30cc.vega-embed details,\n",
       "  #altair-viz-06cbfbdb40264c3c85d579a06f5e30cc.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-06cbfbdb40264c3c85d579a06f5e30cc\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-06cbfbdb40264c3c85d579a06f5e30cc\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-06cbfbdb40264c3c85d579a06f5e30cc\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"crimson\", \"size\": 200, \"stroke\": \"white\", \"strokeWidth\": 1}, \"encoding\": {\"x\": {\"field\": \"xJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}, \"y\": {\"field\": \"yJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"bottom\", \"dx\": 5, \"fontSize\": 13}, \"encoding\": {\"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"xJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}, \"y\": {\"field\": \"yJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-d19523b67ae6520b5dc9f944ca01a3f0\"}, \"height\": 200, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-d19523b67ae6520b5dc9f944ca01a3f0\": [{\"text\": \"cat\", \"x\": -3.484766960144043, \"y\": 1.4733586311340332, \"xJittered\": -3.484766960144043, \"yJittered\": 1.4733586311340332}, {\"text\": \"dog\", \"x\": -0.44105127453804016, \"y\": -3.348930597305298, \"xJittered\": -0.44105127453804016, \"yJittered\": -3.348930597305298}, {\"text\": \"pizza\", \"x\": 3.5124003887176514, \"y\": 3.8346683979034424, \"xJittered\": 3.5124003887176514, \"yJittered\": 3.8346683979034424}, {\"text\": \"coffee\", \"x\": 3.1995232105255127, \"y\": -1.5098546743392944, \"xJittered\": 3.1995232105255127, \"yJittered\": -1.5098546743392944}, {\"text\": \"asymptomatic\", \"x\": 0.41154372692108154, \"y\": -1.778046727180481, \"xJittered\": 0.41154372692108154, \"yJittered\": -1.778046727180481}, {\"text\": \"ko\\u010dka\", \"x\": -3.197653293609619, \"y\": 1.3288077116012573, \"xJittered\": -3.197653293609619, \"yJittered\": 1.3288077116012573}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced = df_to_reduced(df4)\n",
    "\n",
    "source = pd.DataFrame({\n",
    "    \"text\": df_reduced.index,\n",
    "    \"x\": df_reduced[\"embeddings\"].apply(lambda x: x[0]).to_list(),\n",
    "    \"y\": df_reduced[\"embeddings\"].apply(lambda x: x[1]).to_list(),\n",
    "})\n",
    "\n",
    "scatterplot(source, labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a word in a different language *and alphabet*. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>[0.59055364, -0.3334293, -0.03257506, 0.543022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kočka</th>\n",
       "      <td>[0.5026489, -0.23199998, -0.008454391, 0.48297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>γάτα</th>\n",
       "      <td>[0.5377652, -0.28492135, -0.012445372, 0.51958...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              embeddings\n",
       "cat    [0.59055364, -0.3334293, -0.03257506, 0.543022...\n",
       "kočka  [0.5026489, -0.23199998, -0.008454391, 0.48297...\n",
       "γάτα   [0.5377652, -0.28492135, -0.012445372, 0.51958..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"γάτα\" # \"Cat\" in Greek /ˈɣa.ta/\n",
    "\n",
    "df5 = pd.concat([\n",
    "  df4, \n",
    "  pd.DataFrame.from_dict({\"embeddings\": { word: model2.encode(word)}}),\n",
    "])\n",
    "\n",
    "df5.loc[[\"cat\", \"kočka\", word]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And let's try the scatterplot again... {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e456e4f769804ccd93fbeed528ce294a.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e456e4f769804ccd93fbeed528ce294a.vega-embed details,\n",
       "  #altair-viz-e456e4f769804ccd93fbeed528ce294a.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e456e4f769804ccd93fbeed528ce294a\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e456e4f769804ccd93fbeed528ce294a\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e456e4f769804ccd93fbeed528ce294a\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"crimson\", \"size\": 200, \"stroke\": \"white\", \"strokeWidth\": 1}, \"encoding\": {\"x\": {\"field\": \"xJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}, \"y\": {\"field\": \"yJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"bottom\", \"dx\": 5, \"fontSize\": 13}, \"encoding\": {\"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"xJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}, \"y\": {\"field\": \"yJittered\", \"scale\": {\"zero\": false}, \"title\": null, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-0a4cfd30ebba425f3ffcbb87e63dd757\"}, \"height\": 200, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-0a4cfd30ebba425f3ffcbb87e63dd757\": [{\"text\": \"cat\", \"x\": -3.267886161804199, \"y\": 0.5871531367301941, \"xJittered\": -3.0328755381929016, \"yJittered\": 0.3863984920451028}, {\"text\": \"dog\", \"x\": 1.0682406425476074, \"y\": -3.5831055641174316, \"xJittered\": 0.9686622171823482, \"yJittered\": -3.5994489023526657}, {\"text\": \"pizza\", \"x\": 3.267690896987915, \"y\": 4.321041107177734, \"xJittered\": 3.5064257216970125, \"yJittered\": 4.484612381245915}, {\"text\": \"coffee\", \"x\": 3.5861752033233643, \"y\": -0.605080783367157, \"xJittered\": 3.6761273145140985, \"yJittered\": -0.8651138226187316}, {\"text\": \"asymptomatic\", \"x\": 1.4974373579025269, \"y\": -1.8378334045410156, \"xJittered\": 1.263575886736302, \"yJittered\": -1.899264812390685}, {\"text\": \"ko\\u010dka\", \"x\": -2.950587511062622, \"y\": 0.5059904456138611, \"xJittered\": -2.7154858072351793, \"yJittered\": 0.5483099434315466}, {\"text\": \"\\u03b3\\u03ac\\u03c4\\u03b1\", \"x\": -3.2010695934295654, \"y\": 0.6118332147598267, \"xJittered\": -3.343421915854009, \"yJittered\": 0.6485565672439666}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced = df_to_reduced(df5)\n",
    "\n",
    "source = pd.DataFrame({\n",
    "    \"text\": df_reduced.index,\n",
    "    \"x\": df_reduced[\"embeddings\"].apply(lambda x: x[0]).to_list(),\n",
    "    \"y\": df_reduced[\"embeddings\"].apply(lambda x: x[1]).to_list(),\n",
    "})\n",
    "\n",
    "scatterplot(source, labels=True, jitter=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compute similarity between a query and the other words. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_32953_row0_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 100.0%, transparent 100.0%);\n",
       "}\n",
       "#T_32953_row1_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 99.2%, transparent 99.2%);\n",
       "}\n",
       "#T_32953_row2_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 98.4%, transparent 98.4%);\n",
       "}\n",
       "#T_32953_row3_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 30.3%, transparent 30.3%);\n",
       "}\n",
       "#T_32953_row4_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 25.1%, transparent 25.1%);\n",
       "}\n",
       "#T_32953_row5_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 21.0%, transparent 21.0%);\n",
       "}\n",
       "#T_32953_row6_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 11.3%, transparent 11.3%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_32953\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_32953_level0_col0\" class=\"col_heading level0 col0\" >Word</th>\n",
       "      <th id=\"T_32953_level0_col1\" class=\"col_heading level0 col1\" >Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_32953_row0_col0\" class=\"data row0 col0\" >cat ⇔ cat</td>\n",
       "      <td id=\"T_32953_row0_col1\" class=\"data row0 col1\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_32953_row1_col0\" class=\"data row1 col0\" >cat ⇔ γάτα</td>\n",
       "      <td id=\"T_32953_row1_col1\" class=\"data row1 col1\" >0.992417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_32953_row2_col0\" class=\"data row2 col0\" >cat ⇔ kočka</td>\n",
       "      <td id=\"T_32953_row2_col1\" class=\"data row2 col1\" >0.983700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_32953_row3_col0\" class=\"data row3 col0\" >cat ⇔ dog</td>\n",
       "      <td id=\"T_32953_row3_col1\" class=\"data row3 col1\" >0.303288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_32953_row4_col0\" class=\"data row4 col0\" >cat ⇔ pizza</td>\n",
       "      <td id=\"T_32953_row4_col1\" class=\"data row4 col1\" >0.250888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_32953_row5_col0\" class=\"data row5 col0\" >cat ⇔ coffee</td>\n",
       "      <td id=\"T_32953_row5_col1\" class=\"data row5 col1\" >0.209838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_32953_row6_col0\" class=\"data row6 col0\" >cat ⇔ asymptomatic</td>\n",
       "      <td id=\"T_32953_row6_col1\" class=\"data row6 col1\" >0.112521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17e847e50>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output-location: column\n",
    "\n",
    "from sklearn.metrics.pairwise \\\n",
    "  import cosine_similarity\n",
    "\n",
    "query = \"cat\"\n",
    "query_emb = model2.encode(query)\n",
    "\n",
    "similarities = {}\n",
    "\n",
    "for word, embeddings in df5[\"embeddings\"].items():\n",
    "  \n",
    "    # query vector ⇔ word vector\n",
    "  \n",
    "    similarities[word] = cosine_similarity(\n",
    "        [query_emb], \n",
    "        [embeddings]\n",
    "      )[0][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the similarities\n",
    "\n",
    "(\n",
    "  pd.DataFrame({\n",
    "    \"Word\": [f\"{query} ⇔ {k}\" for k in similarities.keys()], \n",
    "    \"Similarity\": similarities.values()\n",
    "  })\n",
    "  .sort_values(by=[\"Similarity\"], ascending=False)\n",
    "  .style\n",
    "    .hide(axis=\"index\")\n",
    "    .set_table_attributes('class=\"dataframe\"')\n",
    "    .bar(subset=['Similarity'], color='#999')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is \"cosine similarity\"? {background=\"#718096\" .slide-code .slide-code-wide .slide-grey .smaller}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7]\n",
      " [ 8  9]\n",
      " [ 2 10]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| output-location: column\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "A, B, C = np.array([6,7]), np.array([8,9]), np.array([2,10])\n",
    "\n",
    "# Stack vectors into a single matrix\n",
    "vectors = np.vstack([A, B, C])\n",
    "print(vectors)\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "cos_sim_matrix = cosine_similarity(vectors)\n",
    "\n",
    "# Calculate angles in degrees\n",
    "theta_AB = np.arccos(cos_sim_matrix[0, 1]) * (180 / np.pi)\n",
    "theta_AC = np.arccos(cos_sim_matrix[0, 2]) * (180 / np.pi)\n",
    "\n",
    "# Origin coordinates\n",
    "origin = np.zeros((3, 2))\n",
    "\n",
    "# Display the \"quiver\" chart\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Cosine Similarity For Vectors A, B, C\")\n",
    "\n",
    "plt.quiver(origin[:, 0], origin[:, 1], vectors[:, 0], vectors[:, 1], \n",
    "           angles='xy', scale_units='xy', scale=1, color=['r', 'g', 'b'])\n",
    "\n",
    "\n",
    "plt.xlim(-1, 11)\n",
    "plt.ylim(-1, 11)\n",
    "\n",
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"Y-axis\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.text(A[0], A[1], 'A', color='black', fontsize=24, ha='right')\n",
    "plt.text(B[0], B[1], 'B', color='black', fontsize=24, ha='right')\n",
    "plt.text(C[0], C[1], 'C', color='black', fontsize=24, ha='right')\n",
    "plt.text(A[0] / 2.5, A[1] / 2.5, f'{theta_AB:.2f}°', color='black', fontsize=12, ha='center')\n",
    "plt.text(A[0] / 2.5, A[1] / 1.5, f'{theta_AC:.2f}°', color='black', fontsize=12, ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do \"word arithmetics\". {.slide-code}\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <td>[-0.009882803, 0.6362919, -0.105976604, -0.097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>[-0.0053758374, 0.26451156, -0.1168356, -0.215...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>[0.17876714, -0.28030494, -0.008455522, 0.4727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queen</th>\n",
       "      <td>[0.36926943, -0.03183403, 0.13288921, 0.218695...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saxophone</th>\n",
       "      <td>[0.09851525, 0.36520788, 0.004772159, -0.50931...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  embeddings\n",
       "king       [-0.009882803, 0.6362919, -0.105976604, -0.097...\n",
       "man        [-0.0053758374, 0.26451156, -0.1168356, -0.215...\n",
       "woman      [0.17876714, -0.28030494, -0.008455522, 0.4727...\n",
       "queen      [0.36926943, -0.03183403, 0.13288921, 0.218695...\n",
       "saxophone  [0.09851525, 0.36520788, 0.004772159, -0.50931..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"king\", \"man\", \"woman\", \"queen\", \"saxophone\"]\n",
    "\n",
    "df6 = pd.DataFrame(\n",
    "    [ [model2.encode(word)] for word in words ],\n",
    "    index=words, columns=[\"embeddings\"])\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `king - man + woman = ?` {.slide-code .smaller}\n",
    "\n",
    "::: aside\n",
    "<http://jalammar.github.io/illustrated-word2vec>\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [0.17426018, 0.09147543, 0.0024034753, '...']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_57936_row0_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 100.0%, transparent 100.0%);\n",
       "}\n",
       "#T_57936_row1_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 85.5%, transparent 85.5%);\n",
       "}\n",
       "#T_57936_row2_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 80.9%, transparent 80.9%);\n",
       "}\n",
       "#T_57936_row3_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 25.9%, transparent 25.9%);\n",
       "}\n",
       "#T_57936_row4_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #999 17.9%, transparent 17.9%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_57936\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_57936_level0_col0\" class=\"col_heading level0 col0\" >Word</th>\n",
       "      <th id=\"T_57936_level0_col1\" class=\"col_heading level0 col1\" >Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_57936_row0_col0\" class=\"data row0 col0\" >queen</td>\n",
       "      <td id=\"T_57936_row0_col1\" class=\"data row0 col1\" >0.790001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_57936_row1_col0\" class=\"data row1 col0\" >king</td>\n",
       "      <td id=\"T_57936_row1_col1\" class=\"data row1 col1\" >0.675087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_57936_row2_col0\" class=\"data row2 col0\" >woman</td>\n",
       "      <td id=\"T_57936_row2_col1\" class=\"data row2 col1\" >0.639414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_57936_row3_col0\" class=\"data row3 col0\" >saxophone</td>\n",
       "      <td id=\"T_57936_row3_col1\" class=\"data row3 col1\" >0.204697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_57936_row4_col0\" class=\"data row4 col0\" >man</td>\n",
       "      <td id=\"T_57936_row4_col1\" class=\"data row4 col1\" >0.141279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17df10910>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output-location: column\n",
    "\n",
    "result = (\n",
    "  df6.loc[\"king\"][\"embeddings\"]\n",
    "  -\n",
    "  df6.loc[\"man\"][\"embeddings\"]\n",
    "  +\n",
    "  df6.loc[\"woman\"][\"embeddings\"])\n",
    "\n",
    "print(\"Result:\", list(result[:3]) + [\"...\"])\n",
    "\n",
    "\n",
    "similarities = {}\n",
    "\n",
    "for word, embeddings in df6[\"embeddings\"].items():\n",
    "  \n",
    "  # result vector ⇔ word vector\n",
    "  \n",
    "  similarities[word] = \\\n",
    "    cosine_similarity([result], [embeddings])[0][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the similarities\n",
    "\n",
    "(\n",
    "  pd.DataFrame({\n",
    "    \"Word\": similarities.keys(), \n",
    "    \"Similarity\": similarities.values()\n",
    "  })\n",
    "  .sort_values(by=[\"Similarity\"], ascending=False)\n",
    "  .style\n",
    "    .hide(axis=\"index\")\n",
    "    .set_table_attributes('class=\"dataframe\"')\n",
    "    .bar(subset=['Similarity'], color='#999')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{.center .center-horizontal}\n",
    "-----\n",
    "\n",
    "<small>\n",
    "![](assets/logo-huggingface.svg){class=\"icon small\" width=\"10\" height=\"10\"}\n",
    "[`spaces/karmiq/glove-word-arithmetics`](https://huggingface.co/spaces/karmiq/glove-word-arithmetics)\n",
    "</small>\n",
    "\n",
    "<iframe\n",
    "\tsrc=\"https://karmiq-glove-word-arithmetics.hf.space\"\n",
    "\tframeborder=\"0\"\n",
    "\twidth=\"850\"\n",
    "\theight=\"450\"\n",
    "  style=\"border: 2px solid #ccc; border-radius: 5px; padding: 10px; box-shadow: 0.3em 0.3em 1em rgba(0, 0, 0, 0.3);\"\n",
    "></iframe>\n",
    "\n",
    "::: footer\n",
    "➊ What Are Text Embeddings?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ➋ Semantic search {background=\"#dc143c\" .center}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic search\n",
    "\n",
    "*Lexical* search <small>(TF-IDF, BM25, …)</small>\n",
    "\n",
    "*Semantic* search: text embeddings and similarity\n",
    "\n",
    "Meaning (\"dimensions\"), not just words\n",
    "\n",
    "(Approximate) \"Nearest Neighbors\" algorithm\n",
    "\n",
    "\n",
    "\n",
    "::: aside\n",
    "<https://txt.cohere.com/what-is-semantic-search/>\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors with `scikit-learn` {.slide-code .slide-code-wide .smaller}\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_150e2_row0_col1 {\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_150e2_row1_col1 {\n",
       "  background-color: #d3d3d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_150e2_row2_col1 {\n",
       "  background-color: #c1c1c1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_150e2_row3_col1 {\n",
       "  background-color: #a0a0a0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_150e2_row4_col1 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_150e2\" class=\"dataframe align-left\">\n",
       "  <caption>Query: food</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_150e2_level0_col0\" class=\"col_heading level0 col0\" >word</th>\n",
       "      <th id=\"T_150e2_level0_col1\" class=\"col_heading level0 col1\" >distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_150e2_row0_col0\" class=\"data row0 col0\" >pizza</td>\n",
       "      <td id=\"T_150e2_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_150e2_row1_col0\" class=\"data row1 col0\" >coffee</td>\n",
       "      <td id=\"T_150e2_row1_col1\" class=\"data row1 col1\" >0.279945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_150e2_row2_col0\" class=\"data row2 col0\" >dog</td>\n",
       "      <td id=\"T_150e2_row2_col1\" class=\"data row2 col1\" >0.355471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_150e2_row3_col0\" class=\"data row3 col0\" >cat</td>\n",
       "      <td id=\"T_150e2_row3_col1\" class=\"data row3 col1\" >0.465242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_150e2_row4_col0\" class=\"data row4 col0\" >asymptomatic</td>\n",
       "      <td id=\"T_150e2_row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17e844d10>"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output-location: column\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the model\n",
    "nn = NearestNeighbors(n_neighbors=len(df6[\"embeddings\"]))\n",
    "\n",
    "# Store the embeddings for efficient lookup\n",
    "nn.fit(df2[\"embeddings\"].tolist())\n",
    "\n",
    "# Define the search query\n",
    "query = \"food\"\n",
    "query_embedding = np.array([model1.encode(query)])\n",
    "\n",
    "# Compare query vector to every vector in the dataset\n",
    "distances, indices = nn.kneighbors(query_embedding)\n",
    "\n",
    "# Normalize the distances to [0-1]\n",
    "scaler = MinMaxScaler()\n",
    "normalized_distances = scaler.fit_transform(distances.reshape(-1, 1))\n",
    "\n",
    "# Display the results\n",
    "(pd.DataFrame({\n",
    "    \"word\": df2.index[indices.flatten()],\n",
    "    \"distance\": normalized_distances.flatten(),\n",
    "})\n",
    " \n",
    "\n",
    " \n",
    " .style\n",
    "    .hide(axis=\"index\")\n",
    "    .set_table_attributes('class=\"dataframe align-left\"')\n",
    "    .set_caption(f\"Query: {query}\")\n",
    "    .background_gradient(subset=[\"distance\"], cmap=\"Greys\", ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When \"Brute Force\" Is Not Enough\n",
    "\n",
    "(Hierarchical) Navigable Small World\n",
    "\n",
    ":::: columns\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "![NSW](assets/hnsw-1-pinecone.png){height=\"250\"}\n",
    ":::\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "![HNSW](assets/hnsw-2-pinecone.png){height=\"250\"}\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "\n",
    "::: aside\n",
    "<https://www.pinecone.io/learn/series/faiss/hnsw/>\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors with *Annoy*\n",
    "\n",
    "1. Download data from [coffee.stackexchange.com](https://coffee.stackexchange.com)\n",
    "2. Extract post titles from XML into Pandas' dataframe\n",
    "3. Compute the text embeddings\n",
    "4. Build the *Annoy* index\n",
    "5. Search the index\n",
    "\n",
    "::: aside\n",
    "<https://github.com/spotify/annoy>\n",
    "\n",
    "<https://github.com/erikbern/ann-presentation>\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Archive {.slide-code .slide-code-wide .smaller}\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "%pip install -q tqdm requests py7zr annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 4.49M/4.49M [01:22<00:00, 54.2kB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_file = \"coffee.stackexchange.com.7z\"\n",
    "input_file_path = os.path.join(\"tmp\", input_file)\n",
    "\n",
    "if not os.path.exists(input_file_path):\n",
    "  archive_url = f\"https://archive.org/download/stackexchange/{input_file}\"\n",
    "  \n",
    "  with requests.get(archive_url, stream=True) as response:\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        total_size = int(response.headers.get(\"content-length\", 0))\n",
    "        \n",
    "        with tqdm(total=total_size, desc=\"Download\", unit=\"B\", unit_scale=True, file=sys.stdout) as p:\n",
    "          \n",
    "          with open(input_file_path, \"wb\") as f:\n",
    "              for chunk in response.iter_content(chunk_size=4096):\n",
    "                  p.update(len(chunk))\n",
    "                  f.write(chunk)\n",
    "else:\n",
    "  print(\"Input file already downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Titles from XML into a DataFrame {.slide-code .slide-code-wide .smaller}\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f335c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_f335c_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_f335c_row0_col0\" class=\"data row0 col0\" >How should I store whole bean coffee?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f335c_row1_col0\" class=\"data row1 col0\" >How fine should I grind coffee for drip/pour over coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f335c_row2_col0\" class=\"data row2 col0\" >Does the hardness of water matter when making coffee?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f335c_row3_col0\" class=\"data row3 col0\" >What's the theory behind using thin spouted kettles when making drip/pour over coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f335c_row4_col0\" class=\"data row4 col0\" >How important is tamping coffee for an espresso machine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17e6a24d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450 rows\n"
     ]
    }
   ],
   "source": [
    "#| output-location: column\n",
    "\n",
    "import pandas as pd\n",
    "from py7zr import SevenZipFile as zip\n",
    "\n",
    "xml_file = \"Posts.xml\"\n",
    "dest = tempfile.TemporaryDirectory().name\n",
    "\n",
    "# Extract the file with posts\n",
    "with zip(input_file_path, \"r\") as archive:\n",
    "    archive.extract(targets=[xml_file], path=dest)\n",
    "\n",
    "# Read XML into a dataframe\n",
    "df = pd.read_xml(os.path.join(dest, xml_file), xpath=\"//row\")\n",
    "\n",
    "# Keep only 'Title' column and rename to 'text'\n",
    "df = df[[\"Title\"]].dropna().rename(columns={\"Title\": \"text\"})\n",
    "\n",
    "display(df.head(5).style.hide(axis=\"index\"))\n",
    "\n",
    "print(f\"{df.size} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Text Embeddings {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process: 100%|██████████| 1450/1450 [00:18<00:00, 79.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How should I store whole bean coffee?</td>\n",
       "      <td>[-0.4377262, 0.14942853, -0.16667569, 0.167280...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How fine should I grind coffee for drip/pour o...</td>\n",
       "      <td>[-0.24292755, -0.36047038, 0.0934966, 0.396481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does the hardness of water matter when making ...</td>\n",
       "      <td>[-0.11959872, -0.2570504, 0.18188146, 0.378879...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   \n",
       "0              How should I store whole bean coffee?  \\\n",
       "1  How fine should I grind coffee for drip/pour o...   \n",
       "2  Does the hardness of water matter when making ...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.4377262, 0.14942853, -0.16667569, 0.167280...  \n",
       "1  [-0.24292755, -0.36047038, 0.0934966, 0.396481...  \n",
       "2  [-0.11959872, -0.2570504, 0.18188146, 0.378879...  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Register progress bar\n",
    "tqdm.pandas(desc=\"Process\")\n",
    "\n",
    "# Compute embeddings\n",
    "df[\"embeddings\"] = df[\"text\"].progress_apply( lambda x: model.encode(x) )\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Index {.slide-code}\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built index with [1450] items and [384] dimensions\n"
     ]
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "f = df[\"embeddings\"][0].size  # Vector dimensions\n",
    "t = AnnoyIndex(f, \"angular\")\n",
    "\n",
    "for i, vector in enumerate(df[\"embeddings\"]):\n",
    "    t.add_item(i, vector)\n",
    "\n",
    "t.build(10)  # 10 trees\n",
    "t.save(os.path.join(\"tmp\", \"coffee.ann\"))\n",
    "\n",
    "print(f\"Built index with [{df.embeddings.size}] items and [{f}] dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Index and Define the Search Method {.slide-code}\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved index\n",
    "#\n",
    "index = AnnoyIndex(f, \"angular\")\n",
    "index.load(os.path.join(\"tmp\", \"coffee.ann\"))\n",
    "\n",
    "# Define the search method\n",
    "#\n",
    "def search(query, index, model, df):\n",
    "    query_embedding = model.encode(query)\n",
    "    nearest_ids = index.get_nns_by_vector(query_embedding, 10)\n",
    "    \n",
    "    return df.iloc[nearest_ids][[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase column width for display\n",
    "#\n",
    "pd.set_option(\"display.max_colwidth\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the Search {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>How many cups of coffee is it safe to consume per day?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>What is the limit to the amount of coffee one can consume?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>What should be the daily coffee intake?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>How much \"coffee\" is there in my cup?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>Is one cup of coffee a day good?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Coffee on daily basis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>How much coffee is too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>Coffee consuming amount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4353</th>\n",
       "      <td>How Much Caffeine is Really in Your Coffee? - analysis / questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>How do I vary between how much froth for each coffee drink?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    text\n",
       "208               How many cups of coffee is it safe to consume per day?\n",
       "1686          What is the limit to the amount of coffee one can consume?\n",
       "3006                             What should be the daily coffee intake?\n",
       "2270                               How much \"coffee\" is there in my cup?\n",
       "3043                                    Is one cup of coffee a day good?\n",
       "792                                                Coffee on daily basis\n",
       "4424                                        How much coffee is too much?\n",
       "2673                                             Coffee consuming amount\n",
       "4353  How Much Caffeine is Really in Your Coffee? - analysis / questions\n",
       "3218         How do I vary between how much froth for each coffee drink?"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"How much coffee can you drink in one day?\", index, model, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the Search {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>What is the limit to the amount of coffee one can consume?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>What is the minimum amount of coffee that produces the maximum possible concentration?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>What should be the daily coffee intake?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>Coffee consuming amount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>What's the minimum recommended age for drinking a coffee?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>Minimum amount of water in coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>Merits &amp; demerits of coffee consumption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>How many cups of coffee is it safe to consume per day?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>How do I vary between how much froth for each coffee drink?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>How much caffeine delivered by eating coffee grounds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        text\n",
       "1686                              What is the limit to the amount of coffee one can consume?\n",
       "4404  What is the minimum amount of coffee that produces the maximum possible concentration?\n",
       "3006                                                 What should be the daily coffee intake?\n",
       "2673                                                                 Coffee consuming amount\n",
       "447                                What's the minimum recommended age for drinking a coffee?\n",
       "3591                                                       Minimum amount of water in coffee\n",
       "3200                                                 Merits & demerits of coffee consumption\n",
       "208                                   How many cups of coffee is it safe to consume per day?\n",
       "3218                             How do I vary between how much froth for each coffee drink?\n",
       "3002                                    How much caffeine delivered by eating coffee grounds"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"What is the maximum coffee consumption?\", index, model, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"Vocabulary Mismatch\" Problem {.center .center-horizontal .smaller}\n",
    "\n",
    "_What is the maximum coffee consumption?_\n",
    "\n",
    "![](assets/screenshot-coffee-stackexchange.png){width=\"800\"}\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search in a Different Language {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>How many cups of coffee is it safe to consume per day?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>What should be the daily coffee intake?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>What is the limit to the amount of coffee one can consume?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>How much \"coffee\" is there in my cup?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Coffee on daily basis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>Coffee consuming amount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>How much coffee is too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>How do I vary between how much froth for each coffee drink?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4353</th>\n",
       "      <td>How Much Caffeine is Really in Your Coffee? - analysis / questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>How many milligrams of caffeine are in a fresh coffee bean?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    text\n",
       "208               How many cups of coffee is it safe to consume per day?\n",
       "3006                             What should be the daily coffee intake?\n",
       "1686          What is the limit to the amount of coffee one can consume?\n",
       "2270                               How much \"coffee\" is there in my cup?\n",
       "792                                                Coffee on daily basis\n",
       "2673                                             Coffee consuming amount\n",
       "4424                                        How much coffee is too much?\n",
       "3218         How do I vary between how much froth for each coffee drink?\n",
       "4353  How Much Caffeine is Really in Your Coffee? - analysis / questions\n",
       "1073         How many milligrams of caffeine are in a fresh coffee bean?"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"Kolik kafe můžu denně vypít?\", index, model, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Databases {.logos}\n",
    "\n",
    "- ![](assets/logos/postgres.png){height=40} PostgreSQL (with `pgvector`)\n",
    "- ![](assets/logos/elasticsearch.png){height=40} Elasticsearch\n",
    "- ![](assets/logos/redis.png){height=40} Redis\n",
    "- ![](assets/logos/pinecone.png){height=40} Pinecone\n",
    "- ![](assets/logos/weviate.png){height=40} Weviate\n",
    "- ![](assets/logos/vespa.png){height=40} Vespa\n",
    "- ![](assets/logos/milvus.jpg){height=40} Milvus\n",
    "- ...\n",
    "\n",
    "::: footer\n",
    "➋ Semantic search\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ➌ Embeddings for other media {background=\"#dc143c\" .center}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LAION dataset\n",
    "\n",
    "- More than 2 *billions* of image/caption pairs\n",
    "- A \"multi-modal\" dataset\n",
    "- Embeddings with the [CLIP](https://openai.com/research/clip) model by OpenAI\n",
    "- Full size: 6.2TB\n",
    "\n",
    "\n",
    "> (…) ensure you have at least 20TB of disk space available\n",
    "\n",
    "<https://clickhouse.com/blog/vector-search-clickhouse-p2>\n",
    "\n",
    "::: aside\n",
    "<https://laion.ai/blog/laion-5b/>\n",
    ":::\n",
    "\n",
    "\n",
    "::: footer\n",
    "➌ Embeddings for other media\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's download *just one file* from the dataset. {.slide-code .smaller}\n",
    "\n",
    "<small><https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings></small>\n",
    "\n",
    "::: footer\n",
    "➌ Embeddings for other media\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping download, file /Users/karmi/Downloads/metadata_0000.parquet already exists (194.8 MB)\n",
      "Skipping download, file /Users/karmi/Downloads/img_emb_0000.npy already exists (1.4 GB)\n",
      "Skipping download, file /Users/karmi/Downloads/text_emb_0000.npy already exists (1.4 GB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import humanize\n",
    "import requests\n",
    "\n",
    "DOWNLOAD_PATH = os.path.expanduser(\"~/Downloads\")\n",
    "BASE_URL = \"https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings/resolve/main\"\n",
    "\n",
    "filenames = {\n",
    "    \"metadata\": \"metadata/metadata_0000.parquet\",\n",
    "    \"image_emb\": \"img_emb/img_emb_0000.npy\",\n",
    "    \"text_emb\": \"text_emb/text_emb_0000.npy\",\n",
    "}\n",
    "\n",
    "for (key, filename) in filenames.items():\n",
    "    url = f\"{BASE_URL}/{filename}\"\n",
    "    filepath = os.path.join(DOWNLOAD_PATH, os.path.basename(filename))\n",
    "    filebasename = os.path.basename(filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        filesize = os.path.getsize(filepath)\n",
    "        print(f\"Skipping download, file {filepath} already exists ({humanize.naturalsize(filesize)})\")\n",
    "    else:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        total_size= int(response.headers.get('content-length', 0))\n",
    "\n",
    "        progress_bar = notebook_tqdm(desc=filebasename, total=total_size, unit='iB', unit_scale=True)\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            try:\n",
    "                for chunk in response.iter_content(chunk_size=8192): \n",
    "                    if chunk:\n",
    "                        progress_bar.update(len(chunk))\n",
    "                        f.write(chunk)\n",
    "            except KeyboardInterrupt:\n",
    "                print(f\"Downloading of [{filebasename}] interrupted.\")\n",
    "            else:\n",
    "                filesize = os.path.getsize(filepath)\n",
    "                print(f\"Downloaded {filepath} ({humanize.naturalsize(filesize)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's peek inside the dataset. {.slide-code .smaller}\n",
    "\n",
    "::: footer\n",
    "➌ Embeddings for other media\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>url</th>\n",
       "      <th>exif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color version PULP FICTION alternative poster art</td>\n",
       "      <td>http://cdn.shopify.com/s/files/1/0282/0804/pro...</td>\n",
       "      <td>{\"Image Orientation\": \"Horizontal (normal)\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Writing A Successful Cover Letter by Cover Let...</td>\n",
       "      <td>http://tse3.mm.bing.net/th?id=OIP.hRMwYK1PG9pk...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Original Herrnhut plastic star, ORANGE (Specia...</td>\n",
       "      <td>https://cdn.shopify.com/s/files/1/0600/1993/pr...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption   \n",
       "0  Color version PULP FICTION alternative poster art  \\\n",
       "1  Writing A Successful Cover Letter by Cover Let...   \n",
       "2  Original Herrnhut plastic star, ORANGE (Specia...   \n",
       "\n",
       "                                                 url   \n",
       "0  http://cdn.shopify.com/s/files/1/0282/0804/pro...  \\\n",
       "1  http://tse3.mm.bing.net/th?id=OIP.hRMwYK1PG9pk...   \n",
       "2  https://cdn.shopify.com/s/files/1/0600/1993/pr...   \n",
       "\n",
       "                                                exif  \n",
       "0  {\"Image Orientation\": \"Horizontal (normal)\", \"...  \n",
       "1                                                 {}  \n",
       "2                                                 {}  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "\n",
    "df = pd.read_parquet(os.path.join(DOWNLOAD_PATH, os.path.basename(filenames[\"metadata\"])))\n",
    "df[[\"caption\", \"url\", \"exif\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's display the images. {.slide-code}\n",
    "\n",
    "::: footer\n",
    "➌ Embeddings for other media\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://cdn.shopify.com/s/files/1/0282/0804/products/pulp_1024x1024.jpg?v=1474264437\" width=\"200\" alt=\"Color version PULP FICTION alternative poster art\"/><img src=\"http://tse3.mm.bing.net/th?id=OIP.hRMwYK1PG9pkAOq30i9QYQDyEs\" width=\"200\" alt=\"Writing A Successful Cover Letter by Cover Letter How To Write A Cover Letter Exles\"/><img src=\"https://cdn.shopify.com/s/files/1/0600/1993/products/A1e_Herrnhut_Stars_orange_special_edition_2016_380x@2x.png?v=1502078257\" width=\"200\" alt=\"Original Herrnhut plastic star, ORANGE (Special Edition 2016), ~ 13 cm / 5 inch ø\"/><img src=\"https://i.pinimg.com/originals/43/49/19/4349195deefe538d7711acdde78e2896.png\" width=\"200\" alt=\"Free Disney Planes Printable Coloring Pages Activity Sheets DisneyPlanes\"/><img src=\"https://i.pinimg.com/736x/3a/15/c5/3a15c55588e9d880bbbfd1a72082afe5--lady-fingers-chrissy-hynde.jpg\" width=\"200\" alt=\"Stevie Nicks Tee On Chrissie Hynde. Wish I could see them on their tour together.\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "\n",
    "images = [\n",
    "    Image(url=row.url, alt=row.caption, width=200)\n",
    "    for row in df[[\"url\", \"caption\"]].head(5).itertuples()\n",
    "]\n",
    "HTML(\"\".join([image._repr_html_() for image in images]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load the image embeddings and initialize the model. {.slide-code .smaller}\n",
    "\n",
    "[![](assets/logo-huggingface.svg){class=\"icon\" width=\"40\" height=\"40\"} `sentence-transformers/clip-ViT-L-14`](https://huggingface.co/sentence-transformers/clip-ViT-L-14)\n",
    "\n",
    "::: footer\n",
    "➌ Embeddings for other media\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "image_embeddings = np.load(os.path.join(DOWNLOAD_PATH, os.path.basename(filenames[\"image_emb\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model3 = SentenceTransformer(\"clip-ViT-L-14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(df, query, indices, **kwargs):\n",
    "    width = kwargs.get(\"width\", 200)\n",
    "    df_res = pd.DataFrame({\n",
    "        \"image\": [Image(url=df[\"url\"][i], width=width)._repr_html_() for i in indices.flatten()],\n",
    "        \"caption\": [df[\"caption\"][i] for i in indices.flatten()] })\n",
    "    \n",
    "    return HTML(df_res\n",
    "        .style\n",
    "            .hide(axis=\"index\")\n",
    "            .set_caption(f\"Query: {query}\")\n",
    "            .set_table_attributes('class=\"dataframe smaller align-left\"')\n",
    "            .set_table_styles([dict(selector=\"th.col0,td.col0\", props=[(\"min-width\", f\"{width}px\")])])\n",
    "            .to_html(escape=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's query the dataset. {.slide-code}\n",
    "\n",
    "<small>A \"multi-modal\" search: searching image embeddings with text embeddings.</small>\n",
    "\n",
    "::: footer\n",
    "➌ Embeddings for other media\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_813e4 th.col0 {\n",
       "  min-width: 200px;\n",
       "}\n",
       "#T_813e4 td.col0 {\n",
       "  min-width: 200px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_813e4\" class=\"dataframe smaller align-left\">\n",
       "  <caption>Query: cat dog pizza coffee asymptomatic</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_813e4_level0_col0\" class=\"col_heading level0 col0\" >image</th>\n",
       "      <th id=\"T_813e4_level0_col1\" class=\"col_heading level0 col1\" >caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_813e4_row0_col0\" class=\"data row0 col0\" ><img src=\"http://rlv.zcache.co.uk/cute_quirky_cartoon_dog_mug-rb525f7f3d7df45f6a36b6eab6a951c46_x7jgr_8byvr_324.jpg\" width=\"200\"/></td>\n",
       "      <td id=\"T_813e4_row0_col1\" class=\"data row0 col1\" >Cute quirky cartoon dog mugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_813e4_row1_col0\" class=\"data row1 col0\" ><img src=\"https://rlv.zcache.co.nz/i_love_skye_terriers_mug-rd2ad2d5ae8834eafa4218fb9dc35e74e_kfpv5_324.jpg?rlvnet=1\" width=\"200\"/></td>\n",
       "      <td id=\"T_813e4_row1_col1\" class=\"data row1 col1\" >I Love Skye Terriers Mug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_813e4_row2_col0\" class=\"data row2 col0\" ><img src=\"https://www.redwolf.in/image/cache/catalog/fridge-magnets/better-with-pizza-fridge-magnet-india-270x270.jpg\" width=\"200\"/></td>\n",
       "      <td id=\"T_813e4_row2_col1\" class=\"data row2 col1\" >Better With Pizza - Scooby Doo Official Fridge Magnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_813e4_row3_col0\" class=\"data row3 col0\" ><img src=\"https://cdn-images.threadless.com/threadless-media/artist_shops/shops/magnusblomster/products/949292/shirt-1552495007-f13a3438ee73bab652eedc1f9334663b.png?v=3&d=eyJvbmx5X21ldGEiOiBmYWxzZSwgImZvcmNlIjogZmFsc2UsICJvcHMiOiBbWyJpZl8iLCBbeyJ0IjogImV4cHIiLCAidiI6IFsiaGFzX2FscGhhIiwgbnVsbCwgbnVsbF19LCB7InQiOiAiY29tcCIsICJ2IjogWyJ0aHJlYWRsZXNzLW1lZGlhL2FydGlzdF9zaG9wcy9zaG9wcy9tYWdudXNibG9tc3Rlci9wcm9kdWN0cy85NDkyOTIvc2hpcnQtMTU1MjQ5NTAwNy1mMTNhMzQzOGVlNzNiYWI2NTJlZWRjMWY5MzM0NjYzYi5wbmciLCBbWyJ0cmltIiwgW3RydWUsIGZhbHNlXSwge31dLCBbInJlc2l6ZSIsIFsxNjg3LjUsIDIwMDguOTI4NTcxNDI4NTcxM10sIHsibWF4X3NjYWxlIjogMy4wfV0sIFsicGFkIiwgWzMzNC44MjE0Mjg1NzE0Mjg1NiwgMjgxLjI1LCAzMzQuODIxNDI4NTcxNDI4NTYsIDI4MS4yNV0sIHsiYmFja2dyb3VuZCI6ICJmZmZmZmYifV0sIFsiY2FudmFzX2NlbnRlcmVkIiwgWzIyNTAuMCwgMjY3OC41NzE0Mjg1NzE0Mjg0XSwgeyJiYWNrZ3JvdW5kIjogImZmZmZmZiJ9XV1dfSwgeyJ0IjogImNvbXAiLCAidiI6IFsidGhyZWFkbGVzcy1tZWRpYS9hcnRpc3Rfc2hvcHMvc2hvcHMvbWFnbnVzYmxvbXN0ZXIvcHJvZHVjdHMvOTQ5MjkyL3NoaXJ0LTE1NTI0OTUwMDctZjEzYTM0MzhlZTczYmFiNjUyZWVkYzFmOTMzNDY2M2IucG5nIiwgW1sicmVzaXplIiwgWzIyNTAuMCwgMjY3OC41NzE0Mjg1NzE0Mjg0XSwgeyJtYXhfc2NhbGUiOiAzLjAsICJzdHlsZSI6ICJDUk9QIn1dLCBbImNhbnZhc19jZW50ZXJlZCIsIFsyMjUwLjAsIDI2NzguNTcxNDI4NTcxNDI4NF0sIHsiYmFja2dyb3VuZCI6ICJmZmZmZmYifV1dXX1dLCB7fV0sIFsiZW5jb2RlIiwgWyIucG5nIl0sIHsiZHBpIjogMzAwfV0sIFsicmVzaXplIiwgWzEzNzVdLCB7fV0sIFsib3ZlcmxheSIsIFsidGhyZWFkbGVzcy1tZWRpYS9hcnRpc3Rfc2hvcHMvb3ZlcmxheXMvM2Y5NjVlZjcxYjE3YjgxMTQ5ZDQyNGZiYTU2MmUzNGMvZnJvbnQtMTQ5NDAwMzkyMy04MzQxMjg5MDAyODA4YzRmMzQzMGFhOWRmYmQ0NGQ2Yy5wbmciXSwgeyJ5IjogMjA1LCAieCI6IDMxOCwgImJhY2tncm91bmQiOiAiZmZmZmZmIn1dLCBbInJlc2l6ZSIsIFs4MDBdLCB7fV0sIFsiY2FudmFzX2NlbnRlcmVkIiwgWzgwMCwgODAwLCAiI2ZmZmZmZiJdLCB7fV0sIFsiZW5jb2RlIiwgWyJqcGciLCA4NV0sIHt9XV19\" width=\"200\"/></td>\n",
       "      <td id=\"T_813e4_row3_col1\" class=\"data row3 col1\" >Starving cat Home Sherpa Blanket Blanket by Magnus Blomster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_813e4_row4_col0\" class=\"data row4 col0\" ><img src=\"https://static1.bigstockphoto.com/0/6/8/large2/8605693.jpg\" width=\"200\"/></td>\n",
       "      <td id=\"T_813e4_row4_col1\" class=\"data row4 col1\" >Dog And Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_813e4_row5_col0\" class=\"data row5 col0\" ><img src=\"http://ciaosoftware.com/images/Lost%20Dog%20Cafe.png\" width=\"200\"/></td>\n",
       "      <td id=\"T_813e4_row5_col1\" class=\"data row5 col1\" >Lost Dog Cafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_813e4_row6_col0\" class=\"data row6 col0\" ><img src=\"https://cdn.drawception.com/images/panels/2015/1-3/hNzWG9GFYZ-10.png\" width=\"200\"/></td>\n",
       "      <td id=\"T_813e4_row6_col1\" class=\"data row6 col1\" >Birthday cake, but it's a pizza with pepperoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_813e4_row7_col0\" class=\"data row7 col0\" ><img src=\"https://static2.bigstockphoto.com/7/3/2/large2/237136057.jpg\" width=\"200\"/></td>\n",
       "      <td id=\"T_813e4_row7_col1\" class=\"data row7 col1\" >Portrait Of Kitten And Puppy On а White Background.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_813e4_row8_col0\" class=\"data row8 col0\" ><img src=\"http://www.quotehd.com/imagequotes/authors74/tmb/jake-gyllenhaal-jake-gyllenhaal-its-funny-to-me-that-people-find.jpg\" width=\"200\"/></td>\n",
       "      <td id=\"T_813e4_row8_col1\" class=\"data row8 col1\" >Jake Gyllenhaal - It's funny to me that people find other people getting coffee really interesting, or walking their dog in the dog park.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_813e4_row9_col0\" class=\"data row9 col0\" ><img src=\"https://t0.gstatic.com/images?q=tbn:ANd9GcTjjwQUc5aMu4aYE0YQCr_HO5zGcUB2tJxITIdQxoXkz6xKjXUJjw\" width=\"200\"/></td>\n",
       "      <td id=\"T_813e4_row9_col1\" class=\"data row9 col1\" >Can Starbucks Be Any Perfect Than This Imagine How Awesome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output-location: slide\n",
    "\n",
    "query = \"cat dog pizza coffee asymptomatic\"\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "NUM_RESULTS = 10\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=NUM_RESULTS, algorithm=\"auto\")\n",
    "\n",
    "nn.fit(image_embeddings)\n",
    "\n",
    "# Search *image* embeddings with *text* embeddings\n",
    "\n",
    "query_embedding = np.array([model3.encode(query)])\n",
    "\n",
    "distances, indices = nn.kneighbors(query_embedding)\n",
    "\n",
    "\n",
    "display_results(df, query, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's query the dataset *with a picture*. {.slide-code .smaller}\n",
    "\n",
    ":::: columns\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "![](https://images.unsplash.com/photo-1425913397330-cf8af2ff40a1?w=600)\n",
    "<small><https://unsplash.com/photos/MMJx78V7xS8></small>\n",
    ":::\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "\n",
    "<!-- NOTE: Executable code is in the cell below -->\n",
    "\n",
    "```{.python}\n",
    "import requests\n",
    "import PIL\n",
    "\n",
    "image_url = \"https://images.unsplash.com/photo-1425913397330-cf8af2ff40a1?w=600\"\n",
    "\n",
    "image = PIL.Image.open(\n",
    "  requests.get(image_url, stream=True).raw\n",
    ")\n",
    "\n",
    "# Search *image* embeddings with *image* embeddings\n",
    "\n",
    "query_image_embedding = model3.encode([image])\n",
    "\n",
    "distances, indices = nn.kneighbors(query_image_embedding)\n",
    "\n",
    "display_results(df, \"Image\", indices, width=400)\n",
    "```\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "::: footer\n",
    "➌ Embeddings for other media\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aea2f th.col0 {\n",
       "  min-width: 400px;\n",
       "}\n",
       "#T_aea2f td.col0 {\n",
       "  min-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aea2f\" class=\"dataframe smaller align-left\">\n",
       "  <caption>Query: Image</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_aea2f_level0_col0\" class=\"col_heading level0 col0\" >image</th>\n",
       "      <th id=\"T_aea2f_level0_col1\" class=\"col_heading level0 col1\" >caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_aea2f_row0_col0\" class=\"data row0 col0\" ><img src=\"https://earthsky.org/upl/2013/07/morning-forest-scence-300x214.jpg\" width=\"400\"/></td>\n",
       "      <td id=\"T_aea2f_row0_col1\" class=\"data row0 col1\" >morning-forest-scence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aea2f_row1_col0\" class=\"data row1 col0\" ><img src=\"https://itsok2notbeok.files.wordpress.com/2017/07/nature-forest-trees-fog.jpeg?w=300&\" width=\"400\"/></td>\n",
       "      <td id=\"T_aea2f_row1_col1\" class=\"data row1 col1\" >nature-forest-trees-fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aea2f_row2_col0\" class=\"data row2 col0\" ><img src=\"https://media.istockphoto.com/photos/misty-forest-picture-id495880050?k=6&m=495880050&s=612x612&w=0&h=7cnyG_gm-8scWaMJ7yr1D3YJKEsY-rAZdmaXIrtPA3M=\" width=\"400\"/></td>\n",
       "      <td id=\"T_aea2f_row2_col1\" class=\"data row2 col1\" >misty forest - trees in mist stock pictures, royalty-free photos & images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aea2f_row3_col0\" class=\"data row3 col0\" ><img src=\"https://blog.ons.gov.uk/wp-content/uploads/sites/6/2021/07/Forest-630x470.jpg\" width=\"400\"/></td>\n",
       "      <td id=\"T_aea2f_row3_col1\" class=\"data row3 col1\" >Picture of a forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aea2f_row4_col0\" class=\"data row4 col0\" ><img src=\"https://static.wixstatic.com/media/244598303d544aa899beb16d0fa95fde.jpg/v1/fill/w_390,h_585,al_c,q_80,usm_0.66_1.00_0.01/Hiking%20Path%20in%20Forest.jpg\" width=\"400\"/></td>\n",
       "      <td id=\"T_aea2f_row4_col1\" class=\"data row4 col1\" >Hiking Path in Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aea2f_row5_col0\" class=\"data row5 col0\" ><img src=\"https://images.unsplash.com/photo-1495395226200-8fbf6b720b8c?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&w=1000&q=80\" width=\"400\"/></td>\n",
       "      <td id=\"T_aea2f_row5_col1\" class=\"data row5 col1\" >woman walking in the forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aea2f_row6_col0\" class=\"data row6 col0\" ><img src=\"https://cdn.eyeem.com/thumb/991f5e54cb5563b3c9e5e061689421c1a672aeee-1406431509/2600/2600\" width=\"400\"/></td>\n",
       "      <td id=\"T_aea2f_row6_col1\" class=\"data row6 col1\" >tree, focus on foreground, branch, growth, tree trunk, close-up, nature, leaf, forest, selective focus, tranquility, plant, day, outdoors, twig, no people, sunlight, green color, beauty in nature, stem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aea2f_row7_col0\" class=\"data row7 col0\" ><img src=\"https://i1.wp.com/artsyforager.com/wp-content/uploads/2016/02/Redwoods4.jpg?resize=600%2C800\" width=\"400\"/></td>\n",
       "      <td id=\"T_aea2f_row7_col1\" class=\"data row7 col1\" >Finding Latitude. The Redwoods | artsy forager #travel #nature #photography #findinglatitude #redwoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aea2f_row8_col0\" class=\"data row8 col0\" ><img src=\"https://0.s3.envato.com/files/217499708/preview.jpg\" width=\"400\"/></td>\n",
       "      <td id=\"T_aea2f_row8_col1\" class=\"data row8 col1\" >Download Morning Forest in Fog nulled download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_aea2f_row9_col0\" class=\"data row9 col0\" ><img src=\"https://www.commercialcafe.com/blog/wp-content/uploads/sites/10/2020/08/Best-US-Cities-by-Public-Parks-and-Walkability.jpg?w=1280&h=500&crop=1\" width=\"400\"/></td>\n",
       "      <td id=\"T_aea2f_row9_col1\" class=\"data row9 col1\" >Best US Cities by Public Parks and Walkability</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output-location: slide\n",
    "\n",
    "import requests\n",
    "import PIL\n",
    "\n",
    "image_url = \"https://images.unsplash.com/photo-1425913397330-cf8af2ff40a1?w=600\"\n",
    "\n",
    "image = PIL.Image.open(\n",
    "  requests.get(image_url, stream=True).raw\n",
    ")\n",
    "\n",
    "# Search *image* embeddings with *image* embeddings\n",
    "\n",
    "query_image_embedding = model3.encode([image])\n",
    "\n",
    "distances, indices = nn.kneighbors(query_image_embedding)\n",
    "\n",
    "display_results(df, \"Image\", indices, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary {background=\"#E2E8F0\"}\n",
    "\n",
    "`TODO`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you! {background=black .center .center-horizontal}\n",
    "\n",
    "![](assets/qr-talk-url.png){width=\"250\" height=\"250\"}\n",
    "\n",
    "::: footer\n",
    "Made with [**Quarto**](https://quarto.org)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One more thing... {background=black .center .center-horizontal visibility=uncounted}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a tiny transformer model {background=\"#3182CE\" .center visibility=uncounted}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a tiny transformer model {visibility=uncounted}\n",
    "\n",
    "- **`nanoGPT`** by Andrej Karpathy\n",
    "- Implementation: `model.py`, `train.py`, `sample.py`\n",
    "- Training: `data/shakespeare_char`, `config/train_shakespeare_char.py`\n",
    "- All ~ 850 LOC\n",
    "- NYT: [*\"Watch an A.I. Learn to Write by Reading Nothing but ...\"*](https://www.nytimes.com/interactive/2023/04/26/upshot/gpt-from-scratch.html?unlocked_article_code=l7MJ8rlrXXZWztIDZPVJMffgm9ywa9txD9FRNNt4z3gPq84LT9p-KxZiodhJ7e7IQpxXD-oWwBvfI7X3tdUbAZoojsnmn-QcW4mR-lme_ma7etxoVzD07tG8-1SaUi1xS7Uh4SM64m4ebkO1p3RVM9UJHdbbqX4u9qQH826vamoqkLJkE1HYSxUbNlXsIXH3bgwYukofD_YfxpxDwa8dQaQr0WtmObuj9U3fvDQSiWxJxEFMFzY6aJiyz6JErTVtbU0vSy6PYT1EECSeBY5UX0_YbwXIJreNN61XDe79D8LJsD6lgwSQ3VVT1NIzCE5su3vLwbvnugUupa5fLbmmNt2P0HaViZWlkA)\n",
    "\n",
    "::: aside\n",
    "<https://github.com/karpathy/nanoGPT>\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "➍ Training a tiny transformer model\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's clone the repository... {.slide-code visibility=uncounted}\n",
    "\n",
    "::: footer\n",
    "➍ Training a tiny transformer model\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mtmp/nanoGPT\u001b[0m\n",
      "├── \u001b[00mLICENSE\u001b[0m\n",
      "├── \u001b[00mREADME.md\u001b[0m\n",
      "├── \u001b[00mbench.py\u001b[0m\n",
      "├── \u001b[00mconfigurator.py\u001b[0m\n",
      "├── \u001b[00mmodel.py\u001b[0m\n",
      "├── \u001b[00msample.py\u001b[0m\n",
      "├── \u001b[00mscaling_laws.ipynb\u001b[0m\n",
      "├── \u001b[00mtrain.py\u001b[0m\n",
      "├── \u001b[00mtransformer_sizing.ipynb\u001b[0m\n",
      "├── \u001b[01;34massets\u001b[0m\n",
      "│   ├── \u001b[00mgpt2_124M_loss.png\u001b[0m\n",
      "│   └── \u001b[01;35mnanogpt.jpg\u001b[0m\n",
      "├── \u001b[01;34mconfig\u001b[0m\n",
      "│   ├── \u001b[00meval_gpt2.py\u001b[0m\n",
      "│   ├── \u001b[00meval_gpt2_large.py\u001b[0m\n",
      "│   ├── \u001b[00meval_gpt2_medium.py\u001b[0m\n",
      "│   ├── \u001b[00meval_gpt2_xl.py\u001b[0m\n",
      "│   ├── \u001b[00mfinetune_python_peps.py\u001b[0m\n",
      "│   ├── \u001b[00mfinetune_shakespeare.py\u001b[0m\n",
      "│   ├── \u001b[00mtrain_gpt2.py\u001b[0m\n",
      "│   ├── \u001b[00mtrain_python_peps_char.py\u001b[0m\n",
      "│   └── \u001b[00mtrain_shakespeare_char.py\u001b[0m\n",
      "└── \u001b[01;34mdata\u001b[0m\n",
      "    ├── \u001b[01;34mopenwebtext\u001b[0m\n",
      "    │   ├── \u001b[00mprepare.py\u001b[0m\n",
      "    │   └── \u001b[00mreadme.md\u001b[0m\n",
      "    ├── \u001b[01;34mpython_peps\u001b[0m\n",
      "    │   └── \u001b[00mprepare.py\u001b[0m\n",
      "    ├── \u001b[01;34mpython_peps_char\u001b[0m\n",
      "    │   └── \u001b[00mprepare.py\u001b[0m\n",
      "    ├── \u001b[01;34mshakespeare\u001b[0m\n",
      "    │   ├── \u001b[00mprepare.py\u001b[0m\n",
      "    │   └── \u001b[00mreadme.md\u001b[0m\n",
      "    └── \u001b[01;34mshakespeare_char\u001b[0m\n",
      "        ├── \u001b[00mprepare.py\u001b[0m\n",
      "        └── \u001b[00mreadme.md\u001b[0m\n",
      "\n",
      "8 directories, 28 files\n"
     ]
    }
   ],
   "source": [
    "! [ -d 'tmp/nanoGPT' ] || \\\n",
    "  git clone -q 'https://github.com/karmi/nanoGPT.git' -b config_python_peps 'tmp/nanoGPT'\n",
    "\n",
    "! tree --filesfirst 'tmp/nanoGPT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's download and prepare the data... {.slide-code visibility=uncounted}\n",
    "\n",
    "::: aside\n",
    "<https://github.com/python/peps>\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "➍ Training a tiny transformer model\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded ZIP to /var/folders/n8/vs92rw8d3z53yxqcfvt9nk9m0000gn/T/tmprjg5wt9q  \n",
      "Extracted content to /var/folders/n8/vs92rw8d3z53yxqcfvt9nk9m0000gn/T/tmp738t2vmv\n",
      "length of dataset in characters: 10,824,592                                     \n",
      "all the unique characters: \n",
      "\f !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¢§®°±µ½ÅÉ×ØßàáäåçèéíïñóöøúüčŁłňšżƛƴʻ̴̷̡̧̨̛̗̘̙̜̝̞̟̣̤̦̩̪̫̬̭̮̯̲̹̺̻̼͇͈͉͍͎̀̂̃̄̆̇̉̊̍̏̒̓̔̽̾̿͆ͅ͏͓͔͙͚͐͑͒͗ͤͥͧͨͩͮͯ͜͢͠͡ΒάαβγεοπτВДНСабвеиклмнорстуцяѕאךערةقمي٥߅৪୨௫ḚṮἤ‏–—‘’“”…ⁿℂℌℕℙ™℮→∀∃∅≈⊗⋅⌁⌚⒯─│┌┐└┘┬┴╌☂☃☺♨⚛✎✒✓⧟⬛スパム十大学屆年日曜月槀櫰波激火筑粹羔鈩ﬁ＞ｎ￥�𝐧𝘯🐱\n",
      "vocab size: 323\n",
      "train has 9,742,132 tokens\n",
      "val has 1,082,460 tokens\n"
     ]
    }
   ],
   "source": [
    "! python3 'tmp/nanoGPT/data/python_peps_char/prepare.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run the training for 100 iterations... {.slide-code visibility=uncounted}\n",
    "\n",
    "::: {.callout-note}\n",
    "Replace the `mps` device when not running on Apple M1/M2 hardware.\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "➍ Training a tiny transformer model\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_python_peps_char.py:\n",
      "# train a miniature character-level model based on Python PEPs\n",
      "# https://peps.python.org/pep-0001/\n",
      "\n",
      "out_dir = \"out-python-peps-char\"\n",
      "eval_interval = 100\n",
      "eval_iters = 20\n",
      "log_interval = 1\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = False  # override via command line if you like\n",
      "wandb_project = \"python-peps-char\"\n",
      "wandb_run_name = None\n",
      "\n",
      "dataset = \"python_peps_char\"\n",
      "gradient_accumulation_steps = 1\n",
      "batch_size = 64\n",
      "block_size = 256  # context of up to 256 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 6\n",
      "n_head = 6\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3  # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = max_iters  # make equal to max_iters usually\n",
      "min_lr = 1e-4  # learning_rate / 10 usually\n",
      "beta2 = 0.99  # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 0  # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'mps'  # run on MPS (https://github.com/karpathy/nanoGPT/issues/28)\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "Overriding: device = mps\n",
      "Overriding: compile = False\n",
      "Overriding: max_iters = 100\n",
      "Overriding: log_interval = 10\n",
      "Overriding: eval_interval = 10\n",
      "Overriding: block_size = 128\n",
      "Overriding: batch_size = 12\n",
      "tokens per iteration will be: 1,536\n",
      "found vocab_size = 323 (inside data/python_peps_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 10.75M\n",
      "/opt/homebrew/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "num decayed parameter tensors: 26, with 10,790,016 parameters\n",
      "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
      "using fused AdamW: False\n",
      "step 0: train loss 5.7881, val loss 5.7859\n",
      "iter 0: loss 5.8206, time 2051.09ms, mfu -100.00%\n",
      "step 10: train loss 3.4102, val loss 3.4164\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 10: loss 3.2577, time 2073.89ms, mfu 0.02%\n",
      "step 20: train loss 3.3962, val loss 3.4160\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 20: loss 3.5071, time 2063.53ms, mfu 0.02%\n",
      "step 30: train loss 3.2524, val loss 3.2869\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 30: loss 3.2609, time 2075.96ms, mfu 0.02%\n",
      "step 40: train loss 3.1787, val loss 3.1473\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 40: loss 3.1098, time 2068.78ms, mfu 0.02%\n",
      "step 50: train loss 3.0840, val loss 3.0892\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 50: loss 3.0965, time 2068.53ms, mfu 0.02%\n",
      "step 60: train loss 3.0588, val loss 3.0387\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 60: loss 2.8480, time 2037.31ms, mfu 0.02%\n",
      "step 70: train loss 2.9941, val loss 2.9716\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 70: loss 3.0581, time 2063.60ms, mfu 0.02%\n",
      "step 80: train loss 2.9373, val loss 2.9428\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 80: loss 2.9166, time 2058.22ms, mfu 0.02%\n",
      "step 90: train loss 2.8879, val loss 2.9092\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 90: loss 2.9189, time 2056.94ms, mfu 0.02%\n",
      "step 100: train loss 2.8599, val loss 2.8568\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 100: loss 2.8701, time 2097.65ms, mfu 0.02%\n"
     ]
    }
   ],
   "source": [
    "! (cd 'tmp/nanoGPT' && \\\n",
    "  python3 train.py 'config/train_python_peps_char.py' \\\n",
    "  --device=mps --compile=False \\\n",
    "  --max_iters=100 --log_interval=10 --eval_interval=10 \\\n",
    "  --block_size=128 --batch_size=12 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try the output... {.slide-code visibility=uncounted}\n",
    "\n",
    "::: footer\n",
    "➍ Training a tiny transformer model\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-python-peps-char\n",
      "Overriding: num_samples = 1\n",
      "Overriding: max_new_tokens = 500\n",
      "Overriding: device = cpu\n",
      "Overriding: seed = 1694413979\n",
      "Overriding: start = A good Python code is \n",
      "number of parameters: 10.75M\n",
      "Loading meta from data/python_peps_char/meta.pkl...\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "A good Python code is  finmos atrerenalar.-sputhe bdinaxlyfas  ano e be te gemenob enguorpllethenenmen osul minnle ad en thexbkerpos n x[ ter\n",
      "s fe otife l\n",
      "\n",
      "  nnps ausyne ans. then at/roosptoorad f me-pesico g orar us  nutheps, thitit._P anin bsesenenos tet.\n",
      ".\n",
      "dicor ance t\n",
      ". lenesints bef sitatsere si onotanf t  d b bincedesefarn t a m e vacjowo lale nurerat4 onor age e anise g mr be onthe-xp an nacof ted tatandasiblarodorong i  thndhan leron  canserinin herd plin fon anatenanpathef s  rithere Ghucotos d tiyronsedur t...\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "! (cd 'tmp/nanoGPT' && \\\n",
    "    python3 sample.py \\\n",
    "    --out_dir=out-python-peps-char \\\n",
    "    --num_samples=1 \\\n",
    "    --max_new_tokens=500 \\\n",
    "    --device=cpu \\\n",
    "    --seed=\"$(date +%s)\" \\\n",
    "    --start='A good Python code is ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's continue the training for 1000 iterations... {.slide-code visibility=uncounted}\n",
    "\n",
    "::: footer\n",
    "➍ Training a tiny transformer model\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_python_peps_char.py:\n",
      "# train a miniature character-level model based on Python PEPs\n",
      "# https://peps.python.org/pep-0001/\n",
      "\n",
      "out_dir = \"out-python-peps-char\"\n",
      "eval_interval = 100\n",
      "eval_iters = 20\n",
      "log_interval = 1\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = False  # override via command line if you like\n",
      "wandb_project = \"python-peps-char\"\n",
      "wandb_run_name = None\n",
      "\n",
      "dataset = \"python_peps_char\"\n",
      "gradient_accumulation_steps = 1\n",
      "batch_size = 64\n",
      "block_size = 256  # context of up to 256 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 6\n",
      "n_head = 6\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3  # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = max_iters  # make equal to max_iters usually\n",
      "min_lr = 1e-4  # learning_rate / 10 usually\n",
      "beta2 = 0.99  # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 0  # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'mps'  # run on MPS (https://github.com/karpathy/nanoGPT/issues/28)\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "Overriding: device = mps\n",
      "Overriding: compile = False\n",
      "Overriding: max_iters = 1000\n",
      "Overriding: eval_interval = 100\n",
      "Overriding: log_interval = 10\n",
      "Overriding: block_size = 128\n",
      "Overriding: batch_size = 12\n",
      "Overriding: init_from = resume\n",
      "tokens per iteration will be: 1,536\n",
      "found vocab_size = 323 (inside data/python_peps_char/meta.pkl)\n",
      "Resuming training from out-python-peps-char\n",
      "number of parameters: 10.75M\n",
      "/opt/homebrew/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "num decayed parameter tensors: 26, with 10,790,016 parameters\n",
      "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
      "using fused AdamW: False\n",
      "step 100: train loss 2.8493, val loss 2.8981\n",
      "iter 100: loss 3.1073, time 2046.86ms, mfu -100.00%\n",
      "iter 110: loss 2.8265, time 159.36ms, mfu 0.21%\n",
      "iter 120: loss 2.9178, time 158.76ms, mfu 0.21%\n",
      "iter 130: loss 3.0910, time 158.29ms, mfu 0.21%\n",
      "iter 140: loss 2.7329, time 153.66ms, mfu 0.21%\n",
      "iter 150: loss 2.7806, time 154.46ms, mfu 0.21%\n",
      "iter 160: loss 2.8659, time 156.52ms, mfu 0.21%\n",
      "iter 170: loss 2.7454, time 160.12ms, mfu 0.21%\n",
      "iter 180: loss 2.7229, time 160.91ms, mfu 0.21%\n",
      "iter 190: loss 2.7062, time 157.70ms, mfu 0.21%\n",
      "step 200: train loss 2.7405, val loss 2.7242\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 200: loss 2.7714, time 2047.83ms, mfu 0.19%\n",
      "iter 210: loss 2.9391, time 155.69ms, mfu 0.19%\n",
      "iter 220: loss 2.7786, time 159.49ms, mfu 0.20%\n",
      "iter 230: loss 2.5624, time 160.60ms, mfu 0.20%\n",
      "iter 240: loss 2.8867, time 155.25ms, mfu 0.20%\n",
      "iter 250: loss 2.6296, time 155.96ms, mfu 0.20%\n",
      "iter 260: loss 2.6903, time 160.19ms, mfu 0.20%\n",
      "iter 270: loss 2.6721, time 157.93ms, mfu 0.20%\n",
      "iter 280: loss 2.7015, time 158.63ms, mfu 0.20%\n",
      "iter 290: loss 2.8002, time 155.70ms, mfu 0.20%\n",
      "step 300: train loss 2.6667, val loss 2.7120\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 300: loss 2.9318, time 2085.57ms, mfu 0.19%\n",
      "iter 310: loss 2.7656, time 157.16ms, mfu 0.19%\n",
      "iter 320: loss 2.7524, time 155.57ms, mfu 0.19%\n",
      "iter 330: loss 2.8231, time 153.63ms, mfu 0.19%\n",
      "iter 340: loss 2.6844, time 154.04ms, mfu 0.20%\n",
      "iter 350: loss 2.6755, time 159.30ms, mfu 0.20%\n",
      "iter 360: loss 2.6727, time 154.88ms, mfu 0.20%\n",
      "iter 370: loss 2.6401, time 158.10ms, mfu 0.20%\n",
      "iter 380: loss 2.5010, time 155.52ms, mfu 0.20%\n",
      "iter 390: loss 2.5265, time 156.44ms, mfu 0.20%\n",
      "step 400: train loss 2.6272, val loss 2.6283\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 400: loss 2.6528, time 2061.84ms, mfu 0.18%\n",
      "iter 410: loss 2.6632, time 157.79ms, mfu 0.19%\n",
      "iter 420: loss 2.6937, time 156.75ms, mfu 0.19%\n",
      "iter 430: loss 2.3994, time 156.39ms, mfu 0.19%\n",
      "iter 440: loss 2.6321, time 161.98ms, mfu 0.19%\n",
      "iter 450: loss 2.5794, time 160.79ms, mfu 0.20%\n",
      "iter 460: loss 2.5512, time 157.49ms, mfu 0.20%\n",
      "iter 470: loss 2.6617, time 157.31ms, mfu 0.20%\n",
      "iter 480: loss 2.5715, time 158.38ms, mfu 0.20%\n",
      "iter 490: loss 2.6151, time 159.02ms, mfu 0.20%\n",
      "step 500: train loss 2.6002, val loss 2.6242\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 500: loss 2.5579, time 2069.60ms, mfu 0.18%\n",
      "iter 510: loss 2.6138, time 157.67ms, mfu 0.19%\n",
      "iter 520: loss 2.5819, time 159.96ms, mfu 0.19%\n",
      "iter 530: loss 2.6238, time 158.65ms, mfu 0.19%\n",
      "iter 540: loss 2.6576, time 159.97ms, mfu 0.19%\n",
      "iter 550: loss 2.4655, time 159.78ms, mfu 0.19%\n",
      "iter 560: loss 2.6956, time 157.31ms, mfu 0.20%\n",
      "iter 570: loss 2.4883, time 160.03ms, mfu 0.20%\n",
      "iter 580: loss 2.5292, time 156.90ms, mfu 0.20%\n",
      "iter 590: loss 2.7204, time 160.22ms, mfu 0.20%\n",
      "step 600: train loss 2.6054, val loss 2.5751\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 600: loss 2.6876, time 2079.26ms, mfu 0.18%\n",
      "iter 610: loss 2.6970, time 160.55ms, mfu 0.18%\n",
      "iter 620: loss 2.5635, time 159.51ms, mfu 0.19%\n",
      "iter 630: loss 2.5722, time 159.64ms, mfu 0.19%\n",
      "iter 640: loss 2.6576, time 159.29ms, mfu 0.19%\n",
      "iter 650: loss 2.6629, time 158.75ms, mfu 0.19%\n",
      "iter 660: loss 2.4561, time 160.27ms, mfu 0.19%\n",
      "iter 670: loss 2.5355, time 159.05ms, mfu 0.20%\n",
      "iter 680: loss 2.6293, time 157.54ms, mfu 0.20%\n",
      "iter 690: loss 2.4230, time 161.01ms, mfu 0.20%\n",
      "step 700: train loss 2.5462, val loss 2.5384\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 700: loss 2.5740, time 2065.55ms, mfu 0.18%\n",
      "iter 710: loss 2.4509, time 156.57ms, mfu 0.18%\n",
      "iter 720: loss 2.6919, time 157.44ms, mfu 0.19%\n",
      "iter 730: loss 2.4529, time 160.13ms, mfu 0.19%\n",
      "iter 740: loss 2.6126, time 151.79ms, mfu 0.19%\n",
      "iter 750: loss 2.6207, time 152.63ms, mfu 0.19%\n",
      "iter 760: loss 2.3668, time 159.03ms, mfu 0.20%\n",
      "iter 770: loss 2.5513, time 159.26ms, mfu 0.20%\n",
      "iter 780: loss 2.5633, time 157.27ms, mfu 0.20%\n",
      "iter 790: loss 2.4206, time 159.83ms, mfu 0.20%\n",
      "step 800: train loss 2.4368, val loss 2.4322\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 800: loss 2.4541, time 2080.52ms, mfu 0.18%\n",
      "iter 810: loss 2.4992, time 156.59ms, mfu 0.19%\n",
      "iter 820: loss 2.5003, time 156.95ms, mfu 0.19%\n",
      "iter 830: loss 2.4490, time 159.98ms, mfu 0.19%\n",
      "iter 840: loss 2.4964, time 155.40ms, mfu 0.19%\n",
      "iter 850: loss 2.4557, time 155.21ms, mfu 0.19%\n",
      "iter 860: loss 2.5860, time 161.07ms, mfu 0.20%\n",
      "iter 870: loss 2.4550, time 159.33ms, mfu 0.20%\n",
      "iter 880: loss 2.4199, time 160.35ms, mfu 0.20%\n",
      "iter 890: loss 2.5686, time 157.15ms, mfu 0.20%\n",
      "step 900: train loss 2.3250, val loss 2.3649\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 900: loss 2.4752, time 2063.28ms, mfu 0.18%\n",
      "iter 910: loss 2.4306, time 159.17ms, mfu 0.18%\n",
      "iter 920: loss 2.3784, time 159.83ms, mfu 0.19%\n",
      "iter 930: loss 2.3465, time 158.60ms, mfu 0.19%\n",
      "iter 940: loss 2.3496, time 160.31ms, mfu 0.19%\n",
      "iter 950: loss 2.2669, time 160.17ms, mfu 0.19%\n",
      "iter 960: loss 2.3639, time 160.37ms, mfu 0.19%\n",
      "iter 970: loss 2.3838, time 156.35ms, mfu 0.20%\n",
      "iter 980: loss 2.3694, time 159.58ms, mfu 0.20%\n",
      "iter 990: loss 2.3414, time 160.78ms, mfu 0.20%\n",
      "step 1000: train loss 2.2963, val loss 2.3054\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 1000: loss 2.3887, time 2068.74ms, mfu 0.18%\n"
     ]
    }
   ],
   "source": [
    "! (cd 'tmp/nanoGPT' && \\\n",
    "  python3 train.py 'config/train_python_peps_char.py' \\\n",
    "  --device=mps --compile=False \\\n",
    "  --max_iters=1000 --eval_interval=100 --log_interval=10 \\\n",
    "  --block_size=128 --batch_size=12 \\\n",
    "  --init_from='resume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... and let's try the output again. {.slide-code visibility=uncounted}\n",
    "\n",
    "::: footer\n",
    "➍ Training a tiny transformer model\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-python-peps-char\n",
      "Overriding: num_samples = 1\n",
      "Overriding: max_new_tokens = 500\n",
      "Overriding: device = cpu\n",
      "Overriding: seed = 1694414209\n",
      "Overriding: start = A good Python code is \n",
      "number of parameters: 10.75M\n",
      "Loading meta from data/python_peps_char/meta.pkl...\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "A good Python code is cons cons Loutimian be taluple binte a\n",
      "\n",
      "-------------\n",
      "\n",
      "A cary is is and the to pron the the kally en norcly extectse fin of vally.\n",
      "\n",
      "N    the thin-ch the pes it the wilosimpor fore``` in cle of to denc: on of ` are birerm typeppvas the pocking the vablort ancat_telle```` mef. \n",
      "-Worf the st `````__Explernclomplect exate ford alltion is to mers etuto ar Gat wsit the ust suctionche ther an\n",
      "for con cas ` onctize por seas usupor she inaction\n",
      "de the cover peveg rarnt is of din as ave cal `````````` all...\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "! (cd 'tmp/nanoGPT' && \\\n",
    "    python3 sample.py \\\n",
    "    --out_dir=out-python-peps-char \\\n",
    "    --num_samples=1 \\\n",
    "    --max_new_tokens=500 \\\n",
    "    --device=cpu \\\n",
    "    --seed=\"$(date +%s)\" \\\n",
    "    --start='A good Python code is ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run 5000 iterations... {.slide-code visibility=uncounted}\n",
    "\n",
    "::: footer\n",
    "➍ Training a tiny transformer model\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_python_peps_char.py:\n",
      "# train a miniature character-level model based on Python PEPs\n",
      "# https://peps.python.org/pep-0001/\n",
      "\n",
      "out_dir = \"out-python-peps-char\"\n",
      "eval_interval = 100\n",
      "eval_iters = 20\n",
      "log_interval = 1\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = False  # override via command line if you like\n",
      "wandb_project = \"python-peps-char\"\n",
      "wandb_run_name = None\n",
      "\n",
      "dataset = \"python_peps_char\"\n",
      "gradient_accumulation_steps = 1\n",
      "batch_size = 64\n",
      "block_size = 256  # context of up to 256 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 6\n",
      "n_head = 6\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3  # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = max_iters  # make equal to max_iters usually\n",
      "min_lr = 1e-4  # learning_rate / 10 usually\n",
      "beta2 = 0.99  # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 0  # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'mps'  # run on MPS (https://github.com/karpathy/nanoGPT/issues/28)\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "Overriding: device = mps\n",
      "Overriding: compile = False\n",
      "Overriding: max_iters = 5000\n",
      "Overriding: eval_interval = 100\n",
      "Overriding: log_interval = 10\n",
      "Overriding: block_size = 128\n",
      "Overriding: batch_size = 12\n",
      "Overriding: init_from = resume\n",
      "tokens per iteration will be: 1,536\n",
      "found vocab_size = 323 (inside data/python_peps_char/meta.pkl)\n",
      "Resuming training from out-python-peps-char\n",
      "number of parameters: 10.75M\n",
      "/opt/homebrew/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "num decayed parameter tensors: 26, with 10,790,016 parameters\n",
      "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
      "using fused AdamW: False\n",
      "step 1000: train loss 2.2751, val loss 2.3217\n",
      "iter 1000: loss 2.5321, time 2033.84ms, mfu -100.00%\n",
      "iter 1010: loss 2.2959, time 159.70ms, mfu 0.21%\n",
      "iter 1020: loss 2.3953, time 158.09ms, mfu 0.21%\n",
      "iter 1030: loss 2.5974, time 161.79ms, mfu 0.21%\n",
      "iter 1040: loss 2.2316, time 157.27ms, mfu 0.21%\n",
      "iter 1050: loss 2.2440, time 156.76ms, mfu 0.21%\n",
      "iter 1060: loss 2.3252, time 156.65ms, mfu 0.21%\n",
      "iter 1070: loss 2.2575, time 160.99ms, mfu 0.21%\n",
      "iter 1080: loss 2.2046, time 161.03ms, mfu 0.21%\n",
      "iter 1090: loss 2.3116, time 163.34ms, mfu 0.21%\n",
      "step 1100: train loss 2.2272, val loss 2.1941\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 1100: loss 2.3039, time 2091.49ms, mfu 0.19%\n",
      "iter 1110: loss 2.4511, time 159.44ms, mfu 0.19%\n",
      "iter 1120: loss 2.3735, time 160.46ms, mfu 0.19%\n",
      "iter 1130: loss 2.0979, time 161.30ms, mfu 0.20%\n",
      "iter 1140: loss 2.3787, time 160.13ms, mfu 0.20%\n",
      "iter 1150: loss 2.1693, time 161.58ms, mfu 0.20%\n",
      "iter 1160: loss 2.2239, time 160.76ms, mfu 0.20%\n",
      "iter 1170: loss 2.2148, time 161.68ms, mfu 0.20%\n",
      "iter 1180: loss 2.2410, time 158.69ms, mfu 0.20%\n",
      "iter 1190: loss 2.3768, time 164.45ms, mfu 0.20%\n",
      "step 1200: train loss 2.1342, val loss 2.1694\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 1200: loss 2.5234, time 2112.01ms, mfu 0.18%\n",
      "iter 1210: loss 2.2162, time 159.61ms, mfu 0.19%\n",
      "iter 1220: loss 2.2980, time 159.95ms, mfu 0.19%\n",
      "iter 1230: loss 2.3325, time 161.26ms, mfu 0.19%\n",
      "iter 1240: loss 2.2036, time 161.14ms, mfu 0.19%\n",
      "iter 1250: loss 2.2108, time 161.39ms, mfu 0.19%\n",
      "iter 1260: loss 2.2324, time 157.18ms, mfu 0.20%\n",
      "iter 1270: loss 2.1259, time 157.28ms, mfu 0.20%\n",
      "iter 1280: loss 2.0822, time 161.55ms, mfu 0.20%\n",
      "iter 1290: loss 2.0488, time 163.20ms, mfu 0.20%\n",
      "step 1300: train loss 2.0907, val loss 2.1053\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 1300: loss 2.1816, time 2099.70ms, mfu 0.18%\n",
      "iter 1310: loss 2.2082, time 161.58ms, mfu 0.18%\n",
      "iter 1320: loss 2.2260, time 163.80ms, mfu 0.19%\n",
      "iter 1330: loss 1.9390, time 164.23ms, mfu 0.19%\n",
      "iter 1340: loss 2.1417, time 165.60ms, mfu 0.19%\n",
      "iter 1350: loss 2.1275, time 163.67ms, mfu 0.19%\n",
      "iter 1360: loss 2.1526, time 165.04ms, mfu 0.19%\n",
      "iter 1370: loss 2.1847, time 163.83ms, mfu 0.19%\n",
      "iter 1380: loss 2.1439, time 164.30ms, mfu 0.19%\n",
      "iter 1390: loss 2.1694, time 163.08ms, mfu 0.19%\n",
      "step 1400: train loss 2.0535, val loss 2.0741\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 1400: loss 2.0581, time 2101.24ms, mfu 0.18%\n",
      "iter 1410: loss 2.1750, time 162.06ms, mfu 0.18%\n",
      "iter 1420: loss 2.1577, time 163.56ms, mfu 0.18%\n",
      "iter 1430: loss 2.0761, time 164.24ms, mfu 0.18%\n",
      "iter 1440: loss 2.1740, time 163.36ms, mfu 0.19%\n",
      "iter 1450: loss 1.9313, time 164.91ms, mfu 0.19%\n",
      "iter 1460: loss 2.2576, time 162.13ms, mfu 0.19%\n",
      "iter 1470: loss 1.9881, time 164.06ms, mfu 0.19%\n",
      "iter 1480: loss 2.0822, time 169.61ms, mfu 0.19%\n",
      "iter 1490: loss 2.2081, time 168.85ms, mfu 0.19%\n",
      "step 1500: train loss 2.0382, val loss 2.0223\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 1500: loss 2.2091, time 2107.37ms, mfu 0.18%\n",
      "iter 1510: loss 2.2030, time 162.18ms, mfu 0.18%\n",
      "iter 1520: loss 2.0815, time 164.80ms, mfu 0.18%\n",
      "iter 1530: loss 1.9971, time 168.94ms, mfu 0.18%\n",
      "iter 1540: loss 2.1914, time 163.79ms, mfu 0.18%\n",
      "iter 1550: loss 2.1675, time 164.10ms, mfu 0.19%\n",
      "iter 1560: loss 1.9964, time 164.74ms, mfu 0.19%\n",
      "iter 1570: loss 2.0627, time 163.78ms, mfu 0.19%\n",
      "iter 1580: loss 2.1765, time 164.61ms, mfu 0.19%\n",
      "iter 1590: loss 1.9497, time 161.92ms, mfu 0.19%\n",
      "step 1600: train loss 1.9919, val loss 1.9822\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 1600: loss 2.0485, time 2123.05ms, mfu 0.18%\n",
      "iter 1610: loss 2.0262, time 162.55ms, mfu 0.18%\n",
      "iter 1620: loss 2.2110, time 167.26ms, mfu 0.18%\n",
      "iter 1630: loss 1.9454, time 164.23ms, mfu 0.18%\n",
      "iter 1640: loss 2.1486, time 164.16ms, mfu 0.18%\n",
      "iter 1650: loss 2.1516, time 164.55ms, mfu 0.19%\n",
      "iter 1660: loss 1.9299, time 164.44ms, mfu 0.19%\n",
      "iter 1670: loss 2.0477, time 165.66ms, mfu 0.19%\n",
      "iter 1680: loss 2.0975, time 166.43ms, mfu 0.19%\n",
      "iter 1690: loss 1.9842, time 166.54ms, mfu 0.19%\n",
      "step 1700: train loss 1.9301, val loss 1.9373\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 1700: loss 1.9992, time 2134.01ms, mfu 0.17%\n",
      "iter 1710: loss 2.0447, time 163.00ms, mfu 0.18%\n",
      "iter 1720: loss 2.0757, time 167.05ms, mfu 0.18%\n",
      "iter 1730: loss 2.0395, time 165.84ms, mfu 0.18%\n",
      "iter 1740: loss 2.0162, time 166.06ms, mfu 0.18%\n",
      "iter 1750: loss 1.9759, time 165.70ms, mfu 0.19%\n",
      "iter 1760: loss 2.1395, time 165.43ms, mfu 0.19%\n",
      "iter 1770: loss 2.0391, time 158.29ms, mfu 0.19%\n",
      "iter 1780: loss 1.9806, time 163.78ms, mfu 0.19%\n",
      "iter 1790: loss 2.1135, time 167.92ms, mfu 0.19%\n",
      "step 1800: train loss 1.8766, val loss 1.9167\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 1800: loss 2.0355, time 2107.03ms, mfu 0.17%\n",
      "iter 1810: loss 2.0390, time 155.03ms, mfu 0.18%\n",
      "iter 1820: loss 2.0104, time 166.09ms, mfu 0.18%\n",
      "iter 1830: loss 1.9560, time 164.62ms, mfu 0.18%\n",
      "iter 1840: loss 2.0396, time 166.15ms, mfu 0.19%\n",
      "iter 1850: loss 1.9310, time 164.93ms, mfu 0.19%\n",
      "iter 1860: loss 1.9971, time 166.84ms, mfu 0.19%\n",
      "iter 1870: loss 1.9659, time 165.48ms, mfu 0.19%\n",
      "iter 1880: loss 1.9533, time 162.90ms, mfu 0.19%\n",
      "iter 1890: loss 1.9889, time 166.04ms, mfu 0.19%\n",
      "step 1900: train loss 1.8782, val loss 1.8935\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 1900: loss 2.0162, time 2109.06ms, mfu 0.17%\n",
      "iter 1910: loss 2.0120, time 165.15ms, mfu 0.18%\n",
      "iter 1920: loss 2.1173, time 166.94ms, mfu 0.18%\n",
      "iter 1930: loss 1.9274, time 163.11ms, mfu 0.18%\n",
      "iter 1940: loss 1.9207, time 163.72ms, mfu 0.18%\n",
      "iter 1950: loss 1.9227, time 163.95ms, mfu 0.19%\n",
      "iter 1960: loss 2.1500, time 157.30ms, mfu 0.19%\n",
      "iter 1970: loss 1.9999, time 164.34ms, mfu 0.19%\n",
      "iter 1980: loss 1.9464, time 163.36ms, mfu 0.19%\n",
      "iter 1990: loss 2.0942, time 164.16ms, mfu 0.19%\n",
      "step 2000: train loss 1.8126, val loss 1.8323\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 2000: loss 1.9382, time 2096.49ms, mfu 0.18%\n",
      "iter 2010: loss 1.8988, time 165.74ms, mfu 0.18%\n",
      "iter 2020: loss 1.9780, time 166.76ms, mfu 0.18%\n",
      "iter 2030: loss 2.1929, time 163.55ms, mfu 0.18%\n",
      "iter 2040: loss 2.0863, time 167.38ms, mfu 0.18%\n",
      "iter 2050: loss 1.9370, time 167.84ms, mfu 0.19%\n",
      "iter 2060: loss 1.8958, time 165.92ms, mfu 0.19%\n",
      "iter 2070: loss 1.8126, time 167.26ms, mfu 0.19%\n",
      "iter 2080: loss 2.1033, time 163.03ms, mfu 0.19%\n",
      "iter 2090: loss 1.9810, time 161.12ms, mfu 0.19%\n",
      "step 2100: train loss 1.8147, val loss 1.8624\n",
      "iter 2100: loss 1.9501, time 1903.94ms, mfu 0.17%\n",
      "iter 2110: loss 1.8082, time 164.58ms, mfu 0.18%\n",
      "iter 2120: loss 1.9426, time 165.68ms, mfu 0.18%\n",
      "iter 2130: loss 2.1383, time 163.34ms, mfu 0.18%\n",
      "iter 2140: loss 1.9970, time 166.34ms, mfu 0.18%\n",
      "iter 2150: loss 2.0046, time 166.80ms, mfu 0.19%\n",
      "iter 2160: loss 2.0325, time 166.42ms, mfu 0.19%\n",
      "iter 2170: loss 1.8115, time 166.18ms, mfu 0.19%\n",
      "iter 2180: loss 1.9505, time 163.50ms, mfu 0.19%\n",
      "iter 2190: loss 1.9368, time 164.19ms, mfu 0.19%\n",
      "step 2200: train loss 1.8122, val loss 1.8284\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 2200: loss 2.0438, time 2130.31ms, mfu 0.17%\n",
      "iter 2210: loss 1.8211, time 160.78ms, mfu 0.18%\n",
      "iter 2220: loss 1.8429, time 164.96ms, mfu 0.18%\n",
      "iter 2230: loss 1.8908, time 165.08ms, mfu 0.18%\n",
      "iter 2240: loss 1.8971, time 165.61ms, mfu 0.18%\n",
      "iter 2250: loss 1.9284, time 167.34ms, mfu 0.19%\n",
      "iter 2260: loss 1.7465, time 165.35ms, mfu 0.19%\n",
      "iter 2270: loss 1.8372, time 166.68ms, mfu 0.19%\n",
      "iter 2280: loss 1.9061, time 162.99ms, mfu 0.19%\n",
      "iter 2290: loss 1.8952, time 163.61ms, mfu 0.19%\n",
      "step 2300: train loss 1.7657, val loss 1.7991\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 2300: loss 2.0742, time 2096.83ms, mfu 0.17%\n",
      "iter 2310: loss 1.8250, time 166.97ms, mfu 0.18%\n",
      "iter 2320: loss 1.7708, time 164.46ms, mfu 0.18%\n",
      "iter 2330: loss 1.9168, time 166.20ms, mfu 0.18%\n",
      "iter 2340: loss 1.9586, time 163.30ms, mfu 0.18%\n",
      "iter 2350: loss 1.7589, time 166.18ms, mfu 0.19%\n",
      "iter 2360: loss 1.9428, time 168.06ms, mfu 0.19%\n",
      "iter 2370: loss 1.8045, time 164.80ms, mfu 0.19%\n",
      "iter 2380: loss 1.8843, time 163.61ms, mfu 0.19%\n",
      "iter 2390: loss 2.0198, time 163.90ms, mfu 0.19%\n",
      "step 2400: train loss 1.7510, val loss 1.7999\n",
      "iter 2400: loss 1.8528, time 1904.17ms, mfu 0.17%\n",
      "iter 2410: loss 1.8748, time 164.39ms, mfu 0.18%\n",
      "iter 2420: loss 1.7897, time 164.89ms, mfu 0.18%\n",
      "iter 2430: loss 1.7412, time 163.11ms, mfu 0.18%\n",
      "iter 2440: loss 1.8162, time 164.41ms, mfu 0.18%\n",
      "iter 2450: loss 1.9715, time 165.29ms, mfu 0.19%\n",
      "iter 2460: loss 1.8782, time 163.82ms, mfu 0.19%\n",
      "iter 2470: loss 1.9325, time 164.61ms, mfu 0.19%\n",
      "iter 2480: loss 1.7956, time 164.44ms, mfu 0.19%\n",
      "iter 2490: loss 1.8469, time 164.23ms, mfu 0.19%\n",
      "step 2500: train loss 1.7438, val loss 1.7246\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 2500: loss 1.7390, time 2134.78ms, mfu 0.17%\n",
      "iter 2510: loss 1.9502, time 162.77ms, mfu 0.18%\n",
      "iter 2520: loss 1.8342, time 165.67ms, mfu 0.18%\n",
      "iter 2530: loss 1.7282, time 166.50ms, mfu 0.18%\n",
      "iter 2540: loss 1.8788, time 164.06ms, mfu 0.18%\n",
      "iter 2550: loss 1.8752, time 164.71ms, mfu 0.19%\n",
      "iter 2560: loss 1.8382, time 164.10ms, mfu 0.19%\n",
      "iter 2570: loss 1.7344, time 162.98ms, mfu 0.19%\n",
      "iter 2580: loss 1.8608, time 166.38ms, mfu 0.19%\n",
      "iter 2590: loss 1.7900, time 164.99ms, mfu 0.19%\n",
      "step 2600: train loss 1.7316, val loss 1.7415\n",
      "iter 2600: loss 1.8116, time 1897.27ms, mfu 0.17%\n",
      "iter 2610: loss 1.8210, time 164.74ms, mfu 0.18%\n",
      "iter 2620: loss 1.8711, time 164.79ms, mfu 0.18%\n",
      "iter 2630: loss 1.8306, time 162.46ms, mfu 0.18%\n",
      "iter 2640: loss 1.7361, time 163.82ms, mfu 0.18%\n",
      "iter 2650: loss 1.7243, time 163.83ms, mfu 0.19%\n",
      "iter 2660: loss 1.8159, time 163.69ms, mfu 0.19%\n",
      "iter 2670: loss 1.8114, time 165.92ms, mfu 0.19%\n",
      "iter 2680: loss 1.8332, time 165.18ms, mfu 0.19%\n",
      "iter 2690: loss 1.8311, time 165.00ms, mfu 0.19%\n",
      "step 2700: train loss 1.6947, val loss 1.7094\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 2700: loss 1.8775, time 2120.45ms, mfu 0.17%\n",
      "iter 2710: loss 1.9892, time 159.29ms, mfu 0.18%\n",
      "iter 2720: loss 1.9068, time 168.33ms, mfu 0.18%\n",
      "iter 2730: loss 1.8624, time 164.18ms, mfu 0.18%\n",
      "iter 2740: loss 2.0804, time 164.69ms, mfu 0.18%\n",
      "iter 2750: loss 1.7825, time 165.19ms, mfu 0.19%\n",
      "iter 2760: loss 1.8506, time 164.88ms, mfu 0.19%\n",
      "iter 2770: loss 1.8467, time 164.96ms, mfu 0.19%\n",
      "iter 2780: loss 1.7341, time 163.63ms, mfu 0.19%\n",
      "iter 2790: loss 1.9544, time 164.20ms, mfu 0.19%\n",
      "step 2800: train loss 1.6984, val loss 1.6776\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 2800: loss 1.7847, time 2130.00ms, mfu 0.17%\n",
      "iter 2810: loss 1.6469, time 163.73ms, mfu 0.18%\n",
      "iter 2820: loss 1.6615, time 164.24ms, mfu 0.18%\n",
      "iter 2830: loss 1.8137, time 164.88ms, mfu 0.18%\n",
      "iter 2840: loss 1.8090, time 165.33ms, mfu 0.18%\n",
      "iter 2850: loss 1.8369, time 164.53ms, mfu 0.19%\n",
      "iter 2860: loss 1.7922, time 165.48ms, mfu 0.19%\n",
      "iter 2870: loss 1.7941, time 165.22ms, mfu 0.19%\n",
      "iter 2880: loss 1.7938, time 165.05ms, mfu 0.19%\n",
      "iter 2890: loss 1.7479, time 163.64ms, mfu 0.19%\n",
      "step 2900: train loss 1.6336, val loss 1.6960\n",
      "iter 2900: loss 1.7545, time 1893.25ms, mfu 0.17%\n",
      "iter 2910: loss 1.8330, time 164.16ms, mfu 0.18%\n",
      "iter 2920: loss 1.8226, time 164.29ms, mfu 0.18%\n",
      "iter 2930: loss 1.8460, time 163.23ms, mfu 0.18%\n",
      "iter 2940: loss 1.7338, time 167.41ms, mfu 0.18%\n",
      "iter 2950: loss 1.7633, time 164.08ms, mfu 0.19%\n",
      "iter 2960: loss 1.8092, time 163.60ms, mfu 0.19%\n",
      "iter 2970: loss 1.7407, time 163.96ms, mfu 0.19%\n",
      "iter 2980: loss 1.8220, time 165.03ms, mfu 0.19%\n",
      "iter 2990: loss 1.8005, time 166.81ms, mfu 0.19%\n",
      "step 3000: train loss 1.7105, val loss 1.6684\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 3000: loss 1.7108, time 2129.25ms, mfu 0.17%\n",
      "iter 3010: loss 1.7510, time 164.12ms, mfu 0.18%\n",
      "iter 3020: loss 1.6979, time 167.62ms, mfu 0.18%\n",
      "iter 3030: loss 1.7289, time 163.67ms, mfu 0.18%\n",
      "iter 3040: loss 2.0497, time 163.84ms, mfu 0.18%\n",
      "iter 3050: loss 1.5651, time 166.91ms, mfu 0.19%\n",
      "iter 3060: loss 1.8488, time 163.34ms, mfu 0.19%\n",
      "iter 3070: loss 1.7764, time 164.49ms, mfu 0.19%\n",
      "iter 3080: loss 1.6803, time 162.05ms, mfu 0.19%\n",
      "iter 3090: loss 1.7195, time 167.62ms, mfu 0.19%\n",
      "step 3100: train loss 1.6231, val loss 1.6290\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 3100: loss 1.7252, time 2211.81ms, mfu 0.17%\n",
      "iter 3110: loss 1.6458, time 166.28ms, mfu 0.18%\n",
      "iter 3120: loss 1.7342, time 184.71ms, mfu 0.18%\n",
      "iter 3130: loss 1.6939, time 195.95ms, mfu 0.18%\n",
      "iter 3140: loss 1.5731, time 185.48ms, mfu 0.18%\n",
      "iter 3150: loss 1.7253, time 181.55ms, mfu 0.18%\n",
      "iter 3160: loss 1.6695, time 182.20ms, mfu 0.18%\n",
      "iter 3170: loss 1.6104, time 192.99ms, mfu 0.18%\n",
      "iter 3180: loss 1.7872, time 183.29ms, mfu 0.18%\n",
      "iter 3190: loss 1.7972, time 182.51ms, mfu 0.18%\n",
      "step 3200: train loss 1.5629, val loss 1.6022\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 3200: loss 1.6589, time 2416.18ms, mfu 0.16%\n",
      "iter 3210: loss 1.6352, time 207.36ms, mfu 0.16%\n",
      "iter 3220: loss 1.6786, time 161.76ms, mfu 0.17%\n",
      "iter 3230: loss 1.6589, time 163.28ms, mfu 0.17%\n",
      "iter 3240: loss 1.7947, time 164.05ms, mfu 0.17%\n",
      "iter 3250: loss 1.5852, time 164.32ms, mfu 0.18%\n",
      "iter 3260: loss 1.6043, time 162.75ms, mfu 0.18%\n",
      "iter 3270: loss 1.5508, time 165.27ms, mfu 0.18%\n",
      "iter 3280: loss 1.7505, time 165.98ms, mfu 0.18%\n",
      "iter 3290: loss 1.7231, time 162.76ms, mfu 0.19%\n",
      "step 3300: train loss 1.6104, val loss 1.5974\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 3300: loss 1.6592, time 2108.82ms, mfu 0.17%\n",
      "iter 3310: loss 1.5303, time 165.20ms, mfu 0.17%\n",
      "iter 3320: loss 1.7430, time 161.06ms, mfu 0.18%\n",
      "iter 3330: loss 1.8581, time 161.36ms, mfu 0.18%\n",
      "iter 3340: loss 1.6117, time 168.71ms, mfu 0.18%\n",
      "iter 3350: loss 1.7177, time 158.68ms, mfu 0.18%\n",
      "iter 3360: loss 1.5891, time 163.76ms, mfu 0.19%\n",
      "iter 3370: loss 1.6948, time 162.09ms, mfu 0.19%\n",
      "iter 3380: loss 1.7693, time 161.96ms, mfu 0.19%\n",
      "iter 3390: loss 1.7800, time 160.02ms, mfu 0.19%\n",
      "step 3400: train loss 1.6072, val loss 1.5938\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 3400: loss 1.8502, time 2099.53ms, mfu 0.17%\n",
      "iter 3410: loss 1.9017, time 161.89ms, mfu 0.18%\n",
      "iter 3420: loss 1.6999, time 164.67ms, mfu 0.18%\n",
      "iter 3430: loss 1.7368, time 165.29ms, mfu 0.18%\n",
      "iter 3440: loss 1.8204, time 161.01ms, mfu 0.18%\n",
      "iter 3450: loss 1.7604, time 160.92ms, mfu 0.19%\n",
      "iter 3460: loss 2.0020, time 162.01ms, mfu 0.19%\n",
      "iter 3470: loss 1.6922, time 167.04ms, mfu 0.19%\n",
      "iter 3480: loss 1.6569, time 160.47ms, mfu 0.19%\n",
      "iter 3490: loss 1.6549, time 161.89ms, mfu 0.19%\n",
      "step 3500: train loss 1.5491, val loss 1.5649\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 3500: loss 1.7571, time 2106.34ms, mfu 0.18%\n",
      "iter 3510: loss 1.5435, time 160.65ms, mfu 0.18%\n",
      "iter 3520: loss 1.7043, time 164.98ms, mfu 0.18%\n",
      "iter 3530: loss 1.7491, time 165.80ms, mfu 0.18%\n",
      "iter 3540: loss 1.5602, time 162.39ms, mfu 0.19%\n",
      "iter 3550: loss 1.6158, time 162.54ms, mfu 0.19%\n",
      "iter 3560: loss 1.8871, time 168.39ms, mfu 0.19%\n",
      "iter 3570: loss 1.6485, time 162.32ms, mfu 0.19%\n",
      "iter 3580: loss 1.6221, time 160.89ms, mfu 0.19%\n",
      "iter 3590: loss 1.8020, time 162.11ms, mfu 0.19%\n",
      "step 3600: train loss 1.5348, val loss 1.5987\n",
      "iter 3600: loss 1.7566, time 1898.96ms, mfu 0.18%\n",
      "iter 3610: loss 1.7522, time 162.16ms, mfu 0.18%\n",
      "iter 3620: loss 1.7873, time 180.97ms, mfu 0.18%\n",
      "iter 3630: loss 1.6991, time 163.17ms, mfu 0.18%\n",
      "iter 3640: loss 1.6118, time 161.46ms, mfu 0.18%\n",
      "iter 3650: loss 1.4223, time 163.61ms, mfu 0.19%\n",
      "iter 3660: loss 1.6822, time 162.17ms, mfu 0.19%\n",
      "iter 3670: loss 1.6539, time 164.36ms, mfu 0.19%\n",
      "iter 3680: loss 1.6619, time 165.50ms, mfu 0.19%\n",
      "iter 3690: loss 2.0044, time 158.69ms, mfu 0.19%\n",
      "step 3700: train loss 1.5574, val loss 1.5598\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 3700: loss 1.6842, time 2099.83ms, mfu 0.18%\n",
      "iter 3710: loss 1.7363, time 163.41ms, mfu 0.18%\n",
      "iter 3720: loss 1.7340, time 160.78ms, mfu 0.18%\n",
      "iter 3730: loss 1.5837, time 166.60ms, mfu 0.18%\n",
      "iter 3740: loss 1.5616, time 162.80ms, mfu 0.19%\n",
      "iter 3750: loss 1.7806, time 164.93ms, mfu 0.19%\n",
      "iter 3760: loss 1.7392, time 166.84ms, mfu 0.19%\n",
      "iter 3770: loss 1.5292, time 162.36ms, mfu 0.19%\n",
      "iter 3780: loss 1.7059, time 163.48ms, mfu 0.19%\n",
      "iter 3790: loss 1.6123, time 162.79ms, mfu 0.19%\n",
      "step 3800: train loss 1.4965, val loss 1.5963\n",
      "iter 3800: loss 1.6724, time 1910.53ms, mfu 0.18%\n",
      "iter 3810: loss 1.6942, time 163.19ms, mfu 0.18%\n",
      "iter 3820: loss 1.6521, time 163.01ms, mfu 0.18%\n",
      "iter 3830: loss 1.6288, time 162.13ms, mfu 0.18%\n",
      "iter 3840: loss 1.9918, time 182.46ms, mfu 0.18%\n",
      "iter 3850: loss 1.5846, time 163.91ms, mfu 0.19%\n",
      "iter 3860: loss 1.5575, time 163.38ms, mfu 0.19%\n",
      "iter 3870: loss 1.6518, time 166.00ms, mfu 0.19%\n",
      "iter 3880: loss 1.7276, time 163.78ms, mfu 0.19%\n",
      "iter 3890: loss 1.6459, time 164.85ms, mfu 0.19%\n",
      "step 3900: train loss 1.4477, val loss 1.5269\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 3900: loss 1.4394, time 2197.16ms, mfu 0.17%\n",
      "iter 3910: loss 1.6200, time 179.92ms, mfu 0.18%\n",
      "iter 3920: loss 1.7070, time 167.86ms, mfu 0.18%\n",
      "iter 3930: loss 1.7698, time 161.85ms, mfu 0.18%\n",
      "iter 3940: loss 1.5829, time 161.94ms, mfu 0.18%\n",
      "iter 3950: loss 1.6896, time 163.17ms, mfu 0.19%\n",
      "iter 3960: loss 1.5704, time 161.78ms, mfu 0.19%\n",
      "iter 3970: loss 1.4399, time 172.25ms, mfu 0.19%\n",
      "iter 3980: loss 1.7062, time 168.82ms, mfu 0.19%\n",
      "iter 3990: loss 1.5533, time 187.08ms, mfu 0.19%\n",
      "step 4000: train loss 1.5597, val loss 1.5972\n",
      "iter 4000: loss 1.7324, time 1894.53ms, mfu 0.17%\n",
      "iter 4010: loss 1.6720, time 188.81ms, mfu 0.17%\n",
      "iter 4020: loss 1.6675, time 161.73ms, mfu 0.18%\n",
      "iter 4030: loss 1.6128, time 165.12ms, mfu 0.18%\n",
      "iter 4040: loss 1.6251, time 161.60ms, mfu 0.18%\n",
      "iter 4050: loss 1.6048, time 162.37ms, mfu 0.18%\n",
      "iter 4060: loss 1.5914, time 163.45ms, mfu 0.19%\n",
      "iter 4070: loss 1.7058, time 163.59ms, mfu 0.19%\n",
      "iter 4080: loss 1.6742, time 180.85ms, mfu 0.19%\n",
      "iter 4090: loss 1.6749, time 164.07ms, mfu 0.19%\n",
      "step 4100: train loss 1.4870, val loss 1.5240\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 4100: loss 1.6794, time 2164.64ms, mfu 0.17%\n",
      "iter 4110: loss 1.5833, time 165.95ms, mfu 0.17%\n",
      "iter 4120: loss 1.4470, time 185.83ms, mfu 0.18%\n",
      "iter 4130: loss 1.6898, time 160.90ms, mfu 0.18%\n",
      "iter 4140: loss 1.4611, time 165.60ms, mfu 0.18%\n",
      "iter 4150: loss 1.7284, time 163.37ms, mfu 0.18%\n",
      "iter 4160: loss 1.4878, time 183.35ms, mfu 0.18%\n",
      "iter 4170: loss 1.5392, time 160.89ms, mfu 0.19%\n",
      "iter 4180: loss 1.6032, time 163.09ms, mfu 0.19%\n",
      "iter 4190: loss 1.6347, time 162.95ms, mfu 0.19%\n",
      "step 4200: train loss 1.5239, val loss 1.5373\n",
      "iter 4200: loss 1.6192, time 1885.46ms, mfu 0.17%\n",
      "iter 4210: loss 1.5643, time 164.74ms, mfu 0.18%\n",
      "iter 4220: loss 1.5764, time 164.68ms, mfu 0.18%\n",
      "iter 4230: loss 1.6121, time 185.84ms, mfu 0.18%\n",
      "iter 4240: loss 1.7452, time 167.00ms, mfu 0.18%\n",
      "iter 4250: loss 1.7670, time 166.09ms, mfu 0.18%\n",
      "iter 4260: loss 1.6667, time 163.55ms, mfu 0.18%\n",
      "iter 4270: loss 1.6600, time 163.45ms, mfu 0.19%\n",
      "iter 4280: loss 1.4909, time 165.07ms, mfu 0.19%\n",
      "iter 4290: loss 1.5410, time 169.44ms, mfu 0.19%\n",
      "step 4300: train loss 1.5069, val loss 1.5214\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 4300: loss 1.6056, time 2306.62ms, mfu 0.17%\n",
      "iter 4310: loss 1.7149, time 165.90ms, mfu 0.17%\n",
      "iter 4320: loss 1.6821, time 162.67ms, mfu 0.18%\n",
      "iter 4330: loss 1.6915, time 161.66ms, mfu 0.18%\n",
      "iter 4340: loss 1.5789, time 168.08ms, mfu 0.18%\n",
      "iter 4350: loss 1.7868, time 163.27ms, mfu 0.18%\n",
      "iter 4360: loss 1.6744, time 161.43ms, mfu 0.19%\n",
      "iter 4370: loss 1.7203, time 161.55ms, mfu 0.19%\n",
      "iter 4380: loss 1.6064, time 165.75ms, mfu 0.19%\n",
      "iter 4390: loss 1.7470, time 162.24ms, mfu 0.19%\n",
      "step 4400: train loss 1.4723, val loss 1.5509\n",
      "iter 4400: loss 1.5397, time 1896.89ms, mfu 0.17%\n",
      "iter 4410: loss 1.5611, time 168.01ms, mfu 0.18%\n",
      "iter 4420: loss 1.5778, time 165.88ms, mfu 0.18%\n",
      "iter 4430: loss 1.5911, time 179.10ms, mfu 0.18%\n",
      "iter 4440: loss 1.7101, time 162.29ms, mfu 0.18%\n",
      "iter 4450: loss 1.7752, time 161.45ms, mfu 0.19%\n",
      "iter 4460: loss 1.6612, time 160.77ms, mfu 0.19%\n",
      "iter 4470: loss 1.6011, time 164.17ms, mfu 0.19%\n",
      "iter 4480: loss 1.6383, time 161.11ms, mfu 0.19%\n",
      "iter 4490: loss 1.6578, time 162.92ms, mfu 0.19%\n",
      "step 4500: train loss 1.4625, val loss 1.4841\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 4500: loss 1.5765, time 2070.37ms, mfu 0.17%\n",
      "iter 4510: loss 1.5513, time 161.39ms, mfu 0.18%\n",
      "iter 4520: loss 1.5143, time 160.98ms, mfu 0.18%\n",
      "iter 4530: loss 1.7307, time 179.88ms, mfu 0.18%\n",
      "iter 4540: loss 1.6566, time 163.43ms, mfu 0.18%\n",
      "iter 4550: loss 1.7524, time 162.34ms, mfu 0.19%\n",
      "iter 4560: loss 1.6054, time 163.84ms, mfu 0.19%\n",
      "iter 4570: loss 1.6432, time 162.32ms, mfu 0.19%\n",
      "iter 4580: loss 1.6222, time 173.01ms, mfu 0.19%\n",
      "iter 4590: loss 1.5922, time 159.84ms, mfu 0.19%\n",
      "step 4600: train loss 1.4737, val loss 1.4831\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 4600: loss 1.6498, time 2098.05ms, mfu 0.17%\n",
      "iter 4610: loss 1.5962, time 161.52ms, mfu 0.18%\n",
      "iter 4620: loss 1.6292, time 162.32ms, mfu 0.18%\n",
      "iter 4630: loss 1.5728, time 162.26ms, mfu 0.18%\n",
      "iter 4640: loss 1.6465, time 165.81ms, mfu 0.19%\n",
      "iter 4650: loss 1.3893, time 161.83ms, mfu 0.19%\n",
      "iter 4660: loss 1.5676, time 170.61ms, mfu 0.19%\n",
      "iter 4670: loss 1.6933, time 163.18ms, mfu 0.19%\n",
      "iter 4680: loss 1.7008, time 164.96ms, mfu 0.19%\n",
      "iter 4690: loss 1.4823, time 161.03ms, mfu 0.19%\n",
      "step 4700: train loss 1.4691, val loss 1.4626\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 4700: loss 1.5413, time 2091.03ms, mfu 0.18%\n",
      "iter 4710: loss 1.6946, time 161.74ms, mfu 0.18%\n",
      "iter 4720: loss 1.5913, time 167.41ms, mfu 0.18%\n",
      "iter 4730: loss 1.5271, time 162.47ms, mfu 0.18%\n",
      "iter 4740: loss 1.5656, time 162.64ms, mfu 0.19%\n",
      "iter 4750: loss 1.5622, time 162.24ms, mfu 0.19%\n",
      "iter 4760: loss 1.6752, time 161.58ms, mfu 0.19%\n",
      "iter 4770: loss 1.5303, time 163.06ms, mfu 0.19%\n",
      "iter 4780: loss 1.5878, time 162.75ms, mfu 0.19%\n",
      "iter 4790: loss 1.5533, time 164.12ms, mfu 0.19%\n",
      "step 4800: train loss 1.4403, val loss 1.5020\n",
      "iter 4800: loss 1.5425, time 1883.88ms, mfu 0.18%\n",
      "iter 4810: loss 1.6820, time 163.45ms, mfu 0.18%\n",
      "iter 4820: loss 1.5900, time 162.54ms, mfu 0.18%\n",
      "iter 4830: loss 1.6629, time 161.99ms, mfu 0.18%\n",
      "iter 4840: loss 1.5858, time 162.08ms, mfu 0.19%\n",
      "iter 4850: loss 1.6204, time 163.16ms, mfu 0.19%\n",
      "iter 4860: loss 1.4941, time 162.83ms, mfu 0.19%\n",
      "iter 4870: loss 1.4298, time 165.45ms, mfu 0.19%\n",
      "iter 4880: loss 1.5327, time 162.88ms, mfu 0.19%\n",
      "iter 4890: loss 1.6551, time 162.14ms, mfu 0.19%\n",
      "step 4900: train loss 1.4436, val loss 1.4341\n",
      "saving checkpoint to out-python-peps-char\n",
      "iter 4900: loss 1.4756, time 2090.28ms, mfu 0.18%\n",
      "iter 4910: loss 1.4568, time 163.83ms, mfu 0.18%\n",
      "iter 4920: loss 1.7181, time 169.17ms, mfu 0.18%\n",
      "iter 4930: loss 1.5902, time 162.39ms, mfu 0.18%\n",
      "iter 4940: loss 1.7921, time 164.22ms, mfu 0.19%\n",
      "iter 4950: loss 1.6566, time 161.02ms, mfu 0.19%\n",
      "iter 4960: loss 1.4211, time 165.87ms, mfu 0.19%\n",
      "iter 4970: loss 1.4426, time 162.19ms, mfu 0.19%\n",
      "iter 4980: loss 1.5027, time 164.04ms, mfu 0.19%\n",
      "iter 4990: loss 1.5483, time 159.71ms, mfu 0.19%\n",
      "step 5000: train loss 1.4438, val loss 1.4542\n",
      "iter 5000: loss 1.4665, time 1889.73ms, mfu 0.18%\n"
     ]
    }
   ],
   "source": [
    "! (cd 'tmp/nanoGPT' && \\\n",
    "  python3 train.py 'config/train_python_peps_char.py' \\\n",
    "  --device=mps --compile=False \\\n",
    "  --max_iters=5000 --eval_interval=100 --log_interval=10 \\\n",
    "  --block_size=128 --batch_size=12 \\\n",
    "  --init_from='resume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... and let's try the output again. {.slide-code visibility=uncounted}\n",
    "\n",
    "::: footer\n",
    "➍ Training a tiny transformer model\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-python-peps-char\n",
      "Overriding: num_samples = 1\n",
      "Overriding: max_new_tokens = 500\n",
      "Overriding: device = cpu\n",
      "Overriding: seed = 1694416832\n",
      "Overriding: start = A good Python code is \n",
      "number of parameters: 10.75M\n",
      "Loading meta from data/python_peps_char/meta.pkl...\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "A good Python code is not performatication\n",
      "or to problem and systems. The allowing may are supported to be value of\n",
      "expected ``except`` and ``updatementer``none``. The is `size to work the\n",
      "``index.tarse`` auth the path that of the same to referreferent and like\n",
      "attributed to item, for version 1.4 is a possible in the version the from\n",
      "statementially returning the part stated by a value of the feel file\n",
      "the beginal for all namest a respured to proposes of the example with ``__``, it implementation is methods\n",
      "developer ...\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "! (cd 'tmp/nanoGPT' && \\\n",
    "    python3 sample.py \\\n",
    "    --out_dir=out-python-peps-char \\\n",
    "    --num_samples=1 \\\n",
    "    --max_new_tokens=500 \\\n",
    "    --device=cpu \\\n",
    "    --seed=\"$(date +%s)\" \\\n",
    "    --start='A good Python code is ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <small>Weights & Biases Integration</small> {.center .center-horizontal .smaller visibility=uncounted}\n",
    "\n",
    "<small>\n",
    "<https://api.wandb.ai/links/karmi/2501lunz>\n",
    "</small>\n",
    "\n",
    "<iframe\n",
    "\tsrc=\"https://api.wandb.ai/links/karmi/2501lunz\"\n",
    "\tframeborder=\"0\"\n",
    "\twidth=\"1024\"\n",
    "\theight=\"550\"\n",
    "  style=\"border: 2px solid #ccc; border-radius: 5px; padding: 10px; box-shadow: 0.3em 0.3em 1em rgba(0, 0, 0, 0.3);\"></iframe>\n",
    "\n",
    "::: footer\n",
    "➍ Training a tiny transformer model\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
